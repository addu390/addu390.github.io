<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://pyblog.xyz/feed.xml" rel="self" type="application/atom+xml" /><link href="https://pyblog.xyz/" rel="alternate" type="text/html" /><updated>2024-07-14T02:21:24+00:00</updated><id>https://pyblog.xyz/feed.xml</id><title type="html">PYBLOG</title><subtitle>How do you know which watermelon &lt;img id=&quot;showerButton&quot; class=&quot;twemoji&quot; src=&quot;https://pyblog.xyz/assets/img/emoji/watermelon.svg&quot; alt=&quot;&quot;&gt; to pick?</subtitle><author><name>Adesh Nalpet Adimurthy</name></author><entry><title type="html">Spatial Index: R Trees</title><link href="https://pyblog.xyz/spatial-index-r-tree" rel="alternate" type="text/html" title="Spatial Index: R Trees" /><published>2024-06-26T00:00:00+00:00</published><updated>2024-06-26T00:00:00+00:00</updated><id>https://pyblog.xyz/spatial-index-r-tree</id><content type="html" xml:base="https://pyblog.xyz/spatial-index-r-tree">&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/featured/webp/rtree-spatial-index.webp&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In this post, let&apos;s explore the &lt;a href=&quot;https://en.wikipedia.org/wiki/R-tree&quot; target=&quot;_blank&quot;&gt;R-Tree&lt;/a&gt; data structure, which is popularly used to store multi-dimensional data, such as data points, segments, and rectangles.&lt;/p&gt;

&lt;h3&gt;1. R-Trees and Rectangles&lt;/h3&gt;

&lt;p&gt;For example, consider the plan of a university layout below. We can use the R-Tree data structure to index the buildings on the map.&lt;/p&gt;

&lt;p&gt;To do so, we can place rectangles around a building or group of buildings and then index them. Suppose there&apos;s a much bigger section of the map signifying a larger department, and we need to query all the buildings within a department. We can use the R-Tree to find all the buildings within (partially or fully contained) the larger section (query rectangle).&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image&quot; src=&quot;./assets/posts/spatial-index/r-tree-campus-level-2.svg&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 0: Layout with MBRs and Query Rectangle&lt;/p&gt;

&lt;p&gt;In the above figure, the red rectangle represent the query rectangle, used to ask the R-Tree to get all the buildings that intersect with the query rectangle (&lt;code&gt;R2, R3, R6&lt;/code&gt;).&lt;/p&gt;

&lt;h3&gt;2. R-Tree - Intuition&lt;/h3&gt;

&lt;p&gt;The main idea in R-trees is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Minimum_bounding_rectangle&quot; target=&quot;_blank&quot;&gt;minimum bounding rectangles&lt;/a&gt;. We&apos;ll come to what &quot;minimum&quot; implies in a second.&lt;/p&gt;

&lt;p&gt;The inner node of an R-tree is as follows: We start with the root node, representing the large landscape. The inner nodes are guideposts that hold pointers to the child nodes we need to go down to in the tree. i.e. each entry of a node points to an area of the data space (described by MBR).&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/spatial-index/r-tree-inner-node.svg&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 1: R-Tree Inner Node&lt;/p&gt;

&lt;p&gt;For instance, think of a &lt;a href=&quot;https://en.wikipedia.org/wiki/Binary_search_tree&quot; target=&quot;_blank&quot;&gt;Binary Search Tree&lt;/a&gt;. From the root node, we make a decision to go left or right. The R-tree is similar, but more of an &lt;a href=&quot;/b-tree&quot; target=&quot;_blank&quot;&gt;M-way tree&lt;/a&gt;, where each node can have multiple entries as seen above. Instead of having integer or string values (one-dimensional), the inner nodes consist of entries (multi-dimensional). In the example, there are 4 entries of rectangles.&lt;/p&gt;

&lt;h3&gt;2.1. MBR - Minimum Bounding Rectangle&lt;/h3&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-35&quot; src=&quot;./assets/posts/spatial-index/r-tree-mbr.svg&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 2: R-Tree Minimum Bounding Rectangle&lt;/p&gt;

&lt;p&gt;Minimum Bounding Rectangles, &lt;code&gt;R1, R2, R3, R4&lt;/code&gt;, contain the objects which are stored in the sub-trees in a minimal way. For instance, say we have 3 rectangles &lt;code&gt;R11, R12, R13&lt;/code&gt;. &lt;code&gt;R1&lt;/code&gt; is the smallest rectangle that can be created to completely contain all three rectangles, hence the name &quot;minimum.&quot;&lt;/p&gt;

&lt;h3&gt;2.2. Search Process and Overlapping MBRs&lt;/h3&gt;

&lt;p&gt;The search process in an R-tree is simple: for a query object/query rectangle; at an inner node, it is the decision to check if any of the entries in a node intersect with the query rectangle.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/spatial-index/r-tree-query-rectangle.svg&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 3: R-Tree Query Rectangle(s)&lt;/p&gt;

&lt;p&gt;For example, consider a query rectangle &lt;code&gt;Q1&lt;/code&gt;. It&apos;s clear that R1 intersects with &lt;code&gt;Q1&lt;/code&gt;, so we would follow down the tree from &lt;code&gt;R1&lt;/code&gt;. Similarly, &lt;code&gt;Q2&lt;/code&gt; intersects with &lt;code&gt;R2&lt;/code&gt;. However, in scenarios where the query rectangle intersects with multiple entries/rectangles (&lt;code&gt;Q3&lt;/code&gt; with &lt;code&gt;R2, R3, R4&lt;/code&gt;), all the intersecting rectangles have to be searched. This can happen if the indexing is not optimized and has to be avoided as it defeats the purpose of indexing in the first place.&lt;/p&gt;

&lt;h3&gt;2.3. R-Tree - Properties&lt;/h3&gt;

&lt;p&gt;Here&apos;s a bit of a larger example of an R-tree.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-85&quot; src=&quot;./assets/posts/spatial-index/r-tree-l-3.svg&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 3: R-Tree Level-2&lt;/p&gt;

&lt;p&gt;Every node in an R-tree has between &lt;code&gt;m&lt;/code&gt; and &lt;code&gt;M&lt;/code&gt; entries. More specifically, each node has between &lt;code&gt;m ≤ ⌈M/2⌉ and M&lt;/code&gt; entries. The node has at least 2 entries unless it&apos;s a leaf.&lt;/p&gt;

&lt;p&gt;By now, if you also read the blog post on &lt;a href=&quot;/b-tree&quot; target=&quot;_blank&quot;&gt;B-Trees and B+ Trees&lt;/a&gt;, you’ll see that an R-Tree is quite similar to a B+ Tree. It uses a similar idea to split the space at each (inner) node into multiple areas. However, B+ Trees mostly work with one-dimensional data, and the data ranges do not overlap.&lt;/p&gt;

&lt;h3&gt;3. Search using an R-Tree&lt;/h3&gt;

&lt;p&gt;Now that we know the idea behind R-Trees and the search process, Let&apos;s put a clear-cut definition to the search process:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Goal: Find all rectangles that overlap with the given rectangle &lt;code&gt;S&lt;/code&gt; (query rectangle).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Let &lt;code&gt;T&lt;/code&gt; denote the node (at the current level/sub-tree).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;S1 (Search in sub-trees): If &lt;code&gt;T&lt;/code&gt; is not a leaf, check all the entries &lt;code&gt;E&lt;/code&gt; in &lt;code&gt;T&lt;/code&gt;. If the MBR of &lt;code&gt;E&lt;/code&gt; overlaps with &lt;code&gt;S&lt;/code&gt;, then continue the search in the sub-tree to which &lt;code&gt;E&lt;/code&gt; points.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;S2 (Search in Leaves): If &lt;code&gt;T&lt;/code&gt; is a leaf node, inspect all entries of &lt;code&gt;E&lt;/code&gt;. All entries that overlap with &lt;code&gt;S&lt;/code&gt; are part of the query result.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;4. Inserting to an R-Tree&lt;/h3&gt;

&lt;p&gt;Coming to inserts, consider a leaf node (MBR) as shown below with 3 entries/objects, &lt;code&gt;R1&lt;/code&gt;, &lt;code&gt;R2&lt;/code&gt;, and &lt;code&gt;R3&lt;/code&gt;. Let&apos;s assume that the leaf is not full yet (MBR has a threshold capacity on the number of objects it can hold).&lt;/p&gt;

&lt;p&gt;Say, there&apos;s a new rectangle &lt;code&gt;R4&lt;/code&gt; coming and it has to be inserted inside the leaf node. As you can see, in order to capture the new objects, the MBR is adjusted, i.e., enlarged to minimally contain &lt;code&gt;R1&lt;/code&gt; to &lt;code&gt;R4&lt;/code&gt;. Going on and inserting another object &lt;code&gt;R5&lt;/code&gt;, the MBR is once again adjusted.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-100&quot; src=&quot;./assets/posts/spatial-index/r-tree-insert.svg&quot; /&gt;&lt;/p&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 4: R-Tree Insert (Adjusting MBR)&lt;/p&gt;

&lt;p&gt;On an insert, when the MBR is updated, i.e., contains more objects, the new MBR has to be updated not only for the node but also propagated to other lower levels and potentially (not always) up to the root node. This is to reflect that the sub-tree now contains more information.&lt;/p&gt;

&lt;h3&gt;4.1. Choice for Insert&lt;/h3&gt;

&lt;p&gt;Unlike the example, it&apos;s not always clear in which node/sub-tree an object should be inserted. Here: &lt;code&gt;MBR1&lt;/code&gt;, &lt;code&gt;MBR2&lt;/code&gt;, or &lt;code&gt;MBR3&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-55&quot; src=&quot;./assets/posts/spatial-index/r-tree-insert-mbrs.svg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The question is, in which MBR should we insert &lt;code&gt;R1&lt;/code&gt; into? Setting aside any rules or justification for a second, &lt;code&gt;R1&lt;/code&gt; can be inserted into any MBR.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-55&quot; src=&quot;./assets/posts/spatial-index/r-tree-insert-mbr1.svg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Inserting into &lt;code&gt;MBR1&lt;/code&gt; would need to immensely grow/expand &lt;code&gt;MBR1&lt;/code&gt; to fully contain &lt;code&gt;R1&lt;/code&gt;. The implication? Say there&apos;s a query rectangle &lt;code&gt;Q1&lt;/code&gt;. After leading down the sub-tree to &lt;code&gt;MBR1&lt;/code&gt;, we find that there&apos;s nothing (no objects). This is because, to contain &lt;code&gt;R1&lt;/code&gt;, we have expanded &lt;code&gt;MBR1&lt;/code&gt; so much that there is a lot of space without any objects. So, it&apos;s fair to conclude that one criterion to add is to insert into MBRs that need to expand the least.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-55&quot; src=&quot;./assets/posts/spatial-index/r-tree-insert-mbr2.svg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Going by that, inserting into &lt;code&gt;MBR2&lt;/code&gt; is a better option as opposed to &lt;code&gt;MBR1&lt;/code&gt;. Similarly, &lt;code&gt;MBR3&lt;/code&gt; may not be a bad option either, depending on the expansion factor.&lt;/p&gt;

&lt;hr class=&quot;post-hr&quot; /&gt;

&lt;p&gt;Stating the obvious (for implementation), the minimum-bounding-rectangle (MBR) is defined as the rectangle that has the maximal and minimal values of all rectangles in each dimension.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-90&quot; src=&quot;./assets/posts/spatial-index/r-tree-overlap-criterion.svg&quot; /&gt;&lt;/p&gt;

&lt;hr class=&quot;post-hr&quot; /&gt;

&lt;p&gt;Summarizing the insertion into R-Tree so far:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In principle, a new rectangle can be inserted into any node.&lt;/li&gt;
&lt;li&gt;If the node is full, a split needs to be performed (more on that in the next section).&lt;/li&gt;
&lt;li&gt;If not, the MBR may have to be adjusted/expanded to accommodate new objects (as seen ).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Observations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Extending bounding boxes is a critical factor for the performance of the R-Tree.&lt;/li&gt;
&lt;li&gt;Try to minimize overlap (of the MBRs).&lt;/li&gt;
&lt;li&gt;Try to minimize spread (the size of the MBR, as seen in section 4.1).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;4.2. Insert - Algorithm&lt;/h3&gt;

&lt;p&gt;Here&apos;s the algorithm proposed by the author of the R-Tree paper &quot;&lt;a href=&quot;https://www.researchgate.net/publication/221213205_R_Trees_A_Dynamic_Index_Structure_for_Spatial_Searching&quot; target=&quot;_blank&quot;&gt;A Dynamic Index Structure for Spatial Searching&lt;/a&gt;,&quot; by A. Guttman, 1984.&lt;/p&gt;

&lt;p&gt;The rest of this section is mostly going over snippets of code and explanations from this paper, but with more examples and visualization.&lt;/p&gt;

&lt;p&gt;Algorithm: Search for leaf to insert (&lt;a href=&quot;https://en.wikipedia.org/wiki/Hilbert_R-tree#Insertion&quot; target=&quot;_blank&quot;&gt;ChooseLeaf&lt;/a&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;CS1: Let &lt;code&gt;N&lt;/code&gt; be the root.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;CS2:
&lt;ul&gt;
    &lt;li&gt;If &lt;code&gt;N&lt;/code&gt; is a leaf, return &lt;code&gt;N&lt;/code&gt;.&lt;/li&gt;
    &lt;li&gt;&lt;p&gt;If &lt;code&gt;N&lt;/code&gt; is not a leaf: Search for an entry in &lt;code&gt;N&lt;/code&gt; whose rectangle (MBR) requires the least area increase in order to accommodate the new rectangle. In the case where there are multiple options, consider an entry that has the smallest (in area) MBR.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CS3: Let &lt;code&gt;N&lt;/code&gt; be the child node, then continue to step CS2 (repeat).&lt;/li&gt;
&lt;/ul&gt;

&lt;hr class=&quot;post-hr&quot; /&gt;

&lt;p&gt;A much simpler example of 8 objects, each object with one multidimensional attribute (Range or line-segments on x-axis) and one identity (Color). To insert these objects one by one in an empty R-tree of degree &lt;code&gt;M = 3&lt;/code&gt; (maximum number of entries at each node) and &lt;code&gt;m ≥ M/2&lt;/code&gt; (minimum number of entries at each node = 2).&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-100&quot; src=&quot;./assets/posts/spatial-index/r-tree-insert-example.svg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Observation: in the case where the selected leaf is already full, a splitting operation is performed. Let&apos;s understand the overflow problem better (the split problem):&lt;/p&gt;

&lt;h3&gt;4.3. Handling Overflow&lt;/h3&gt;

&lt;p&gt;In the case a node/leaf is full and a new entry cannot be stored anymore, a split needs to be performed, just as for a B+ Tree. The difference is that the split can be done arbitrarily and not only in the middle as for a B+ Tree.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-30&quot; src=&quot;./assets/posts/spatial-index/r-tree-split-problem.svg&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;4.3.1. The Split Problem&lt;/h3&gt;
&lt;p&gt;Given &lt;code&gt;M + 1&lt;/code&gt; entries in a node (exceeded maximum capacity per node), which two subsets of these entries should be considered as new and old nodes?&lt;/p&gt;

&lt;p&gt;To better understand the split problem, let&apos;s take a step back and consider 4 rectangles (&lt;code&gt;R1, R2, R3, R4&lt;/code&gt;) that need to be assigned to two nodes (MBRs) in a meaningful way.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-90&quot; src=&quot;./assets/posts/spatial-index/r-tree-split-problem-example.svg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Why is one better than the other? As mentioned before (Section 4.1), the area of expansion of the poor split is much larger compared to the good split (despite the overlap). This leads to more empty spaces in the node/MBR that do not have any objects.&lt;/p&gt;

&lt;p&gt;A realistic use case for an R-Tree is &lt;code&gt;M = 50&lt;/code&gt; and there are &lt;code&gt;2^(M-1)&lt;/code&gt; possibilities. Hence, a naive approach to look at all possible subsets and choose the best one is not practical (too expensive!).&lt;/p&gt;

&lt;h3&gt;4.3.2. The Split Problem: Quadratic Cost&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Search for split with smallest possible area&lt;/li&gt;
&lt;li&gt;Cost is Quadratic in &lt;code&gt;M&lt;/code&gt; and linear in number of dimensions &lt;code&gt;d&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Idea:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;Search for pairs of entries that would cause the largest MBR area if placed in the same node. Then put these entries in two different nodes&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Then: Consider all remaining entries and consider the one (among the 2 nodes) for which the increase in area (of MBR) has the largest possible difference between the two nodes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This entry is assigned to the node with the smallest increase. Repeat until all entries are assigned&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-80&quot; src=&quot;./assets/posts/spatial-index/r-tree-split-quadratic.svg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In this example, two nodes, &lt;code&gt;MBR1&lt;/code&gt; and &lt;code&gt;MBR2&lt;/code&gt;, are created. &lt;code&gt;R1&lt;/code&gt; and &lt;code&gt;R2&lt;/code&gt; in the same MBR would lead to creating the largest MBR. &lt;code&gt;R3&lt;/code&gt; is then inserted into &lt;code&gt;MBR1&lt;/code&gt; and not &lt;code&gt;MBR2&lt;/code&gt;, as the area increase of &lt;code&gt;MBR1&lt;/code&gt; is smaller compared to &lt;code&gt;MBR2&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Method &quot;AdjustTree,&quot; is called whenever a new entry is inserted. It is responsible for adapting the parent&apos;s MBR and propagating the changes bottom up, handling splits as well as changes to MBRs. In the worst case, the propagation can be up to the root node.&lt;/p&gt;

&lt;h3&gt;5. R-Tree Variants&lt;/h3&gt;

&lt;p&gt;R-trees do not guarantee good worst-case performance, but generally speaking, they perform well with real-world data. Addressing this specific problem, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Priority_R-tree&quot; target=&quot;_blank&quot;&gt;Priority R-tree&lt;/a&gt; is a worst-case &lt;a href=&quot;https://en.wikipedia.org/wiki/Asymptotically_optimal_algorithm&quot; target=&quot;_blank&quot;&gt;asymptotically optimal&lt;/a&gt; alternative to the spatial tree R-tree, which is essentially a hybrid between a k-dimensional tree (&lt;a href=&quot;https://en.wikipedia.org/wiki/K-d_tree&quot; target=&quot;_blank&quot;&gt;k-d tree&lt;/a&gt;) and an R-tree.&lt;/p&gt;

&lt;p&gt;Another commonly used variant is the &lt;a href=&quot;https://en.wikipedia.org/wiki/R*-tree&quot; target=&quot;_blanl&quot;&gt;R*-Tree&lt;/a&gt;, which uses the same algorithm as the regular R-tree for query and delete operations. However, while inserting, the R*-tree uses a combined strategy: for leaf nodes, overlap is minimized, and for inner nodes, enlargement and area are minimized, making the tree construction slightly more expensive.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/R%2B_tree&quot; target=&quot;_blanl&quot;&gt;R+-Tree&lt;/a&gt;, on the other hand, solves one main problem to ensure nodes do not overlap with each other, leading to better point query performance. However, it does so by inserting an object into multiple leaves if necessary, which is a disadvantage due to duplicate entries and larger tree size.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Hilbert_R-tree&quot; target=&quot;_blanl&quot;&gt;Hilbert R-Tree&lt;/a&gt; uses &lt;a href=&quot;/spatial-index-space-filling-curve&quot;&gt;space-filling curves&lt;/a&gt;, specifically the Hilbert curve, to impose a linear ordering on the data rectangles. It has two variants: Packed Hilbert R-trees, suitable for static databases in which updates are very rare, and dynamic Hilbert R-trees, suitable for dynamic databases where insertions, deletions, or updates may occur in real time.&lt;/p&gt;

&lt;h3&gt;6. Conclusion&lt;/h3&gt;

&lt;p&gt;R-trees have come a long way since the first paper was published in 1984. Today, their applications span over multi-dimensional indexes, computer graphics, video games, spatial data management systems, and many more.&lt;/p&gt;

&lt;p&gt;On the flip side, R-trees can degrade badly with discrete data. Hence, it&apos;s highly recommended to understand the data representation before using R-trees. R-trees are also relatively slow when there&apos;s a very high mutation rate, i.e., where the index changes often; this is because of the higher cost for constructing and updating the index (due to tree rebalancing) and they are more optimized for various search operations. Lastly, R-trees can be a poor algorithm choice when primarily dealing with points as opposed to polygons/regions.&lt;/p&gt;

&lt;h3&gt;7. References&lt;/h3&gt;
&lt;pre style=&quot;max-height: 300px&quot;&gt;&lt;code&gt;[1] A. Guttman, &quot;A Dynamic Index Structure for Spatial Searching,&quot; presented at the ACM SIGMOD International Conference on Management of Data, 1984. [Online]. Available: https://www.researchgate.net/publication/220805321_A_Dynamic_Index_Structure_for_Spatial_Searching.
[2] &quot;R-Tree,&quot; Wikipedia. [Online]. Available: https://en.wikipedia.org/wiki/R-tree.
[3] &quot;B-Trees and B+ Trees,&quot; PyBlog. [Online]. Available: https://www.pyblog.xyz/b-trees-b-plus-trees.
[4] &quot;Spatial Index R-Tree,&quot; YouTube, https://www.youtube.com/watch?v=U0jUvvQkaFw.
&lt;/code&gt;&lt;/pre&gt;</content><author><name>Adesh Nalpet Adimurthy</name></author><category term="System Wisdom" /><category term="Database" /><category term="Spatial Index" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pyblog.xyz/assets/featured/webp/rtree-spatial-index.webp" /><media:content medium="image" url="https://pyblog.xyz/assets/featured/webp/rtree-spatial-index.webp" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Spatial Index: Tessellation</title><link href="https://pyblog.xyz/spatial-index-tessellation" rel="alternate" type="text/html" title="Spatial Index: Tessellation" /><published>2024-06-17T00:00:00+00:00</published><updated>2024-06-17T00:00:00+00:00</updated><id>https://pyblog.xyz/spatial-index-tessellation</id><content type="html" xml:base="https://pyblog.xyz/spatial-index-tessellation">&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/featured/webp/space-tessellation.webp&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Brewing! this post a continuation of &lt;a href=&quot;/spatial-index-grid-system&quot;&gt;Spatial Index: Grid Systems&lt;/a&gt; where we will set the foundation for tessellation and delve into the details of &lt;a href=&quot;https://github.com/uber/h3&quot; target=&quot;_blank&quot;&gt;Uber H3&lt;/a&gt;&lt;/p&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;0. Foundation&lt;/summary&gt;
&lt;p&gt;Tessellation or tiling is the process of covering/dividing a space into smaller, non-overlapping shapes that fit together perfectly without gaps or overlaps. In spatial indexing, tessellation is used to break down the Earth&apos;s surface into manageable units for efficient data storage, querying, and analysis.&lt;/p&gt;

&lt;p&gt;The rationale behind why a geographical grid system (&lt;a href=&quot;cartograms-documentation#tessellation&quot; target=&quot;_blank&quot;&gt;Tessellation system&lt;/a&gt;) is necessary: The real world is cluttered with various geographical elements, both natural and man-made, none of which follow any consistent structure. To perform geographic algorithms or analyses on it, we need a more abstract form.&lt;/p&gt;

&lt;p&gt;Maps are a good start and are the most common abstraction, with which most people are familiar. However, maps still contain all sorts of inconsistencies. This calls for a grid system, which takes the cluttered geographic space and provides a more clean and structured mathematical space, making it much easier to perform computations and queries.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-100&quot; src=&quot;./assets/posts/spatial-index/h3-why-grids.png&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 0: Tessellated View of Halifax&lt;/p&gt;

&lt;p&gt;The primary principle of the grid is to break the space into uniform cells. These cells are the units of analysis used in geographic systems. Think of it as pixels in an image.&lt;/p&gt;

&lt;p&gt;A grid system adds a couple more layers on top of this, consisting of a series of nested grids, usually at increasingly fine resolutions. They include a way to uniquely identify any cell in the system. Other common grid systems include &lt;a href=&quot;https://en.wikipedia.org/wiki/Graticule_(cartography)&quot; target=&quot;_blank&quot;&gt;Graticule&lt;/a&gt; (latitude and longitude), &lt;a href=&quot;https://learn.microsoft.com/en-us/bingmaps/articles/bing-maps-tile-system#tile-coordinates-and-quadkeys&quot; target=&quot;_blank&quot;&gt;Quad Key&lt;/a&gt;  (Mercator projection), &lt;a href=&quot;/spatial-index-grid-system#3-geohash&quot; target=&quot;_blank&quot;&gt;Geohash&lt;/a&gt; (Equirectangular projection) and &lt;a href=&quot;/spatial-index-grid-system#4-google-s2&quot; target=&quot;_blank&quot;&gt;Google S2&lt;/a&gt; (Spherical projection).&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;1. Uber H3 - Intuition&lt;/summary&gt;
&lt;p&gt;Most systems use four-sided polygons (Square, Rectangle and Quadrilateral). H3 is the grid system developed by Uber, which uses hexagon cells as its base. It covers the space/world with hexagons and has different levels of resolution, with the smallest cells representing about &lt;code&gt;1 cm²&lt;/code&gt; of space.&lt;/p&gt;

&lt;h3&gt;1.1. Why Hexagons?&lt;/h3&gt;

&lt;p&gt;Starting off by adding rules or needs for choosing a tile, such as:&lt;/p&gt;
&lt;ul style=&quot;list-style-type:none;&quot;&gt;
&lt;li&gt;(a) Uniform shape&lt;/li&gt;
&lt;li&gt;(b) Uniform edge length&lt;/li&gt;
&lt;li&gt;(c) Uniform angles&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Brings down the number of options, with the most commonly used shapes being squares, equilateral triangles, and hexagons.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/spatial-index/h3-tile-options-2.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 1: Triangle vs Square vs Hexagon (neighbors)&lt;/p&gt;

&lt;p&gt;Another important property of tiles is uniform adjacency, i.e., how unambiguous the neighbors are. For example, squares have 4 unambiguous neighbors but also have 4 ambiguous neighbors at the corners, which may not provide the best perception of neighbors if you consider a circular radius.&lt;/p&gt; 

&lt;p&gt;Equilateral triangles are much worse, with 3 unambiguous neighbors and 9 ambiguous neighbors, which is one of the reasons why triangles are not commonly used, along with the rotation of cells necessary for tessellation. Lastly, hexagons are the best, with 6 unambiguous neighbors and a structure very close to finding neighbors by radius.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image&quot; src=&quot;./assets/posts/spatial-index/hex-square-tessellation.png&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 2: Square vs Hexagon (Optimal Space-Filling)&lt;/p&gt;

&lt;p&gt;Hexagons are more space-efficient and have optimal space-filling properties. This means that when filling a polygon with uniform cells, hexagons generally result in less over/under filling compared to squares.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-50&quot; src=&quot;./assets/posts/spatial-index/h3-tile-options-3.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 3: Square vs Hexagon (Child Containment)&lt;/p&gt;

&lt;p&gt;Hierarchical relationships between resolutions are another important property. Evidently, squares have hierarchical relationships with perfect child containment and can use algorithms such as quad trees to navigate up and down the hierarchy and space-filling curves to traverse the grid. Hexagons, while not having perfect child containment, can still function effectively with a tolerable margin of error.&lt;/p&gt;

&lt;p&gt;Without taking triangles into account, the summary of the comparison between squares and hexagons:&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-50&quot; src=&quot;./assets/posts/spatial-index/h3-tile-options.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 4: Squares vs Hexagons (Full Comparison)&lt;/p&gt;

&lt;p&gt;More on Hexagons vs Squares at &lt;a href=&quot;/cartograms-documentation#hexagonsvssquares&quot;&gt;Conceptualization of a Cartogram&lt;/a&gt;&lt;/p&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;h3&gt;1.2. Why Icosahedron?&lt;/h3&gt;

&lt;p&gt;Lastly, low shape and area distortion is more related to the projection than the shape of the tile. There are many types of projections, but the most commonly used are polyhedra. One such projection is the &lt;a href=&quot;/spatial-index-grid-system#3-1-geohash-intuition&quot;&gt;cylindrical projection&lt;/a&gt;, used in &lt;a href=&quot;/spatial-index-grid-system#3-geohash&quot;&gt;Geohash&lt;/a&gt;, which works well for squares but has the problem of distortion near the poles, making it hard to get equal surface area cells across the projection.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-80&quot; src=&quot;./assets/posts/spatial-index/uniform-shape-polyhedrons.png&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 5: Uniform Shape Polyhedrons&lt;/p&gt;

&lt;p&gt;The smaller the face, the lesser the distortion. An icosahedron, with 20 faces, is the better option among the uniform-face polyhedrons for fitting hexagons and triangles on them. Fitting squares on an icosahedron or even a tetrahedron is not ideal. Squares are mostly suitable for cubes (as seen in &lt;a href=&quot;/spatial-index-grid-system#4-google-s2&quot;&gt;S2&lt;/a&gt;). Taking the best of both worlds, an icosahedron with hexagons is the way to go.&lt;/p&gt;

&lt;h3&gt;1.3. H3 Grid System&lt;/h3&gt;

&lt;p&gt;Putting it all together, we take the polyhedron, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Icosahedron&quot; target=&quot;_blank&quot;&gt;icosahedron&lt;/a&gt;, project it on the surface of the Earth, then each face on the icosahedron is split into hexagon cells. More specifically, 4 full hexagon cells are completely contained by the face, 3 cells are half contained, and 3 corners form the pentagon.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/spatial-index/h3-tessellation.svg&quot; /&gt;
&lt;p&gt;Each hexagonal cell can be further subdivided into 7 hexagon cells with marginal error for containment. The number of levels decides the resolution.&lt;/p&gt;
&lt;img class=&quot;center-image-0 center-image&quot; src=&quot;./assets/posts/spatial-index/h3-tessellation-2.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 6: H3 Projection and Tessellation&lt;/p&gt;

&lt;p&gt;The H3 grid system divides the surface of the Earth into &lt;code&gt;122&lt;/code&gt; (110 hexagons and 12 icosahedron vertex-centered pentagons) base cells (resolution 0), which are used as the foundation for higher resolution cells. Each base cell has a specific orientation relative to the face of the icosahedron it is on. This orientation determines how cells at higher resolutions are positioned and indexed.&lt;/p&gt;

&lt;h3&gt;1.4. Why Pentagons?&lt;/h3&gt;

&lt;p&gt;Looking at the icosahedron, the 5 faces come together at every vertex, and truncating that creates the base cell. Pentagons are unavoidable at the vertices. However, there are only 12 of them at every resolution. But again, for most cases dealing with spaces within a city where the resolution is higher than 9, the pentagons, if far off in the water, they are safe to ignore.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-80&quot; src=&quot;./assets/posts/spatial-index/dymaxion-layout.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 7: Dymaxion layout (12 Vertices in Water)&lt;/p&gt;

&lt;p&gt;While the layout of the faces on the icosahedron can be done in any fashion, H3 uses the layout developed by Buckminster Fuller called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Dymaxion_map&quot; target=&quot;_blank&quot;&gt;Dymaxion layout&lt;/a&gt;.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-30&quot; src=&quot;./assets/posts/spatial-index/h3-tessellation.gif&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 8: H3 Projection and Tessellation (Animated)&lt;/p&gt;

&lt;p&gt;The benefit is that all the vertices end up in the water. For most applications, land is more important than water, and since the vertices are in the water, it reduces the need to deal with pentagons.&lt;/p&gt;

&lt;h3&gt;1.5. Cell ID&lt;/h3&gt;
&lt;p&gt;A cell ID is a 64-bit integer that uniquely identifies a hexagonal cell at a particular resolution. The composition of an H3 cell ID is as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Mode (4 bits): Identifies the H3 mode, which indicates the type of the identifier. For cell IDs, this value defaults set to 1.&lt;/li&gt;
&lt;li&gt;Edge Mode (Reserved, 3 bits): Indicates the edge mode, which is 0 for cell IDs.&lt;/li&gt;
&lt;li&gt;Resolution (4 bits): Specifies the resolution of the cell. H3 supports resolutions from 0 (coarsest) to 15 (finest).&lt;/li&gt;
&lt;li&gt;Base Cell (7 bits): Identifies the base cell, which is one of the 122 base cells that form the foundation of the H3 grid.&lt;/li&gt;
&lt;li&gt;Cell Index (45 bits): Contains the specific index of the cell within the base cell and resolution.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This structure (&lt;a href=&quot;#2-5-faceijk-to-h3-index&quot;&gt;Figure 14&lt;/a&gt;) allows H3 to efficiently encode the hierarchical location and resolution of each hexagonal cell in a compact 64-bit integer.&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;2. H3 - Implementation&lt;/summary&gt;

&lt;p&gt;The implementation below, loosely follows the steps of the actual H3 index calculation for demonstration purposes (to better understand the H3 Index). Here&apos;s a step-by-step process with reasonable simplifications:&lt;/p&gt;

&lt;h3&gt;2.1. LatLong to Vec3D&lt;/h3&gt;
&lt;p&gt;Convert latitude and longitude to &lt;a href=&quot;https://en.wikipedia.org/wiki/Cartesian_coordinate_system&quot; target=&quot;_blank&quot;&gt;3D Cartesian coordinates&lt;/a&gt; using the formulas (similar to Section &lt;a href=&quot;/spatial-index-grid-system#4-2-1-lat-long-to-x-y-z-&quot;&gt;4.2.1 in S2&lt;/a&gt;):.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-80&quot; src=&quot;./assets/posts/spatial-index/ecef.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 9: (lat, long) to (x, y, z) Transformation&lt;/p&gt;

&lt;details class=&quot;code-container&quot; open=&quot;&quot;&gt;&lt;summary class=&quot;p&quot;&gt;2.1a. LatLong to Vec3D - Snippet&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;private static double[] latLonToVec3D(double lat, double lon) {
    double r = Math.cos(Math.toRadians(lat));
    double x = r * Math.cos(Math.toRadians(lon));
    double y = r * Math.sin(Math.toRadians(lon));
    double z = Math.sin(Math.toRadians(lat));
    return new double[]{x, y, z};
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3&gt;2.2. Icosahedron Properties&lt;/h3&gt;
&lt;p&gt;We can identify the &lt;code&gt;12&lt;/code&gt; vertices of the icosahedron using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Golden_ratio&quot; target=&quot;_blank&quot;&gt;golden ratio&lt;/a&gt; &lt;code&gt;(ϕ)&lt;/code&gt;. It a well known property of a regular icosahedron, where three mutually perpendicular rectangles of aspect ratio &lt;code&gt;(ϕ)&lt;/code&gt; are arranged such that they share a common center.&lt;/p&gt;

&lt;p&gt;The icosahedron has 12 vertices, 20 faces, and 30 edges. The 12 vertices are given by: &lt;code&gt;(±1, ±ϕ, 0)&lt;/code&gt;, &lt;code&gt;(±ϕ, 0, ±1)&lt;/code&gt;, &lt;code&gt;(0, ±1, ±ϕ)&lt;/code&gt;. Lastly, the vertices need to be normalized to lie on the surface of a unit sphere.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image&quot; src=&quot;./assets/posts/spatial-index/golden-ratio.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 10: Golden Ratio Rectangles&lt;/p&gt;

&lt;p&gt;To calculate the &lt;code&gt;20&lt;/code&gt; face centers of the icosahedron:&lt;/p&gt;
&lt;p&gt;For each face, average the coordinates of its three vertices and normalize the resulting vector to lie on the unit sphere. Use the formula:&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-65&quot; src=&quot;./assets/posts/spatial-index/face-centers.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 11: Icosahedron Face Center&lt;/p&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;p&quot;&gt;2.2a. Icosahedron Vertices - Snippet&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;double PHI = (1.0 + Math.sqrt(5.0)) / 2.0;
double[][] vertices = {
        {-1, PHI, 0}, {1, PHI, 0}, {-1, -PHI, 0}, {1, -PHI, 0},
        {0, -1, PHI}, {0, 1, PHI}, {0, -1, -PHI}, {0, 1, -PHI},
        {PHI, 0, -1}, {PHI, 0, 1}, {-PHI, 0, -1}, {-PHI, 0, 1}
};

// Normalize the vertices to lie on the unit sphere
for (int i = 0; i &amp;lt; vertices.length; i++) {
    vertices[i] = normalize(vertices[i]);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;// Computes the center of a face defined by three vertices.
private static double[] computeFaceCenter(double[] a, double[] b, double[] c) {
    double[] center = new double[3];
    center[0] = (a[0] + b[0] + c[0]) / 3.0;
    center[1] = (a[1] + b[1] + c[1]) / 3.0;
    center[2] = (a[2] + b[2] + c[2]) / 3.0;
    return normalize(center);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;// Normalizes a vector to lie on the unit sphere.
private static double[] normalize(double[] v) {
    double length = Math.sqrt(v[0] * v[0] + v[1] * v[1] + v[2] * v[2]);
    return new double[]{v[0] / length, v[1] / length, v[2] / length};
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3&gt;2.3. Vec3D to Vec2D&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;Vec2D&lt;/code&gt; represents the cartesian coordinates on the face of the icosahedron. It provides a 2D projection (&lt;a href=&quot;#1-4-why-pentagons-&quot;&gt;Figure 7&lt;/a&gt;) of a point on the spherical surface of the Earth onto one of the icosahedron&apos;s faces, used to map geographic coordinates (latitude and longitude) onto a planar hexagonal grid. The conversion involves &lt;a href=&quot;https://en.wikipedia.org/wiki/Gnomonic_projection&quot; target=&quot;_blank&quot;&gt;gnomonic projection&lt;/a&gt;, which translates 3D coordinates to a 2D plane by projecting from the center of the sphere to the plane tangent to the face of the icosahedron.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Calculate &lt;code&gt;r&lt;/code&gt; (Radial Distance): Convert the distance from the face center to an angle using the inverse cosine function.&lt;/li&gt;
&lt;li&gt;Gnomonic Scaling: Scale the angle &lt;code&gt;r&lt;/code&gt; for the hexagonal grid at the given resolution.&lt;/li&gt;
&lt;li&gt;Calculate θ (Azimuthal Angle): Determine the angle from the face center, adjusting for face orientation and resolution.&lt;/li&gt;
&lt;li&gt;Convert to local 2D Coordinates: Transform polar coordinates &lt;code&gt;(r, θ)&lt;/code&gt; into Cartesian coordinates &lt;code&gt;(x, y)&lt;/code&gt;.&lt;/li&gt;   
&lt;/ul&gt;

&lt;img class=&quot;center-image-0 center-image&quot; src=&quot;./assets/posts/spatial-index/h3-to-vec2d.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 12: Gnomonic Projection (XYZ to rθ)&lt;/p&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;p&quot;&gt;2.3a. Vec3D to Vec2D - Snippet&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;// faceAxesAzRadsCII: Icosahedron face `ijk` axes as azimuth in radians from face center to vertex
// faceCenterGeo: Icosahedron face centers in lat/lng radians.
// RES0_U_GNOMONIC: Scaling factor from `Vec2d` resolution 0 unit length (or distance between adjacent cell center points on the plane) to gnomonic unit length.
// SQRT7_POWERS: Power of √7 for each resolution.
// AP7_ROT_RADS: Rotation angle between Class II and Class III resolution axes: asin(sqrt(3/28))

public Vec2d toVec2d(int resolution, int face, double distance) {
    // cos(r) = 1 - 2 * sin^2(r/2) = 1 - 2 * (sqd / 4) = 1 - sqd/2
    double r = acos(1.0 - distance / 2.0);
    if (r &amp;lt; EPSILON) {
        return new Vec2d(0.0, 0.0);
    }
    
    // Perform gnomonic scaling of `r` (`tan(r)`) and scale for current
    r = (tan(r) / RES0_U_GNOMONIC) * SQRT7_POWERS[resolution];
    
    // Compute counter-clockwise `theta` from Class II i-axis.
    double theta = faceAxesAzRadsCII[face][0] - this.azimuth(faceCenterGeo[face]);
    
    // Adjust `theta` for Class III.
    if ((resolution % 2) != 0) {
        theta -= AP7_ROT_RADS;
    }
    
    // Convert to local x, y.
    return new Vec2d(r * cos(theta), r * sin(theta));
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;p&gt;About &lt;code&gt;SQRT7_POWERS&lt;/code&gt;. Each resolution beyond 0 is created using an aperture 7 resolution spacing, i.e. number of cells in the next finer resolution (&lt;a href=&quot;#1-uber-h3-intuition&quot;&gt;Figure 1 and 3&lt;/a&gt;). So, as resolution increases, unit length is scaled by &lt;code&gt;sqrt(7)&lt;/code&gt;. H3 has 15 resolutions/levels (+resolution 0).&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3&gt;2.4. Vec2D to FaceIJK&lt;/h3&gt;
&lt;p&gt;Hexagonal grids have three primary axes, unlike the two we have for square grids. In &lt;a href=&quot;https://www.redblobgames.com/grids/hexagons/#coordinates&quot; target=&quot;_blank&quot;&gt;Axial coordinates&lt;/a&gt; or the Cube coordinates, the three coordinates (i, j, k) ensure that any point in the hexagonal grid can be described without ambiguity.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/spatial-index/h3-axial.png&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 13: Axial Coordinates (Class II and Class III)&lt;/p&gt;

&lt;p&gt;There are several other hex coordinate systems based, in this case, the constraints are &lt;code&gt;i + j + k = 0&lt;/code&gt;, with &lt;code&gt;120°&lt;/code&gt; axis separation.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;faceIJK&lt;/code&gt; represents the position/location of a hexagon within a face of the icosahedron using three coordinates &lt;code&gt;(i, j, k)&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Reverse Conversion: Translate Cartesian coordinates into the hexagonal coordinate system by aligning them with the hex grid&apos;s axes.&lt;/li&gt;
&lt;li&gt;Quantize and Round: Convert floating-point coordinates to integer grid positions, determining the closest hexagon center.&lt;/li&gt;
&lt;/ul&gt;
&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/spatial-index/h3-vec2d-facexyz.svg&quot; /&gt; 
&lt;ul&gt;
&lt;li&gt;Check Hex Center and Round: Use remainders to accurately determine which hexagon the point falls into by rounding to the nearest hex center.&lt;/li&gt;
&lt;pre&gt;&lt;code&gt;// Determine i and j based on r1 and r2
IF r1 &amp;lt; 0.5 THEN
    IF r1 &amp;lt; 1 / 3 THEN
        i = m1
        j = m2 + (r2 &amp;gt;= (1 + r1) / 2)
    ELSE
        i = m1 + ((1 - r1) &amp;lt;= r2 &amp;amp;&amp;amp; r2 &amp;lt; (2 * r1))
        j = m2 + (r2 &amp;gt;= (1 - r1))
ELSE IF r1 &amp;lt; 2 / 3 THEN
    j = m2 + (r2 &amp;gt;= (1 - r1))
    i = m1 + ((2 * r1 - 1) &amp;gt;= r2 || r2 &amp;gt;= (1 - r1))
ELSE
    i = m1 + 1
    j = m2 + (r2 &amp;gt;= (r1 / 2))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/p&gt;
&lt;li&gt;Fold Across Axes if Necessary: Correct the coordinates if they fall into negative regions, ensuring the coordinates remain within the valid grid.&lt;/li&gt;
&lt;pre&gt;&lt;code&gt;IF value.x &amp;lt; 0 THEN
    offset = j % 2
    axis_i = (j + offset) / 2
    diff = i - axis_i
    i = i - 2 * diff - offset

IF value.y &amp;lt; 0 THEN
    i = i - (2 * j + 1) / 2
    j = -j
&lt;/code&gt;&lt;/pre&gt;
&lt;li&gt;Normalize: Purpose: Adjust the coordinates to maintain the properties of the hexagonal grid, ensuring &lt;code&gt;i + j + k = 0&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;p&quot;&gt;2.4a. Vec2D to FaceIJK - Snippet&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;public static CoordIJK fromVec2d(Vec2d value) {
    int k = 0;

    double a1 = Math.abs(value.x);
    double a2 = Math.abs(value.y);

    // Reverse conversion
    double x2 = a2 / SIN60;
    double x1 = a1 + x2 / 2.0;

    // Quantize and round
    int m1 = (int) x1;
    int m2 = (int) x2;

    double r1 = x1 - m1;
    double r2 = x2 - m2;

    int i, j;
    if (r1 &amp;lt; 0.5) {
        if (r1 &amp;lt; 1.0 / 3.0) {
            i = m1;
            j = m2 + (r2 &amp;gt;= (1.0 + r1) / 2.0 ? 1 : 0);
        } else {
            i = m1 + ((1.0 - r1) &amp;lt;= r2 &amp;amp;&amp;amp; r2 &amp;lt; (2.0 * r1) ? 1 : 0);
            j = m2 + (r2 &amp;gt;= (1.0 - r1) ? 1 : 0);
        }
    } else if (r1 &amp;lt; 2.0 / 3.0) {
        j = m2 + (r2 &amp;gt;= (1.0 - r1) ? 1 : 0);
        i = m1 + ((2.0 * r1 - 1.0) &amp;gt;= r2 || r2 &amp;gt;= (1.0 - r1) ? 1 : 0);
    } else {
        i = m1 + 1;
        j = m2 + (r2 &amp;gt;= (r1 / 2.0) ? 1 : 0);
    }

    // Fold Across Axes if Necessary
    if (value.x &amp;lt; 0) {
        int offset = j % 2;
        int axis_i = (j + offset) / 2;
        int diff = i - axis_i;
        i = i - 2 * diff - offset;
    }

    if (value.y &amp;lt; 0) {
        i = i - (2 * j + 1) / 2;
        j = -j;
    }

    return new CoordIJK(i, j, k).normalize();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;p&gt;Each grid resolution is rotated &lt;code&gt;~19.1°&lt;/code&gt; relative to the next coarser resolution. The rotation alternates between counterclockwise (CCW) and clockwise (CW) at each successive resolution, so that each resolution will have one of two possible orientations as shown in Figure 13: &lt;code&gt;Class II&lt;/code&gt; or &lt;code&gt;Class III&lt;/code&gt;. The base cells, which make up resolution 0, are &lt;code&gt;Class II&lt;/code&gt;.&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3&gt;2.5. FaceIJK to H3 Index&lt;/h3&gt;
&lt;p&gt;Lastly, the &lt;a href=&quot;https://h3geo.org/docs/core-library/latLngToCellDesc&quot; target=&quot;_blank&quot;&gt;face and face-centered ijk coordinates are converted to H3 Index&lt;/a&gt;.&lt;/p&gt; 

&lt;img class=&quot;center-image-0 center-image-100&quot; src=&quot;./assets/posts/spatial-index/h3-index-structure.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 14: H3 Index Structure&lt;/p&gt;

&lt;p&gt;If the resolution is not uptill level 15, rest of the vits are set to 1s, for example: &lt;code&gt;83001dfffffffff&lt;/code&gt;. The binary representation is as below (Figure 15); &lt;code&gt;Index mode = 1&lt;/code&gt; i.e. indexes the regular hexagon type. Resolution = 3; Base Cell = 0; Resolution 1, 2 and 3 are 0, 3 and 5, rest are 1s.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-100&quot; src=&quot;./assets/posts/spatial-index/h3-index-structure-example.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 15: H3 Index Structure (Example: 83001dfffffffff)&lt;/p&gt;

&lt;p&gt;This primarily involves coverting to Direction bits, representing the hierarchical path from a base cell to a specific cell at a given resolution. These bits encode the sequence of directional steps taken within the hexagonal grid to reach the target cell from the base cell.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Handle Base Cell: If the resolution is 0 (base cell), directly set the base cell in the index.&lt;/li&gt;
&lt;pre&gt;&lt;code&gt;// Convert IJK to Direction Bits
faceIJK.coord = directions_bits_from_ijk(faceIJK.coord, resolution)

// Set the Base Cell
base_cell = get_base_cell(faceIJK)
bits = set_base_cell(bits, base_cell)
&lt;/code&gt;&lt;/pre&gt;
&lt;li&gt;Build from Finest Resolution Up and Set Base Cell: Convert IJK coordinates to direction bits starting from the finest resolution (r), updating the index progressively. Identify and set the correct base cell for the given IJK coordinates.&lt;/li&gt;
&lt;pre&gt;&lt;code&gt;// Handle Pentagon Cells
IF base_cell.is_pentagon() THEN
    IF first_axe(bits) == Direction.K THEN
        // Check for a CW/CCW offset face (default is CCW).
        IF base_cell.is_cw_offset(faceIJK.face) THEN
            bits = rotate60(bits, 1, CW)
        ELSE
            bits = rotate60(bits, 1, CCW)
        END IF
    END IF
    FOR i = 0 TO rotation_count DO
        bits = pentagon_rotate60(bits, CCW)
    END FOR
ELSE
    bits = rotate60(bits, rotation_count, CCW)
END IF
&lt;/code&gt;&lt;/pre&gt;
&lt;li&gt;Handle Pentagon Cells: Apply necessary rotations if the base cell is a pentagon to ensure the correct orientation and avoid the missing k-axes subsequence (if the direction bits indicate a move along the &lt;code&gt;k-axis&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since each base cell can be oriented differently (&lt;a href=&quot;#1-3-h3-grid-system&quot;&gt;Section 1.3&lt;/a&gt;) on the icosahedron&apos;s faces, rotations are needed to standardize these orientations. &lt;code&gt;rotation_count&lt;/code&gt; refers to the number of 60-degree rotations that need to be applied to the H3 cell index to align it with the canonical orientation of the base cell (also &lt;a href=&quot;https://h3geo.org/docs/core-library/latLngToCellDesc&quot; target=&quot;_blank&quot;&gt;refer&lt;/a&gt;).&lt;/p&gt;


&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3&gt;2.6. Official H3 library&lt;/h3&gt;
&lt;p&gt;Here&apos;s a Java snippet using the official H3 library provided by Uber:&lt;/p&gt;
&lt;details open=&quot;&quot; class=&quot;code-container&quot;&gt;&lt;summary class=&quot;p&quot;&gt;2.7a. Official H3 - Snippet&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;import com.uber.h3core.H3Core;

public class H3Index {
    public static void main(String[] args) throws Exception {
        H3Core h3 = H3Core.newInstance();
        double lat = 37.7749;
        double lon = -122.4194;
        int resolution = 9;

        long h3Index = h3.geoToH3(lat, lon, resolution);
        System.out.println(Long.toHexString(h3Index));
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;


&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;3. H3 - Conclusion&lt;/summary&gt;
&lt;p&gt;So far, in the Spatial Index Series, we have seen the use of space-filling curves and their application in grid systems like Geohash and S2. Finally, we explored Uber&apos;s H3, which falls under grid systems and more specifically relies on tessellation. By now, it&apos;s likely clear that H3 indexes are not directly queryable on the database by ranges or prefixes, but they have more importance towards the accuracy of filling a polygon, nearby search by radius, high resolution, and many more.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/spatial-index/h3_level_0_1.png&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 16: H3 grid segmentation (Level 0 and Level 1)&lt;/p&gt;

&lt;p&gt;If you missed the series, it starts with &lt;a href=&quot;/spatial-index-space-filling-curve&quot;&gt;Spatial Index: Space-Filling Curves&lt;/a&gt;, followed by &lt;a href=&quot;/spatial-index-grid-system&quot;&gt;Spatial Index: Grid Systems&lt;/a&gt;, and finally, the current post, &lt;a href=&quot;#spatial-index-tessellation&quot;&gt;Spatial Index: Tessellation&lt;/a&gt;.&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot;&gt;4. References&lt;/summary&gt;
&lt;pre style=&quot;max-height: 300px&quot;&gt;&lt;code&gt;1. Uber Technologies, Inc., &quot;H3: A Hexagonal Hierarchical Spatial Index,&quot; GitHub. [Online]. Available: https://github.com/uber/h3.
2. Wikipedia, &quot;Graticule,&quot; [Online]. Available: https://en.wikipedia.org/wiki/Graticule.
3. Microsoft, &quot;QuadKey,&quot; Microsoft Docs. [Online]. Available: https://learn.microsoft.com/en-us/bingmaps/articles/bing-maps-tile-system.
4. Wikipedia, &quot;Geohash,&quot; [Online]. Available: https://en.wikipedia.org/wiki/Geohash.
5. Google, &quot;Google S2 Geometry Library,&quot; [Online]. Available: https://s2geometry.io/.
6. Wikipedia, &quot;Icosahedron,&quot; [Online]. Available: https://en.wikipedia.org/wiki/Icosahedron.
7. Wikipedia, &quot;Dot product,&quot; [Online]. Available: https://en.wikipedia.org/wiki/Dot_product.
8. Wikipedia, &quot;Basis vectors,&quot; [Online]. Available: https://en.wikipedia.org/wiki/Basis_(linear_algebra).
9. Wikipedia, &quot;3D Cartesian coordinates,&quot; [Online]. Available: https://en.wikipedia.org/wiki/Cartesian_coordinate_system.
10. A. N. Adimurthy, &quot;Spatial Index: Tessellation,&quot; PyBlog. [Online]. Available: https://www.pyblog.xyz/spatial-index-tessellation.
11. Wikipedia, &quot;Conceptualization of a Cartogram,&quot; [Online]. Available: https://en.wikipedia.org/wiki/Cartogram.
12. Wikipedia, &quot;Golden ratio,&quot; [Online]. Available: https://en.wikipedia.org/wiki/Golden_ratio.
13. Wikipedia, &quot;Icosahedron vertices,&quot; [Online]. Available: https://en.wikipedia.org/wiki/Icosahedron#Vertices.
14. Wikipedia, &quot;H3: A Hexagonal Hierarchical Spatial Index,&quot; [Online]. Available: https://en.wikipedia.org/wiki/H3_(spatial_index).
15. Wikipedia, &quot;Dymaxion map,&quot; [Online]. Available: https://en.wikipedia.org/wiki/Dymaxion_map.
16. K. Sahr, &quot;Geodesic Discrete Global Grid Systems,&quot; Southern Oregon University. [Online]. Available: https://webpages.sou.edu/~sahrk/sqspc/pubs/gdggs03.pdf.
17. D. F. Marble, &quot;The Fundamental Data Structures for Implementing Digital Tessellation,&quot; University of Edinburgh. [Online]. Available: https://www.geos.ed.ac.uk/~gisteac/gis_book_abridged/files/ch36.pdf.
18. J. Castner, &quot;The Application of Tessellation in Geographic Data Handling,&quot; Semantic Scholar. [Online]. Available: https://pdfs.semanticscholar.org/feb2/3e69e19875817848ac8694b15f58d2ef52b0.pdf.
19. &quot;Hexagonal Tessellation and Its Application in Geographic Information Systems,&quot; YouTube. [Online]. Available: https://www.youtube.com/watch?v=wDuKeUkNLkQ&amp;amp;list=PL0HGds8aHQsAYm86RzQdZtFFeLpIOjk00.
20. Hydronium Labs. &quot;h3o: A safer, faster, and more flexible H3 library written in Rust.&quot; GitHub Repository. Available: https://github.com/HydroniumLabs/h3o/tree/master.
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;</content><author><name>Adesh Nalpet Adimurthy</name></author><category term="System Wisdom" /><category term="Database" /><category term="Spatial Index" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pyblog.xyz/assets/featured/webp/space-tessellation.webp" /><media:content medium="image" url="https://pyblog.xyz/assets/featured/webp/space-tessellation.webp" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Spatial Index: Grid Systems</title><link href="https://pyblog.xyz/spatial-index-grid-system" rel="alternate" type="text/html" title="Spatial Index: Grid Systems" /><published>2024-06-12T00:00:00+00:00</published><updated>2024-06-12T00:00:00+00:00</updated><id>https://pyblog.xyz/spatial-index-grid-system</id><content type="html" xml:base="https://pyblog.xyz/spatial-index-grid-system">&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/featured/webp/space-grids.webp&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This post is a continuation of &lt;a href=&quot;/spatial-index-space-filling-curve&quot;&gt;Stomping Grounds: Spatial Indexes&lt;/a&gt;, but don’t worry if you missed the first part—you’ll still find plenty of new insights right here.&lt;/p&gt;

&lt;h3&gt;3. Geohash&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Geohash&quot; target=&quot;_blank&quot;&gt;Geohash&lt;/a&gt;: Invented in 2008 by Gustavo Niemeyer, encodes a geographic location into a short string of letters and digits. It&apos;s a hierarchical spatial data structure that subdivides space into buckets of grid shape using a Z-order curve (&lt;a href=&quot;/spatial-index-space-filling-curve#2-space-filling-curves&quot;&gt;Section 2.&lt;/a&gt;).&lt;/p&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;3.1. Geohash - Intuition&lt;/summary&gt;

&lt;p&gt;Earth is round or more accurately, an ellipsoid. Map projection is a set of transformations represent the globe on a plane. In a map projection. Coordinates (latitude and longitude) of locations from the surface of the globe are transformed to coordinates on a plane. And GeoHash Uses &lt;a href=&quot;https://en.wikipedia.org/wiki/Equirectangular_projection&quot; target=&quot;_blank&quot;&gt;Equirectangular projection&lt;/a&gt;&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image&quot; src=&quot;./assets/posts/spatial-index/projection.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 21: Equirectangular projection/ Equidistant Cylindrical Projection&lt;/p&gt;

&lt;p&gt;The core of GeoHash is just an clever use of Z-order curves. Split the map-projection (rectangle) into 2 equal rectangles, each identified by unique bit strings.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-90&quot; src=&quot;./assets/posts/spatial-index/geohash-level-0.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 22: GeoHash Level 1 - Computation&lt;/p&gt;

&lt;p&gt;Observation: the divisions along X and Y axes are interleaved between bit strings. For example: an arbitrary bit string &lt;code&gt;01110 01011 00000&lt;/code&gt;, follows:&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image&quot; src=&quot;./assets/posts/spatial-index/geohash-bit-interleave.svg&quot; /&gt;

&lt;p&gt;By futher encoding this to Base32 (&lt;code&gt;0123456789bcdefghjkmnpqrstuvwxyz&lt;/code&gt;), we map a unique string to a quadrant in a grid and quadrants that share the same prefix are closer to each other; e.g. &lt;code&gt;000000&lt;/code&gt; and &lt;code&gt;000001&lt;/code&gt;. By now we know that interleaving trace out a Z-order curve.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-90&quot; src=&quot;./assets/posts/spatial-index/geohash-z-order.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 23: GeoHash Level 1 - Z-Order Curve&lt;/p&gt;

&lt;p&gt;Higher levels (higher order z-curves) lead to higher precision. The geohash algorithm can be iteratively repeated for higher precision. That&apos;s one cool property of geohash, adding more characters increase precision of the location.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-80&quot; src=&quot;./assets/posts/spatial-index/geohash-level-1.svg&quot; /&gt; 
&lt;img class=&quot;center-image-0 center-image-80&quot; src=&quot;./assets/posts/spatial-index/geohash-level-2.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 24: GeoHash Level 2&lt;/p&gt;

&lt;p&gt;Despite the easy implementation and wide usage of geohash, it inherits the disadvantages of Z-order curves (&lt;a href=&quot;/spatial-index-space-filling-curve#2-5-z-order-curve-implementation&quot;&gt;Section 2.5&lt;/a&gt;): weakly preserved latitude-longitude proximity; does not always guarantee that locations that are physically close are also close on the Z-curve. &lt;/p&gt;

&lt;p&gt;Adding on to it, is the use of &lt;a href=&quot;https://en.wikipedia.org/wiki/Tissot%27s_indicatrix&quot; target=&quot;_blank&quot;&gt;equirectangular projection&lt;/a&gt;, where the division of the map into equal subspaces leads to unequal/disproportional surface areas, especially near the poles (northern and southern hemisphere). However, there are alternatives such as &lt;a href=&quot;https://www.researchgate.net/publication/328727378_GEOHASH-EAS_-_A_MODIFIED_GEOHASH_GEOCODING_SYSTEM_WITH_EQUAL-AREA_SPACES&quot; target=&quot;_blank&quot;&gt;Geohash-EAS&lt;/a&gt; (Equal-Area Spaces).&lt;/p&gt;
&lt;/details&gt;
&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;3.2. Geohash - Implementation&lt;/summary&gt;
&lt;p&gt;To Convert a geographical location (latitude, longitude) into a concise string of characters and vice versa:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Convert latitude and longitude to a binary strings.&lt;/li&gt;
&lt;li&gt;Interleave the binary strings of latitude and longitude.&lt;/li&gt;
&lt;li&gt;Geohash: Convert the interleaved binary string into a base32 string.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;p&quot;&gt;3.2a. Geohash Encoder - Snippet&lt;/summary&gt;

&lt;pre&gt;&lt;code&gt;public class GeohashEncoder {

    public static String encodeGeohash(double latitude, double longitude, int precision) {
        // 1. Convert Lat and Long into a binary string based on the range.
        String latBin = convertToBinary(latitude, -90, 90, precision * 5 / 2);
        String lonBin = convertToBinary(longitude, -180, 180, precision * 5 / 2);

        // 2. Interweave the binary strings.
        String interwovenBin = interweave(lonBin, latBin);

        // 3. Converts a binary string to a base32 geohash.
        String geohash = binaryToBase32(interwovenBin);

        return geohash.substring(0, precision);
    }

    private static String convertToBinary(double value, double min, double max, int precision) {
        StringBuilder binaryStr = new StringBuilder();
        for (int i = 0; i &amp;lt; precision; i++) {
            double mid = (min + max) / 2;
            if (value &amp;gt;= mid) {
                binaryStr.append(&apos;1&apos;);
                min = mid;
            } else {
                binaryStr.append(&apos;0&apos;);
                max = mid;
            }
        }
        return binaryStr.toString();
    }

    private static String interweave(String str1, String str2) {
        StringBuilder interwoven = new StringBuilder();
        for (int i = 0; i &amp;lt; str1.length(); i++) {
            interwoven.append(str1.charAt(i));
            interwoven.append(str2.charAt(i));
        }
        return interwoven.toString();
    }

    private static String binaryToBase32(String binaryStr) {
        String base32Alphabet = &quot;0123456789bcdefghjkmnpqrstuvwxyz&quot;;
        StringBuilder base32Str = new StringBuilder();
        for (int i = 0; i &amp;lt; binaryStr.length(); i += 5) {
            String chunk = binaryStr.substring(i, Math.min(i + 5, binaryStr.length()));
            int decimalVal = Integer.parseInt(chunk, 2);
            base32Str.append(base32Alphabet.charAt(decimalVal));
        }
        return base32Str.toString();
    }

    public static void main(String[] args) {
        double latitude = 37.7749;
        double longitude = -122.4194;
        int precision = 5;
        String geohash = encodeGeohash(latitude, longitude, precision);
        System.out.println(&quot;Geohash: &quot; + geohash);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;3.3. Geohash - Conclusion&lt;/summary&gt;
&lt;p&gt;Similar to &lt;a href=&quot;/spatial-index-space-filling-curve#2-7-z-order-curve-and-hilbert-curve-conclusion&quot;&gt;Section 2.7&lt;/a&gt; (Indexing the Z-values); Geohashes convert latitude and longitude into a single, sortable string, simplifying spatial data management. A &lt;a href=&quot;/b-tree&quot;&gt;B-trees&lt;/a&gt; or search tree such as GiST/SP-GiST (Generalized Search Tree) index are commonly used for geohash indexing in databases.&lt;/p&gt;

&lt;p&gt;Prefix Search: Nearby locations share common geohash prefixes, enabling efficient filtering of locations by performing prefix searches on the geohash column&lt;/p&gt;

&lt;p&gt;Neighbor Searches: Generate geohashes for a target location and its neighbors to quickly retrieve nearby points. Which also extends to Area Searches: Calculate geohash ranges that cover a specific area and perform range queries to find all relevant points within that region.&lt;/p&gt;

&lt;p&gt;Popular databases such as &lt;a href=&quot;https://clickhouse.com/docs/en/sql-reference/functions/geo/geohash&quot; target=&quot;_blank&quot;&gt;ClickHouse&lt;/a&gt;, &lt;a href=&quot;https://dev.mysql.com/doc/refman/8.4/en/spatial-geohash-functions.html&quot; target=&quot;_blank&quot;&gt;MySQL&lt;/a&gt;, &lt;a href=&quot;https://postgis.net/docs/ST_GeoHash.html&quot; target=&quot;_blank&quot;&gt;PostGIS&lt;/a&gt;, &lt;a href=&quot;https://cloud.google.com/bigquery/docs/reference/standard-sql/geography_functions#st_geohash&quot; target=&quot;_blank&quot;&gt;BigQuery&lt;/a&gt;, &lt;a href=&quot;https://docs.aws.amazon.com/redshift/latest/dg/ST_GeoHash-function.html&quot; target=&quot;_blank&quot;&gt;RedShift&lt;/a&gt; and many others offer built-in geohash function. And many variations have been developed, such as the &lt;a href=&quot;https://github.com/yinqiwen/geohash-int&quot; target=&quot;_blank&quot;&gt;64-bit Geohash&lt;/a&gt; and &lt;a href=&quot;https://ntnuopen.ntnu.no/ntnu-xmlui/handle/11250/2404058&quot; target=&quot;_blank&quot;&gt;Hilbert-Geohash&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Interactive Geohash Visualization: &lt;a href=&quot;/geohash&quot; target=&quot;_blank&quot;&gt;/geohash&lt;/a&gt;&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;h3&gt;4. Google S2&lt;/h3&gt;
&lt;p&gt;&lt;/p&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;4.1. S2 - Intuition&lt;/summary&gt;

&lt;p&gt;Google&apos;s S2 library was released more than 10 years ago and didn&apos;t exactly the get the attention it deserved, much later in 2017, Google announced the release of open-source C++ &lt;a href=&quot;https://github.com/google/s2geometry&quot; target=&quot;_blank&quot;&gt;s2geometry library&lt;/a&gt;. With the use of Hilbert Curve (&lt;a href=&quot;/spatial-index-space-filling-curve#2-2-hilbert-curve-intuition&quot;&gt;Section 2.2&lt;/a&gt;) and cube face (spherical) projection instead of geohash&apos;s Z-order curve and equirectangular projection; S2 addresses (to an extent) the large jumps (&lt;a href=&quot;/spatial-index-space-filling-curve#2-5-z-order-curve-implementation&quot;&gt;Section 2.5&lt;/a&gt;) problem with Z-order curves and disproportional surface areas associated with equirectangular projection.&lt;/p&gt;

&lt;p&gt;The core of S2 is the hierarchical decomposition of the sphere into &quot;cells&quot;; done using a &lt;a href=&quot;/quadtree&quot; target=&quot;_blank&quot;&gt;Quad-tree&lt;/a&gt;, where a quadrant is recursively subdivided into four equal sub-cells and the use of Hilbet Curve goes hand-in-hand - runs across the centers of the quad-tree’s leaf nodes.&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;4.2. S2 - Implementation&lt;/summary&gt;

&lt;p&gt;The overview of solution is to:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;Enclose sphere in cube&lt;/li&gt;
    &lt;li&gt;Project point(s) &lt;code&gt;p&lt;/code&gt; onto the cube&lt;/li&gt;
    &lt;li&gt;Build a quad-tree/hilbert-curve on each cube face (6 faces)&lt;/li&gt;
    &lt;li&gt;Assign ID to the quad-tree cell that contains the projection of point(s) &lt;code&gt;p&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Starting with the input &lt;a href=&quot;https://en.wikipedia.org/wiki/Geographic_coordinate_system#Latitude_and_longitude&quot; target=&quot;_blank&quot;&gt;co-ordinates&lt;/a&gt;, latitude (Degrees: -90° to +90°. Radians: -π/2 to π/2) and longitude (-180° to +180°. Radians: 0 to 2π). And &lt;a href=&quot;https://en.wikipedia.org/wiki/World_Geodetic_System&quot; target=&quot;_blank&quot;&gt;WGS84&lt;/a&gt; is a commmonly standard used in &lt;a href=&quot;https://en.wikipedia.org/wiki/Earth-centered,_Earth-fixed_coordinate_system&quot; target=&quot;_blank&quot;&gt;geocentric coordinate system&lt;/a&gt;.&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3&gt;4.2.1. (Lat, Long) to (X,Y,Z)&lt;/h3&gt;

&lt;p&gt;Covert &lt;code&gt;p = (lattitude,longitude) =&amp;gt; (x,y,z)&lt;/code&gt; XYZ co-ordinate system (&lt;code&gt;x = [-1.0, 1.0], y = [-1.0, 1.0], z = [-1.0, -1.0]&lt;/code&gt;), based on coordinates on the unit sphere (unit radius), which is similar to &lt;a href=&quot;https://en.wikipedia.org/wiki/Earth-centered,_Earth-fixed_coordinate_system&quot; target=&quot;_blank&quot;&gt;Earth-centered, Earth-fixed coordinate system&lt;/a&gt;.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-80&quot; src=&quot;./assets/posts/spatial-index/ecef.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 25: (lat, long) to (x, y, z) Transformation with ECEF&lt;/p&gt;

&lt;p&gt;Where, &lt;code&gt;(x, y, z)&lt;/code&gt;: X-axis at latitude 0°, longitude 0° (equator and prime meridian intersection), Y-axis at latitude 0°, longitude 90° (equator and 90°E meridian intersection), Z-axis at latitude 90° (North Pole), Altitude (&lt;code&gt;PM&lt;/code&gt; on Figure 25) = Height to the reference ellipsoid/Sphere (Zero for a Round Planet approximation)&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3&gt;4.2.2. (X,Y,Z) to (Face,U,V)&lt;/h3&gt;

&lt;p&gt;To map &lt;code&gt;(x,y,z)&lt;/code&gt; to &lt;code&gt;(face, u,v)&lt;/code&gt;, each of the six faces of the cube is projected onto the sphere. The process is similar to &lt;a href=&quot;https://en.wikipedia.org/wiki/UV_mapping&quot; target=&quot;_blank&quot;&gt;UV Mapping&lt;/a&gt;: to project 3D model surface into a 2D coordinate space. where &lt;code&gt;u&lt;/code&gt; and &lt;code&gt;v&lt;/code&gt; denote the axes of the 2D plane. In this case, &lt;code&gt;U,V&lt;/code&gt; represent the location of a point on one face of the cube.&lt;/p&gt;

&lt;p&gt;The projection can simply be imagined as a unit sphere circumscribed by a cube. And a ray is emitted from the center of the sphere to obtain the projection of the point on the sphere to the 6 faces of the cube, that is, the sphere is projected into a cube.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image&quot; src=&quot;./assets/posts/spatial-index/s2-cell-step-1-2.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 26: (lat, long) to (x, y, z) and (x, y, z) to (face, u, v)&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;face&lt;/code&gt; denotes which of the 6 (0 to 5) cube faces a point on the sphere is mapped onto. Figure 27, shows the 6 faces of the cube (&lt;a href=&quot;https://en.wikipedia.org/wiki/Cube_mapping&quot; target=&quot;_blank&quot;&gt;cube mapping&lt;/a&gt;) after the projection. For a unit-sphere, for each face, the point &lt;code&gt;u,v = (0,0)&lt;/code&gt; represent the center of the face.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-100&quot; src=&quot;./assets/posts/spatial-index/s2-globe.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 27: Cube Face (Spherical) Projection&lt;/p&gt;

&lt;p&gt;The evident problem here is that, the linear projection leads to same-area cells on the cube having different sizes on the sphere (Length and Area Distortion), with the ratio of highest to lowest area of &lt;code&gt;5.2&lt;/code&gt; (areas on the cube can be up to 5.2 times longer or shorter than the corresponding distances on the sphere).&lt;/p&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;p&quot;&gt;4.2.2a. S2 FaceXYZ to UV - Snippet&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;public static class Vector3 {
    public double x;
    public double y;
    public double z;

    public Vector3(double x, double y, double z) {
        this.x = x;
        this.y = y;
        this.z = z;
    }
}

public static int findFace(Vector3 r) {
    double absX = Math.abs(r.x);
    double absY = Math.abs(r.y);
    double absZ = Math.abs(r.z);

    if (absX &amp;gt;= absY &amp;amp;&amp;amp; absX &amp;gt;= absZ) {
        return r.x &amp;gt; 0 ? 0 : 3;
    } else if (absY &amp;gt;= absX &amp;amp;&amp;amp; absY &amp;gt;= absZ) {
        return r.y &amp;gt; 0 ? 1 : 4;
    } else {
        return r.z &amp;gt; 0 ? 2 : 5;
    }
}

public static double[] validFaceXYZToUV(int face, Vector3 r) {
    switch (face) {
        case 0:
            return new double[]{r.y / r.x, r.z / r.x};
        case 1:
            return new double[]{-r.x / r.y, r.z / r.y};
        case 2:
            return new double[]{-r.x / r.z, -r.y / r.z};
        case 3:
            return new double[]{r.z / r.x, r.y / r.x};
        case 4:
            return new double[]{r.z / r.y, -r.x / r.y};
        default:
            return new double[]{-r.y / r.z, -r.x / r.z};
    }
}

public static void main(String[] args) {
    Vector3 r = new Vector3(1.0, 2.0, 3.0);
    int face = 0;
    double[] uv = validFaceXYZToUV(face, r);
    System.out.println(&quot;u: &quot; + uv[0] + &quot;, v: &quot; + uv[1]);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;p&gt;The Cube &lt;code&gt;Face&lt;/code&gt; is the largest absolute X,Y,Z component, when component is -ve, back faces are used.&lt;/p&gt;
&lt;img class=&quot;center-image-0 center-image-60&quot; src=&quot;./assets/posts/spatial-index/s2-xyz-uv.svg&quot; /&gt; 
&lt;p&gt;Face and XYZ is mapped to UV by using the other two X, Y, Z components (other than largest component of face) and diving it by the largest component, a value between &lt;code&gt;[-1, 1]&lt;/code&gt;. Additionally, some faces of the cube are transposed (-ve) to produce the single continuous hilbert curve on the cube.&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3&gt;4.2.3. (Face,U,V) to (Face,S,T)&lt;/h3&gt;

&lt;p&gt;The ST coordinate system is an extension of UV with an additional non-linear transformation layer to address the (Area Preservation) disproportionate sphere surface-area to cube cell mapping. Without which, cells near the cube face edges would be smaller than those near the cube face centers.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-80&quot; src=&quot;./assets/posts/spatial-index/s2-cell-step-3.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 28: (u, v) to (s, t)&lt;/p&gt;

&lt;p&gt;S2 uses Quadratic projection for &lt;code&gt;(u,v)&lt;/code&gt; =&amp;gt; &lt;code&gt;(s,t)&lt;/code&gt;. Comparing &lt;code&gt;tan&lt;/code&gt; and &lt;code&gt;quadratic&lt;/code&gt; projections: The tan projection has the least Area/Distance Distortion. However, quadratic projection, which is an approximation of the tan projection - is much faster and almost as good as tangent.&lt;/p&gt;
&lt;table&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;/td&gt;
            &lt;td&gt;Area Ratio&lt;/td&gt;
            &lt;td&gt;Cell → Point (µs)&lt;/td&gt;
            &lt;td&gt;Point → Cell (µs)&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Linear&lt;/td&gt;
            &lt;td&gt;5.20&lt;/td&gt;
            &lt;td&gt;0.087&lt;/td&gt;
            &lt;td&gt;0.085&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Tangent&lt;/td&gt;
            &lt;td&gt;1.41&lt;/td&gt;
            &lt;td&gt;0.299&lt;/td&gt;
            &lt;td&gt;0.258&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr style=&quot;background-color: rgb(213, 232, 212);&quot;&gt;
            &lt;td&gt;Quadratic&lt;/td&gt;
            &lt;td&gt;2.08&lt;/td&gt;
            &lt;td&gt;0.096&lt;/td&gt;
            &lt;td&gt;0.108&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/table&gt;

&lt;p&gt;&lt;code&gt;Cell → Point&lt;/code&gt; and &lt;code&gt;Point → Cell&lt;/code&gt; represents the transformation from (U, V) to (S, T) coordinates and vice versa.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-90&quot; src=&quot;./assets/posts/spatial-index/s2-uv-st-face-0.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 29: (face, u, v) to (face, s, t); for face = 0&lt;/p&gt;

&lt;p&gt;For the quadratic transformation: Apply a square root transformation; sqrt(1 + 3 * u) and to maintain the uniformity of the grid cells&lt;/p&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;p&quot;&gt;4.2.3a. S2 UV to ST - Snippet&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;public static double uvToST(double u) {
    if (u &amp;gt;= 0) {
        return 0.5 * Math.sqrt(1 + 3 * u);
    } else {
        return 1 - 0.5 * Math.sqrt(1 - 3 * u);
    }
}

public static void main(String[] args) {
    // (u, v) values in the range [-1, 1]
    double u1 = 0.5;
    double v1 = -0.5;
    
    // Convert (u, v) to (s, t)
    double s1 = uvToST(u1);
    double t1 = uvToST(v1);

    System.out.println(&quot;For (u, v) = (&quot; + u1 + &quot;, &quot; + v1 + &quot;):&quot;);
    System.out.println(&quot;s: &quot; + s1);
    System.out.println(&quot;t: &quot; + t1);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3&gt;4.2.4. (Face,S,T) to (Face,I,J)&lt;/h3&gt;

&lt;p&gt;The IJ coordinates are discretized ST coordinates and divides the ST plane into &lt;code&gt;2&lt;sup&gt;30&lt;/sup&gt; × 2&lt;sup&gt;30&lt;/sup&gt;&lt;/code&gt;, i.e. the i and j coordinates in S2 range from &lt;code&gt;0 to 2&lt;sup&gt;30&lt;/sup&gt; - 1&lt;/code&gt;. And represent the two dimensions of the leaf-cells (lowest-level cells) on a cube face.&lt;/p&gt;

&lt;p&gt;Why 2&lt;sup&gt;30&lt;/sup&gt;? The i and j coordinates are each represented using 30 bits, which is &lt;code&gt;2&lt;sup&gt;30&lt;/sup&gt;&lt;/code&gt; distinct values for both i and j coordinates (every cm² of the earth), this large range allows precise positioning within each face of the cube (high spatial resolution). The total number of unique cells is &lt;code&gt;6 x (2&lt;sup&gt;30&lt;/sup&gt; × 2&lt;sup&gt;30&lt;/sup&gt;)&lt;/code&gt;&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-100&quot; src=&quot;./assets/posts/spatial-index/s2-st-ij.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 30: (face, s, t) to (face, i, j); for face = 0&lt;/p&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;p&quot;&gt;4.2.4a. S2 ST to IJ - Snippet&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;public static int stToIj(double s) {
  return Math.max(
    0, Math.min(1073741824 - 1, (int) Math.round(1073741824 * s))
  );
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3&gt;4.2.5. (Face,I,J) to S2 Cell ID&lt;/h3&gt;
&lt;p&gt;The hierarchical sub-division of each cube face into 4 equal quadrants calls for Hilbert Space-Filling Curve (&lt;a href=&quot;/spatial-index-space-filling-curve#2-2-hilbert-curve-intuition&quot;&gt;Section 2.2&lt;/a&gt;): to enumerate cells along a Hilbert space-filling curve.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-100&quot; src=&quot;./assets/posts/spatial-index/s2-ij-cell.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 31: (face, i, j) to Hilbert Curve Position&lt;/p&gt;

&lt;p&gt;Hilbert Curve preserves spatial locality, meaning, the values that are close on the cube face/surface, are numerically close in the Hilbert curve position (illustration in Figure 31 - Level 3).&lt;/p&gt;

&lt;p&gt;Transformation: The Hilbert curve transforms the IJ coordinate position on the cube face from 2D to 1D and is given by a &lt;code&gt;60 bit&lt;/code&gt; integer (&lt;code&gt;0 to 2&lt;sup&gt;60&lt;/sup&gt;&lt;/code&gt;).&lt;/p&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;p&quot;&gt;4.2.5a. S2 IJ to S2 Cell ID - Snippet&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;public class S2CellId {
    private static final long MAX_LEVEL = 30;
    private static final long POS_BITS = 2 * MAX_LEVEL + 1;
    private static final long FACE_BITS = 3;
    private static final long FACE_MASK = (1L &amp;lt;&amp;lt; FACE_BITS) - 1;
    private static final long POS_MASK = (1L &amp;lt;&amp;lt; POS_BITS) - 1;

    public static long faceIjToCellId(int face, int i, int j) {
        // Face Encoding
        long cellId = ((long) face) &amp;lt;&amp;lt; POS_BITS;
        // Loop from MAX_LEVEL - 1 down to 0
        for (int k = MAX_LEVEL - 1; k &amp;gt;= 0; --k) {
            // Hierarchical Position Encoding
            int mask = 1 &amp;lt;&amp;lt; k;
            long bits = (((i &amp;amp; mask) != 0) ? 1 : 0) &amp;lt;&amp;lt; 1 | (((j &amp;amp; mask) != 0) ? 1 : 0);
            cellId |= bits &amp;lt;&amp;lt; (2 * k);
        }
        return cellId;
    }

    public static void main(String[] args) {
        int face = 2; 
        int i = 536870912;
        int j = 536870912;

        long cellId = faceIjToCellId(face, i, j);
        System.out.println(&quot;S2 Cell ID: &quot; + cellId);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;p&gt;The &lt;b&gt;S2 Cell ID&lt;/b&gt; is represented by a &lt;code&gt;64-bit&lt;/code&gt; integer,&lt;/p&gt; 
&lt;ul&gt;
&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/spatial-index/s2-cell-id.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 32: (face, i, j) to S2 Cell ID&lt;/p&gt;
&lt;li&gt;the left &lt;code&gt;3 bits&lt;/code&gt; are used to represent the cube face &lt;code&gt;[0-5],&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;the next following &lt;code&gt;60 bits&lt;/code&gt; represents the Hilbert Curve position,&lt;/li&gt;
&lt;li&gt;with &lt;code&gt;[0-30]&lt;/code&gt; levels; two bits for every higher order/level, followed by a trailing &lt;code&gt;1&lt;/code&gt; bit, which is a marker to identify the level of the cell (by position).&lt;/li&gt;
&lt;li&gt;and the last digits are padded with 0s&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;fffpppp...pppppppp1  # Level 30 cell ID
fffpppp...pppppp100  # Level 29 cell ID
fffpppp...pppp10000  # Level 28 cell ID
...
...
...
fffpp10...000000000  # Level 1 cell ID
fff1000...000000000  # Level 0 cell ID
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice the position of trailing &lt;code&gt;1&lt;/code&gt; and padded &lt;code&gt;0&lt;/code&gt;s, correlated to the level.&lt;/p&gt;
&lt;hr class=&quot;hr&quot; /&gt;

&lt;p&gt;&lt;b&gt;S2 Tokens&lt;/b&gt; are a string representation of S2 Cell IDs (uint64), which can be more convenient for storage.&lt;/p&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;p&quot;&gt;4.2.5b. S2 Cell ID to S2 Token - Snippet&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;public static String cellIdToToken(long cellId) {
    // The zero token is encoded as &apos;X&apos; rather than as a zero-length string
    if (cellId == 0) {
        return &quot;X&quot;;
    }

    // Convert cell ID to a hex string and strip any trailing zeros
    String hexString = Long.toHexString(cellId).replaceAll(&quot;0*$&quot;, &quot;&quot;);
    return hexString;
}

public static void main(String[] args) {
    long cellId = 3383821801271328768L; // Given example value

    // Convert S2 Cell ID to S2 Token
    String token = cellIdToToken(cellId);

    System.out.println(&quot;S2 Cell ID: &quot; + cellId);
    System.out.println(&quot;S2 Token: &quot; + token);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;p&gt;It&apos;s similar to Geohash, however, prefixes from a high-order S2 token does not yield a parent lower-order token, because the trailing 1 bit in S2 cell ID wouldn&apos;t be set correctly. Convert S2 Cell ID to an S2 Token by encoding the ID into a base-16 (hexadecimal) string.&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;4.3. S2 - Conclusion&lt;/summary&gt;
&lt;p&gt;Google&apos;s S2 provides spatial indexing by using hierarchical decomposition of the sphere into cells through a combination of Hilbert curves and cube face (spherical) projection. This approach mitigates some of the spatial locality issues present in Z-order curves and offers more balanced surface area representations. S2&apos;s use of (face, u, v) coordinates, quadratic projection, and Hilbert space-filling curves ensures efficient and precise spatial indexing.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-100&quot; src=&quot;./assets/posts/spatial-index/s2-stats.svg&quot; /&gt;

&lt;p&gt;Closing with a strong pro and a con, S2 offers a high resolution of as low as &lt;code&gt;0.48 cm²&lt;/code&gt; cell size (level 30), but the number of cells required to cover a given polygon isn&apos;t the best. This makes it a good transition to talk about Uber&apos;s &lt;a href=&quot;https://www.uber.com/en-CA/blog/h3/&quot; target=&quot;_blank&quot;&gt;H3&lt;/a&gt;. The question is, &lt;a href=&quot;/cartograms-documentation#hexagonsvssquares&quot;&gt;Why Hexagons?&lt;/a&gt;&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot;&gt;3. References&lt;/summary&gt;

&lt;pre style=&quot;max-height: 300px&quot;&gt;&lt;code&gt;6. Christian S. Perone, &quot;Google’s S2, geometry on the sphere, cells and Hilbert curve,&quot; in Terra Incognita, 14/08/2015, https://blog.christianperone.com/2015/08/googles-s2-geometry-on-the-sphere-cells-and-hilbert-curve/. [Accessed: 12-Jun-2024].
7. B. Feifke, &quot;Geospatial Indexing Explained,&quot; Ben Feifke, Dec. 2022. [Online]. Available: https://benfeifke.com/posts/geospatial-indexing-explained/. [Accessed: 12-Jun-2024].
8. &quot;S2 Concepts,&quot; S2 Geometry Library Documentation, 2024. [Online]. Available: https://docs.s2cell.aliddell.com/en/stable/s2_concepts.html. [Accessed: 13-Jun-2024].
9. &quot;Geospatial Indexing: A Look at Google&apos;s S2 Library,&quot; CNIter Blog, Mar. 2023. [Online]. Available: https://cniter.github.io/posts/720275bd.html. [Accessed: 13-Jun-2024].
10. &quot;S2 Geometry Library,&quot; S2 Geometry, 2024. [Online]. Available: https://s2geometry.io/. [Accessed: 13-Jun-2024].
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;</content><author><name>Adesh Nalpet Adimurthy</name></author><category term="System Wisdom" /><category term="Database" /><category term="Spatial Index" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pyblog.xyz/assets/featured/webp/space-grids.webp" /><media:content medium="image" url="https://pyblog.xyz/assets/featured/webp/space-grids.webp" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Spatial Index: Space-Filling Curves</title><link href="https://pyblog.xyz/spatial-index-space-filling-curve" rel="alternate" type="text/html" title="Spatial Index: Space-Filling Curves" /><published>2024-06-11T00:00:00+00:00</published><updated>2024-06-11T00:00:00+00:00</updated><id>https://pyblog.xyz/spatial-index-space-filling-curve</id><content type="html" xml:base="https://pyblog.xyz/spatial-index-space-filling-curve">&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/featured/webp/spatio-temporal-index.webp&quot; /&gt;&lt;/p&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;0. Overview&lt;/summary&gt;
&lt;p&gt;Spatial data has grown (/is growing) rapidly thanks to web services tracking where and when users do things. Most applications add location tags and often allow users check in specific places and times. This surge is largely due to smartphones, which act as location sensors, making it easier than ever to capture and analyze this type of data.&lt;/p&gt;

&lt;p&gt;The goal of this post is to dive into the different spatial indexes that are widely used in both relational and non-relational databases. We&apos;ll look at the pros and cons of each type, and also discuss which indexes are the most popular today.&lt;/p&gt;

&lt;img class=&quot;center-image-0&quot; src=&quot;./assets/posts/spatial-index/spatial-index-types.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 0: Types of Spatial Indexes&lt;/p&gt;

&lt;p&gt;Spatial indexes fall into two main categories: space-driven and data-driven structures. Data-driven structures, like the R-tree family, are tailored to the distribution of the data itself. Space-driven structures include partitioning trees (kd-trees, quad-trees), space-filling curves (Z-order, Hilbert), and grid systems (H3, S2, Geohash), each partitioning space to optimize spatial queries. This classification isn&apos;t exhaustive, as many other methods cater to specific needs in spatial data management.&lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;1. Foundation&lt;/summary&gt;
&lt;p&gt;To understand the need for spatial indexes, or more generally, a way to index multi-dimensional data.&lt;/p&gt;
&lt;img class=&quot;center-image-40&quot; src=&quot;./assets/posts/spatial-index/no-sort-no-partition-table.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 1: Initial Table Structure&lt;/p&gt;
&lt;p&gt;Consider a table with the following fields: &lt;code&gt;device&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt;, and &lt;code&gt;Y&lt;/code&gt;, all of which are integers ranging from 1 to 4. Data is inserted into this table randomly by an external application.&lt;/p&gt;

&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/spatial-index/no-sort-no-partition-full-scan.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 2: Unpartitioned and Unsorted Table&lt;/p&gt;
&lt;p&gt;Currently, the table is neither partitioned nor sorted. As a result, the data is distributed across all files (8 files), each containing a mix of all ranges. This means all files are similar in nature. Running a query like &lt;code&gt;Device = 1 and X = 2&lt;/code&gt; requires a full scan of all files, which is inefficient.&lt;/p&gt;

&lt;img class=&quot;center-image-90&quot; src=&quot;./assets/posts/spatial-index/no-sort-full-scan.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 3: Partitioning by Device&lt;/p&gt;
&lt;p&gt;To optimize this, we partition the table by the &lt;code&gt;device&lt;/code&gt; field into 4 partitions: &lt;code&gt;Device = 1&lt;/code&gt;, &lt;code&gt;Device = 2&lt;/code&gt;, &lt;code&gt;Device = 3&lt;/code&gt;, and &lt;code&gt;Device = 4&lt;/code&gt;. Now, the same query (&lt;code&gt;Device = 1 and X = 2&lt;/code&gt;) only needs to scan the relevant partition. This reduces the scan to just 2 files.&lt;/p&gt;

&lt;img class=&quot;center-image-90&quot; src=&quot;./assets/posts/spatial-index/partial-scan-x.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 4: Sorting Data Within Partitions&lt;/p&gt;
&lt;p&gt;Further optimization can be achieved by sorting the data within each partition by the &lt;code&gt;X&lt;/code&gt; field. With this setup, each file in a partition holds a specific range of &lt;code&gt;X&lt;/code&gt; values. For example, one file in the &lt;code&gt;Device = 1&lt;/code&gt; partition hold &lt;code&gt;X = 1 to 2&lt;/code&gt;. This makes the query &lt;code&gt;Device = 1 and X = 2&lt;/code&gt; even more efficient.&lt;/p&gt;

&lt;img class=&quot;center-image-90&quot; src=&quot;./assets/posts/spatial-index/no-sort-full-scan-y.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 5: Limitation with Sorting on a Single Field&lt;/p&gt;
&lt;p&gt;However, if the query changes to &lt;code&gt;Device = 1 and Y = 2&lt;/code&gt;, the optimization is lost because the sorting was done on &lt;code&gt;X&lt;/code&gt; and not &lt;code&gt;Y&lt;/code&gt;. This means the query will still require scanning the entire partition for &lt;code&gt;Device = 1&lt;/code&gt;, bringing us back to a less efficient state.&lt;/p&gt;

&lt;p&gt;At this point, there&apos;s a clear need for efficiently partitioning 2-dimensional data. Why not use &lt;a href=&quot;/b-tree&quot;&gt;B-tree&lt;/a&gt; with a composite index? A composite index prioritizes the first column in the index, leading to inefficient querying for the second column. This leads us back to the same problem, particularly when both dimensions need to be considered simultaneously for efficient querying.&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;2. Space-Filling Curves&lt;/summary&gt;

&lt;p&gt;&lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt; from 1 to 4 on a 2D axis. The goal is to traverse the data and number them accordingly (the path). using Space-Filling Curves AKA squiggly lines.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-90&quot; src=&quot;./assets/posts/spatial-index/space-filling-trivial-details.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 6: Exploring Space-Filling Curve and Traversing the X-Y Axis&lt;/p&gt;

&lt;p&gt;Starting from &lt;code&gt;Y = 1&lt;/code&gt; and &lt;code&gt;X = 1&lt;/code&gt;, as we traverse up to &lt;code&gt;X = 1&lt;/code&gt; and &lt;code&gt;Y = 4&lt;/code&gt;, it&apos;s evident that there is no locality preservation (Lexicographical Order). The distance between points &lt;code&gt;(1, 4)&lt;/code&gt; and &lt;code&gt;(1, 3)&lt;/code&gt; is 6, a significant difference for points that are quite close to each other. Grouping this data into files keeps unrelated data together and ended up sorting by one column while ignoring the information in the other column (back to square one). i.e. &lt;code&gt;X = 2&lt;/code&gt; leads to a full scan.&lt;/p&gt;


&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;2.1. Z-Order Curve - Intuition&lt;/summary&gt;
&lt;p&gt;A recursive Z pattern, also known as the Z-order curve, is an effective way to preserve locality in many cases.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/spatial-index/z-order-types.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 7: Z-Order Curve Types&lt;/p&gt;
&lt;p&gt;The Z-order curve can take many shapes, depending on which coordinate goes first. The typical Z-shape occurs when the Y-coordinate goes first (most significant bit), and the upper left corner is the base. A mirror image Z-shape occurs when the Y-coordinate goes first and the lower left corner is the base. An N-shape occurs when the X-coordinate goes first and the lower left corner is the base.&lt;/p&gt;

&lt;p&gt;Z-order curve grows exponentially, and the next size is the second-order curve that has 2-bit sized dimensions. Duplicate the first-order curve four times and connect them together to form a continuous curve.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-90&quot; src=&quot;./assets/posts/spatial-index/z-order.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 8: Z-Order Curve&lt;/p&gt;

&lt;p&gt;Points &lt;code&gt;(1, 4)&lt;/code&gt; and &lt;code&gt;(1, 3)&lt;/code&gt; are separated by a single square. With 4 files based on this curve, the data is not spread out along a single dimension. Instead, the 4 files are clustered across both dimensions, making the data selective on both &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt; dimensions.&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;2.2. Hilbert Curve - Intuition&lt;/summary&gt;

&lt;p&gt;The Hilbert curve is another type of space-filling curve that serve a similar purpose, rather than using a Z-shaped pattern like the Z-order curve, it uses a gentler U-shaped pattern. When compared with the Z-order curve in Figure 9, it’s quite clear that the Hilbert curve always maintains the same distance between adjacent data points.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-90&quot; src=&quot;./assets/posts/spatial-index/hilbert-second-order.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 9: First Order and Second Order Hilbert Curve&lt;/p&gt;
&lt;p&gt;Hilbert curve also grows exponentially, to do so, duplicate the first-order curve and connect them. Additionally, some of the first-order curves are rotated to ensure that the interconnections are not larger than 1 point.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-90&quot; src=&quot;./assets/posts/spatial-index/hilbert-exponent.svg&quot; /&gt; 
&lt;p&gt;Comparing with the Z-curves (from Figure 8, higher-order in Figure 18), the Z-order curve is longer than the Hilbert curve at all levels, for the same area.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-90&quot; src=&quot;./assets/posts/spatial-index/hilbert-types.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 10: Hilbert Curve Types&lt;/p&gt;
&lt;p&gt;Although there are quite a lot of varaints of Hilbert curve, the common pattern is to rotate by 90 degrees and repeat the pattern in next higher order(s).&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-90&quot; src=&quot;./assets/posts/spatial-index/hilbert-curve.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 11: Hilbert Curve&lt;/p&gt;
&lt;p&gt;Hilbert curves traverse through the data, ensuring that multi-dimensional data points that are close together in 2D space remain close together along the 1D line or curve, thus preserving locality and enhancing query efficiency across both dimensions.&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;2.3. Z-Order Curve and Hilbert Curve - Comparison&lt;/summary&gt;

&lt;p&gt;Taking an example, if we query for &lt;code&gt;X = 3&lt;/code&gt;, we only need to search 2 of the files. Similarly, for &lt;code&gt;Y = 3&lt;/code&gt;, the search is also limited to 2 files in both Z-order and Hilbert Curves&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-100&quot; src=&quot;./assets/posts/spatial-index/z-order-curve-example.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 12: Z-Order Curve - Example&lt;/p&gt;

&lt;p&gt;Unlike a hierarchical sort on only one dimension, the data is selective across both dimensions, making the multi-dimensional search more efficient.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-100&quot; src=&quot;./assets/posts/spatial-index/hilbert-curve-example.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 13: Hilbert Curve - Example&lt;/p&gt;

&lt;p&gt;Although both the curves give a similar advantage, the main shortcoming with Z-order curve: it fails to maintain perfect data locality across all the data points in the curve. In Figure 12, notice the data points between index 8 and 9 are further apart. As the size of the Z-curve increases, so does the distance between such points that connect different parts of curve together.&lt;/p&gt;

&lt;p&gt;Hilbert curve is more preferred over the Z-order curve for ensuring better data locality and Z-order curve is still widely used because of it&apos;s simplicity.&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;2.4. Optimizing with Z-Values&lt;/summary&gt;

&lt;p&gt;In the examples so far, we have presumed that the &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt; values are dense, meaning that there is a value for every combination of &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt;. However, in real-world scenarios, data can be sparse, with many &lt;code&gt;X, Y&lt;/code&gt; combinations missing&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-80&quot; src=&quot;./assets/posts/spatial-index/3-partition-curves.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 14: Flexibility in Number of Files&lt;/p&gt;
&lt;p&gt;The number of files (4 in the prior examples) isn&apos;t necessarily dictated. Here&apos;s what 3 files would look like using both Z-order and Hilbert curves. The benefits still holds to an extent because of the space-filling curve, which efficiently clusters related data points.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-90&quot; src=&quot;./assets/posts/spatial-index/z-order-sparse.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 15: Optimizing with Z-Values&lt;/p&gt;
&lt;p&gt;To improve efficiency, we can use Z-values. If files are organized by Z-values, each file has a min-max Z-value range. Filters on &lt;code&gt;X&lt;/code&gt; and &lt;code&gt;Y&lt;/code&gt; can be transformed into Z-values, enabling efficient querying by limiting the search to relevant files based on their Z-value ranges.&lt;/p&gt;

&lt;img class=&quot;center-image-0&quot; src=&quot;./assets/posts/spatial-index/z-order-z-values.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 16: Efficient Querying with Min-Max Z-Values&lt;/p&gt;
&lt;p&gt;Consider a scenario where the min-max Z-values of 3 files are &lt;code&gt;1 to 5&lt;/code&gt;, &lt;code&gt;6 to 9&lt;/code&gt;, and &lt;code&gt;13 to 16&lt;/code&gt;. Querying by &lt;code&gt;2 ≤ X ≤ 3&lt;/code&gt; and &lt;code&gt;3 ≤ Y ≤ 4&lt;/code&gt; would initially require scanning 2 files. However, if we convert these ranges to their Z-value equivalent, which is &lt;code&gt;10 ≤ Z ≤ 15&lt;/code&gt;, we only need to scan one file, since the min-max Z-values are known.&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;2.5. Z-Order Curve - Implementation&lt;/summary&gt;

&lt;p&gt;So far, wkt, Z-ordering arranges the 2D pairs on a 1-dimensional line. More importantly, values that were close together in the 2D plane would still be close to each other on the Z-order line. The implementation goal is to derive Z-Values that preserves spatial locality from M-dimensional data-points (Z-ordering is not limited to 2-dimensional space and it can be abstracted to work in any number of dimensions)&lt;/p&gt;

&lt;p&gt;Z-order bit-interleaving is a technique that interleave bits of two or more values to create a 1-D value while spatial locality is preserved:&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-45&quot; src=&quot;./assets/posts/spatial-index/interleave.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 17: Bit Interleaving&lt;/p&gt;
&lt;p&gt;Example: 4-bit values &lt;code&gt;X = 10&lt;/code&gt;, &lt;code&gt;Y = 12&lt;/code&gt; on a 2D grid, &lt;code&gt;X = 1010&lt;/code&gt;, &lt;code&gt;Y = 1100&lt;/code&gt;, then interleaved value &lt;code&gt;Z = 1110 0100&lt;/code&gt; (&lt;code&gt;228&lt;/code&gt;)&lt;/p&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;p&quot;&gt;2.5a. Z-Order Curve - Snippet&lt;/summary&gt;

&lt;pre&gt;&lt;code&gt;public class ZOrderCurve {

    // Function to interleave bits of two integers x and y
    public static long interleaveBits(int x, int y) {
        long z = 0;
        for (int i = 0; i &amp;lt; 32; i++) {
            z |= (long)((x &amp;amp; (1 &amp;lt;&amp;lt; i)) &amp;lt;&amp;lt; i) | ((y &amp;amp; (1 &amp;lt;&amp;lt; i)) &amp;lt;&amp;lt; (i + 1));
        }
        return z;
    }

    // Function to compute the Z-order curve values for a list of points
    public static long[] zOrderCurve(int[][] points) {
        long[] zValues = new long[points.length];
        for (int i = 0; i &amp;lt; points.length; i++) {
            int x = points[i][0];
            int y = points[i][1];
            zValues[i] = interleaveBits(x, y);
        }
        return zValues;
    }

    public static void main(String[] args) {
        int[][] points = { {1, 2}, {3, 4}, {5, 6} };
        long[] zValues = zOrderCurve(points);

        System.out.println(&quot;Z-order values:&quot;);
        for (long z : zValues) {
            System.out.println(z);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/spatial-index/z-order-2d-plane.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 18: 2-D Z-Order Curve Space&lt;/p&gt;

&lt;p&gt;From the above Z-order keys, we see that points that are close to each other in the original space have close Z-order keys. For instance, points sharing the prefix &lt;code&gt;000&lt;/code&gt; in their Z-order keys are close in 2D space, while points with the prefix &lt;code&gt;110&lt;/code&gt; indicate greater distance.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/spatial-index/z-order-success.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 19: 2-D Z-Order Curve Space and a Query Region&lt;/p&gt;
&lt;p&gt;Now that we know how to calculate the z-order keys, we can use the z-order keys to define a range of values to read (reange-query), to do so, we have to find the lower and upper counds. For example: The query rectangle: &lt;code&gt;2 ≤ X ≤ 3&lt;/code&gt; to &lt;code&gt;4 ≤ Y ≤ 5&lt;/code&gt;, the lower bound is &lt;code&gt;Z-Order(X = 2, Y = 4) = 100100&lt;/code&gt; and upper bound is &lt;code&gt;(X = 3, Y = 5) = 100111&lt;/code&gt;, translates to Z-order values of &lt;code&gt;36&lt;/code&gt; and &lt;code&gt;39&lt;/code&gt;.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/spatial-index/z-order-danger.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 20: 2-D Z-Order Curve Space and a Query Region (The Problem)&lt;/p&gt;
&lt;p&gt;However, range queries based on Z-Order keys are not always present in a continuous Z path. For example: The query rectangle &lt;code&gt;1 ≤ X ≤ 3&lt;/code&gt; to &lt;code&gt;3 ≤ Y ≤ 4&lt;/code&gt;, the lower bound &lt;code&gt;Z-Order(X = 1, Y = 3) = 001011&lt;/code&gt; and upper bound is &lt;code&gt;(X = 3, Y = 4) = 100101&lt;/code&gt;, translates to Z-order values of &lt;code&gt;11 and 37&lt;/code&gt; - optimized using subranges.&lt;/p&gt;

&lt;p&gt;The Z-order curve weakly preserves latitude-longitude proximity, i.e. two locations that are close in physical distance are not guaranteed to be close following the Z-curve&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;2.6. Hilbert Curve - Implementation&lt;/summary&gt;
&lt;p&gt;From &lt;a href=&quot;#2-2-hilbert-curve-intuition&quot;&gt;Section 2.2&lt;/a&gt;, wkt: The Hilbert curve implementation converts 2D coordinates to a single scalar value that preserves spatial locality by recursively rotating and transforming the coordinate space.&lt;/p&gt;

&lt;p&gt;In the code snippet: The &lt;code&gt;xyToHilbert&lt;/code&gt; function computes this scalar value using bitwise operations, while the &lt;code&gt;hilbertToXy&lt;/code&gt; function reverses this process. This method ensures that points close in 2D space remain close in the 1D Hilbert curve index, making it useful for spatial indexing.&lt;/p&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;p&quot;&gt;2.6a. Hilbert Curve - Snippet&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;public class HilbertCurve {
    // Rotate/flip a quadrant appropriately
    private static void rot(int n, int[] x, int[] y, int rx, int ry) {
        if (ry == 0) {
            if (rx == 1) {
                x[0] = n - 1 - x[0];
                y[0] = n - 1 - y[0];
            }
            // Swap x and y
            int temp = x[0];
            x[0] = y[0];
            y[0] = temp;
        }
    }

    // Convert (x, y) to Hilbert curve distance
    public static int xyToHilbert(int n, int x, int y) {
        int d = 0;
        int[] ix = { x };
        int[] iy = { y };

        for (int s = n / 2; s &amp;gt; 0; s /= 2) {
            int rx = (ix[0] &amp;amp; s) &amp;gt; 0 ? 1 : 0;
            int ry = (iy[0] &amp;amp; s) &amp;gt; 0 ? 1 : 0;
            d += s * s * ((3 * rx) ^ ry);
            rot(s, ix, iy, rx, ry);
        }

        return d;
    }

    // Convert Hilbert curve distance to (x, y)
    public static void hilbertToXy(int n, int d, int[] x, int[] y) {
        int rx, ry, t = d;
        x[0] = y[0] = 0;
        for (int s = 1; s &amp;lt; n; s *= 2) {
            rx = (t / 2) % 2;
            ry = (t ^ rx) % 2;
            rot(s, x, y, rx, ry);
            x[0] += s * rx;
            y[0] += s * ry;
            t /= 4;
        }
    }

    public static void main(String[] args) {
        int n = 16; // size of the grid (must be a power of 2)
        int x = 5;
        int y = 10;
        int d = xyToHilbert(n, x, y);
        System.out.println(&quot;The Hilbert curve distance for (&quot; + x + &quot;, &quot; + y + &quot;) is: &quot; + d);

        int[] point = new int[2];
        hilbertToXy(n, d, point, point);
        System.out.println(&quot;The coordinates for Hilbert curve distance &quot; + d + &quot; are: (&quot; + point[0] + &quot;, &quot; + point[1] + &quot;)&quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;2.7. Z-Order Curve and Hilbert Curve - Conclusion&lt;/summary&gt;

&lt;p&gt;Usage: Insert data points and their Z-order keys/Hilbert Keys (let&apos;s call it Z and H keys) into a one-dimensional hierarchical index structure, such as a &lt;a href=&quot;/b-tree&quot;&gt;B-Tree&lt;/a&gt; or Quad-Tree. For range or nearest neighbor queries, convert the search criteria into Z/H keys or range of keys. After retrieval, further filter the results as necessary to remove any garbage values.&lt;/p&gt;

&lt;p&gt;To conclude: Space-Filling Curves such as Z-Order/Hilbert indexing is a powerful technique to query higher-dimensional data, especially as the data volumes grows. By combining bits from multiple dimensions into a single value, space-Filling Curves indexing preserves spatial locality, enabling efficient data indexing and retrieval.&lt;/p&gt;

&lt;p&gt;However, as seen in &lt;a href=&quot;#2-5-z-order-curve-implementation&quot;&gt;Section 2.5&lt;/a&gt;, large jumps along the Z-Order curve can affect certain types of queries (better with Hilbert curves &lt;a href=&quot;#2-2-hilbert-curve-intuition&quot;&gt;Section 2.2&lt;/a&gt;). The success of Z-Order indexing relies on the data&apos;s distribution and cardinality. Therefore, it is essential to evaluate the nature of the data, query patterns, performance needs and limitation(s) of indexing strategies.&lt;/p&gt;
&lt;/details&gt;

&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot;&gt;3. References&lt;/summary&gt;

&lt;pre style=&quot;max-height: 300px&quot;&gt;&lt;code&gt;1. &quot;Programming the Hilbert curve&quot; (American Institue of Physics (AIP) Conf. Proc. 707, 381 (2004)).
2. Wikipedia. “Z-order curve,” [Online]. Available: https://en.wikipedia.org/wiki/Z-order_curve.
3. Amazon Web Services, “Z-order indexing for multifaceted queries in Amazon DynamoDB – Part 1,” [Online]. Available: https://aws.amazon.com/blogs/database/z-order-indexing-for-multifaceted-queries-in-amazon-dynamodb-part-1/. [Accessed: 10-Jun-2024].
4. N. Chandra, “Z-order indexing for efficient queries in Data Lake,” Medium, 20-Sep-2021. [Online]. Available: https://medium.com/@nishant.chandra/. [Accessed: 10-Jun-2024]z-order-indexing-for-efficient-queries-in-data-lake-48eceaeb2320. [Accessed: 10-Jun-2024].
5. YouTube, “Z-order indexing for efficient queries in Data Lake,” [Online]. Available: https://www.youtube.com/watch?v=YLVkITvF6KU. [Accessed: 10-Jun-2024].
&lt;/code&gt;&lt;/pre&gt;

&lt;/details&gt;</content><author><name>Adesh Nalpet Adimurthy</name></author><category term="System Wisdom" /><category term="Database" /><category term="Spatial Index" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pyblog.xyz/assets/featured/webp/spatio-temporal-index.webp" /><media:content medium="image" url="https://pyblog.xyz/assets/featured/webp/spatio-temporal-index.webp" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Real-time insights: Telemetry Pipeline</title><link href="https://pyblog.xyz/telemetry-pipeline" rel="alternate" type="text/html" title="Real-time insights: Telemetry Pipeline" /><published>2024-06-07T00:00:00+00:00</published><updated>2024-06-07T00:00:00+00:00</updated><id>https://pyblog.xyz/telemetry-pipeline</id><content type="html" xml:base="https://pyblog.xyz/telemetry-pipeline">&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/featured/webp/telemetry-pipeline.webp&quot; /&gt;&lt;/p&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;0. Overview&lt;/summary&gt;
&lt;p&gt;&lt;/p&gt;
&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;0.1. Architecture&lt;/summary&gt;
&lt;p&gt;A &lt;a href=&quot;https://en.wikipedia.org/wiki/Telemetry&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;telemetry&lt;/a&gt; pipeline is a system that collects, ingests, processes, stores, and analyzes telemetry data (metrics, logs, traces) from various sources in real-time or near real-time to provide insights into the performance and health of applications and infrastructure.&lt;/p&gt;

&lt;img class=&quot;telemetry-barebone center-image-90&quot; src=&quot;./assets/posts/telemetry/telemetry-barebone.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 0: Barebone Telemetry Pipeline Architecture&lt;/p&gt;

&lt;p&gt;It typically involves tools like Telegraf for data collection, Kafka for ingestion, Flink for processing, and &lt;a href=&quot;https://cassandra.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Cassandra&lt;/a&gt; and &lt;a href=&quot;https://victoriametrics.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;VictoriaMetrics&lt;/a&gt; for storage and analysis.&lt;/p&gt;

&lt;img class=&quot;telemetry-architecture&quot; src=&quot;./assets/posts/telemetry/telemetry-architecture.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 1: Detailed Telemetry Pipeline Architecture&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;0.2. Stages&lt;/summary&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Collection&lt;/b&gt;: Telemetry data is collected from various sources using agents like Telegraf and &lt;a href=&quot;https://www.fluentd.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Fluentd&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Ingestion&lt;/b&gt;: Data is ingested through message brokers such as Apache Kafka or Kinesis to handle high throughput.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Processing&lt;/b&gt;: Real-time processing is done using stream processing frameworks like Apache Flink for filtering, aggregating, and enriching data.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Storage and Analysis&lt;/b&gt;: Processed data is stored in systems like Cassandra, &lt;a href=&quot;https://clickhouse.com/&quot; target=&quot;_blank&quot;&gt;ClickHouse&lt;/a&gt; and &lt;a href=&quot;https://www.elastic.co/downloads/elasticsearch&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Elasticsearch&lt;/a&gt;, and analyzed using tools like &lt;a href=&quot;https://grafana.com/&quot; target=&quot;_blank&quot;&gt;Grafana&lt;/a&gt; and &lt;a href=&quot;https://www.elastic.co/kibana&quot; target=&quot;_blank&quot;&gt;Kibana&lt;/a&gt; for visualization and alerting.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;

&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;1. Collection&lt;/summary&gt;
&lt;p&gt;&lt;/p&gt;
&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;1.1. Collection Agent&lt;/summary&gt;

&lt;p&gt;To start, we&apos;ll use &lt;a href=&quot;https://www.influxdata.com/time-series-platform/telegraf/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Telegraf&lt;/a&gt;, a versatile open-source agent that collects metrics from various sources and writes them to different outputs. Telegraf supports a wide range of &lt;a href=&quot;https://docs.influxdata.com/telegraf/v1/plugins/#input-plugins&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;input&lt;/a&gt; and &lt;a href=&quot;https://docs.influxdata.com/telegraf/v1/plugins/#output-plugins&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;output plugins&lt;/a&gt;, making it easy to gather data from sensors, servers, GPS systems, and more.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image-0 center-image-80 telegraf-overview&quot; src=&quot;./assets/posts/telemetry/telegraf-overview.svg&quot; /&gt; &lt;/p&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 2: Telegraf for collecting metrics &amp;amp; data&lt;/p&gt;

&lt;p&gt;For this example, we&apos;ll focus on collecting the CPU temperature and Fan speed from a macOS system using the &lt;a href=&quot;https://github.com/influxdata/telegraf/blob/release-1.30/plugins/inputs/exec/README.md&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;exec plugin&lt;/a&gt; in Telegraf. And leverage the &lt;a href=&quot;https://github.com/lavoiesl/osx-cpu-temp&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;osx-cpu-temp&lt;/a&gt; command line tool to fetch the CPU temperature.&lt;/p&gt;

&lt;p&gt;🌵 &lt;a href=&quot;https://github.com/inlets/inlets-pro&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Inlets&lt;/a&gt; allows devices behind firewalls or NAT to securely expose local services to the public internet by tunneling traffic through a public-facing Inlets server&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;1.2. Dependencies&lt;/summary&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Using Homebrew: &lt;code&gt;brew install telegraf&lt;/code&gt;&lt;br /&gt;
For other OS, refer: &lt;a href=&quot;https://docs.influxdata.com/telegraf/v1/install/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs.influxdata.com/telegraf/v1/install&lt;/a&gt;. &lt;br /&gt;
Optionally, download the latest telegraf release from: &lt;a href=&quot;https://www.influxdata.com/downloads&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;https://www.influxdata.com/downloads&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Using Homebrew: &lt;code&gt;brew install osx-cpu-temp&lt;/code&gt;&lt;br /&gt;
Refer: &lt;a href=&quot;https://github.com/lavoiesl/osx-cpu-temp&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;github.com/lavoiesl/osx-cpu-temp&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;
&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;1.3. Events&lt;/summary&gt;

&lt;p&gt;Here&apos;s a &lt;b&gt;custom script&lt;/b&gt; to get the CPU and Fan Speed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash
timestamp=$(date +%s)000000000
hostname=$(hostname | tr &quot;[:upper:]&quot; &quot;[:lower:]&quot;)
cpu=$(osx-cpu-temp -c | sed -e &apos;s/\([0-9.]*\).*/\1/&apos;)
fans=$(osx-cpu-temp -f | grep &apos;^Fan&apos; | sed -e &apos;s/^Fan \([0-9]\) - \([a-zA-Z]*\) side *at \([0-9]*\) RPM (\([0-9]*\)%).*/\1,\2,\3,\4/&apos;)
echo &quot;cpu_temp,device_id=$hostname temp=$cpu $timestamp&quot;
for f in $fans; do
  side=$(echo &quot;$f&quot; | cut -d, -f2 | tr &quot;[:upper:]&quot; &quot;[:lower:]&quot;)
  rpm=$(echo &quot;$f&quot; | cut -d, -f3)
  pct=$(echo &quot;$f&quot; | cut -d, -f4)
  echo &quot;fan_speed,device_id=$hostname,side=$side rpm=$rpm,percent=$pct $timestamp&quot;
done
&lt;/code&gt;&lt;/pre&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;p&gt;&lt;b&gt;Output Format&lt;/b&gt;: &lt;code&gt;measurement,host=foo,tag=measure val1=5,val2=3234.34 1609459200000000000&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The output is of &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1/write_protocols/line_protocol_reference/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Line protocol syntax&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Where &lt;code&gt;measurement&lt;/code&gt; is the “table” (“measurement&quot; in InfluxDB terms) to which the metrics are written.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;host=foo,tag=measure&lt;/code&gt; are tags to can group and filter by.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;val1=5,val2=3234.34&lt;/code&gt; are values, to display in graphs.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;1716425990000000000&lt;/code&gt; is the current unix timestamp + 9 x &quot;0&quot; — representing nanosecond timestamp.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;b&gt;Sample Output&lt;/b&gt;: &lt;code&gt;cpu_temp,device_id=adeshs-mbp temp=0.0 1716425990000000000&lt;/code&gt;&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;1.4. Configuration&lt;/summary&gt;
&lt;p&gt;The location of &lt;code&gt;telegraf.conf&lt;/code&gt; installed using homebrew: &lt;code&gt;/opt/homebrew/etc/telegraf.conf&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Telegraf&apos;s configuration file is written using &lt;a href=&quot;https://github.com/toml-lang/toml#toml&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;TOML&lt;/a&gt; and is composed of three sections: &lt;a href=&quot;https://github.com/influxdata/telegraf/blob/master/docs/CONFIGURATION.md#global-tags&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;global tags&lt;/a&gt;, &lt;a href=&quot;https://github.com/influxdata/telegraf/blob/master/docs/CONFIGURATION.md#agent&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;agent&lt;/a&gt; settings, and &lt;a href=&quot;https://github.com/influxdata/telegraf/blob/master/docs/CONFIGURATION.md#plugins&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;plugins&lt;/a&gt; (inputs, outputs, processors, and aggregators).&lt;/p&gt;

&lt;p&gt;Once Telegraf collects the data, we need to transmit it to a designated endpoint for further processing. For this, we&apos;ll use the &lt;a href=&quot;https://github.com/influxdata/telegraf/blob/release-1.30/plugins/outputs/http/README.md&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;HTTP output plugin&lt;/a&gt; in Telegraf to send the data in JSON format to a Flask application (covered in the next section).&lt;/p&gt;

&lt;p&gt;Below is what the &lt;code&gt;telegraf.conf&lt;/code&gt; file looks like, with &lt;code&gt;exec&lt;/code&gt; input plugin (format: &lt;code&gt;influx&lt;/code&gt;) and &lt;code&gt;HTTP&lt;/code&gt; output plugin (format: &lt;code&gt;JSON&lt;/code&gt;).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[agent]
  interval = &quot;10s&quot;
  round_interval = true
  metric_buffer_limit = 10000
  flush_buffer_when_full = true
  collection_jitter = &quot;0s&quot;
  flush_interval = &quot;10s&quot;
  flush_jitter = &quot;0s&quot;
  precision = &quot;&quot;
  debug = false
  quiet = false
  logfile = &quot;/path to telegraf log/telegraf.log&quot;
  hostname = &quot;host&quot;
  omit_hostname = false

[[inputs.exec]]
  commands = [&quot;/path to custom script/osx_metrics.sh&quot;]
  timeout = &quot;5s&quot;
  name_suffix = &quot;_custom&quot;
  data_format = &quot;influx&quot;
  interval = &quot;10s&quot;

[[outputs.http]]
  url = &quot;http://127.0.0.1:5000/metrics&quot;
  method = &quot;POST&quot;
  timeout = &quot;5s&quot;
  data_format = &quot;json&quot;
  [outputs.http.headers]
    Content-Type = &quot;application/json&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Edit &lt;code&gt;telegraf.conf&lt;/code&gt; (use above config):&lt;br /&gt; &lt;code&gt;vi /opt/homebrew/etc/telegraf.conf&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;🚧: Don&apos;t forget to expore tons of other input and output plugins: &lt;a href=&quot;https://docs.influxdata.com/telegraf/v1/plugins/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs.influxdata.com/telegraf/v1/plugins&lt;/a&gt;&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;h4&quot; id=&quot;telemetry-1-5&quot;&gt;1.5. Start Capture&lt;/summary&gt;
&lt;p&gt;Run &lt;code&gt;telegraf&lt;/code&gt; (when installed from Homebrew):&lt;br /&gt; &lt;code&gt;/opt/homebrew/opt/telegraf/bin/telegraf -config /opt/homebrew/etc/telegraf.conf&lt;/code&gt;&lt;/p&gt;
&lt;/details&gt;

&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;2. Ingestion&lt;/summary&gt;
&lt;p&gt;&lt;/p&gt;
&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;2.1. Telemetry Server&lt;/summary&gt;

&lt;p&gt;The telemetry server layer is designed to be &lt;u&gt;lightweight&lt;/u&gt;. Its primary function is to authenticate incoming requests and publish raw events directly to Message Broker/Kafka. Further processing of these events will be carried out by the stream processing framework.&lt;/p&gt;

&lt;p&gt;For our example, the &lt;a href=&quot;https://flask.palletsprojects.com/en/3.0.x/&quot; target=&quot;_blank&quot;&gt;Flask&lt;/a&gt; application serves as the telemetry server, acting as the entry point (via load-balancer) for the requests. It receives the data from a POST request, validates it, and publishes the messages to a &lt;a href=&quot;https://kafka.apache.org/&quot; target=&quot;_blank&quot;&gt;Kafka&lt;/a&gt; topic.&lt;/p&gt;

&lt;p&gt;Topic partition is the unit of parallelism in Kafka. Choose a partition key (ex: client_id) that evenly distributes records to avoid hotspots and &lt;a href=&quot;https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster&quot; target=&quot;_blank&quot;&gt;number of partitions&lt;/a&gt; to achieve good throughput.&lt;/p&gt;

&lt;p&gt;🚧 Message Broker Alternatives: &lt;a href=&quot;https://aws.amazon.com/kinesis/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Amazon Kinesis&lt;/a&gt;, &lt;a href=&quot;https://redpanda.com/&quot; target=&quot;_blank&quot;&gt;Redpanda&lt;/a&gt;&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;2.2. Dependencies&lt;/summary&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Using PIP: &lt;code&gt;pip3 install Flask flask-cors kafka-python&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;b&gt;For Local Kafka Set-up&lt;/b&gt; (Or use Docker from next sub-section):
&lt;li&gt;&lt;p&gt;Using Homebrew: &lt;code&gt;brew install kafka&lt;/code&gt; &lt;br /&gt;Refer: &lt;a href=&quot;https://formulae.brew.sh/formula/kafka&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Homebrew Kafka&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Start Zookeeper: &lt;code&gt;zookeeper-server-start /opt/homebrew/etc/kafka/zookeeper.properties&lt;/code&gt;&lt;br /&gt;
Start Kafka: &lt;code&gt;brew services restart kafka&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Create Topic: &lt;code&gt;kafka-topics --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic learn&lt;/code&gt; &lt;br /&gt;Usage: &lt;a href=&quot;https://kafka.apache.org/documentation/#topicconfigs&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Kafka CLI&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;h4&quot; id=&quot;telemetry-2-3&quot;&gt;2.3. Docker Compose&lt;/summary&gt;

&lt;p&gt;To set up Kafka using Docker Compose, ensure Docker is installed on your machine by following the instructions on the &lt;a href=&quot;https://docs.docker.com/get-docker/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Docker installation&lt;/a&gt; page. Once Docker is installed, create a &lt;code&gt;docker-compose.yml&lt;/code&gt; for &lt;code&gt;Kafka&lt;/code&gt; and &lt;code&gt;Zookeeper&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;version: &apos;3.7&apos;

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.5
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - &quot;2181:2181&quot;

  kafka:
    image: confluentinc/cp-kafka:7.3.5
    ports:
      - &quot;9092:9092&quot;  # Internal port
      - &quot;9094:9094&quot;  # External port
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://localhost:9094
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,OUTSIDE://0.0.0.0:9094
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      CONFLUENT_SUPPORT_METRICS_ENABLE: &quot;false&quot;
    depends_on:
      - zookeeper

  kafka-topics-creator:
    image: confluentinc/cp-kafka:7.3.5
    depends_on:
      - kafka
    entrypoint: [&quot;/bin/sh&quot;, &quot;-c&quot;]
    command: |
      &quot;
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:9092 --list

      echo -e &apos;Creating kafka topics&apos;
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic raw-events --replication-factor 1 --partitions 1

      echo -e &apos;Successfully created the following topics:&apos;
      kafka-topics --bootstrap-server kafka:9092 --list
      &quot;

  schema-registry:
    image: confluentinc/cp-schema-registry:7.3.5
    environment:
      - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
      - SCHEMA_REGISTRY_HOST_NAME=schema-registry
      - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8085,http://localhost:8085
    ports:
      - 8085:8085
    depends_on: [zookeeper, kafka]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Run &lt;code&gt;docker-compose up&lt;/code&gt; to start the services (Kafka + Zookeeper).&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;h4&quot; id=&quot;telemetry-2-4&quot;&gt;2.4. Start Server&lt;/summary&gt;

&lt;p&gt;The Flask application includes a &lt;code&gt;/metrics&lt;/code&gt; endpoint, as configured in &lt;code&gt;telegraf.conf&lt;/code&gt; output to collect metrics. When data is sent to this endpoint, the Flask app receives and publishes the message to &lt;code&gt;Kafka&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;New to Flask? Refer: &lt;a href=&quot;https://flask.palletsprojects.com/en/3.0.x/quickstart/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Flask Quickstart&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import os
from flask_cors import CORS
from flask import Flask, jsonify, request
from dotenv import load_dotenv
from kafka import KafkaProducer
import json


app = Flask(__name__)
cors = CORS(app)
load_dotenv()

producer = KafkaProducer(bootstrap_servers=&apos;localhost:9094&apos;, 
                         value_serializer=lambda v: json.dumps(v).encode(&apos;utf-8&apos;))

@app.route(&apos;/metrics&apos;, methods=[&apos;POST&apos;])
def process_metrics():
    data = request.get_json()
    print(data)
    producer.send(&apos;raw-events&apos;, data)
    return jsonify({&apos;status&apos;: &apos;success&apos;}), 200


if __name__ == &quot;__main__&quot;:
    app.run(debug=True, host=&quot;0.0.0.0&quot;, port=int(os.environ.get(&quot;PORT&quot;, 8080)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Start all services 🚀:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Run Flask App (Telemetry Server):&lt;br /&gt; &lt;code&gt;flask run&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ensure &lt;code&gt;telegraf&lt;/code&gt; is running (Refer: &lt;a href=&quot;#telemetry-1-5&quot;&gt;Section 1.5&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;

&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;3. Processing&lt;/summary&gt;
&lt;p&gt;&lt;/p&gt;
&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;3.1. Stream Processor&lt;/summary&gt;
&lt;p&gt;The Stream Processor is responsible for data transformation, enrichment, stateful computations/updates over unbounded (push-model) and bounded (pull-model) data streams and sink enriched and transformed data to various data stores or applications. Key Features to Look for in a Stream Processing Framework:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Scalability and Performance&lt;/b&gt;: Scale by adding nodes, efficiently use resources, process data with minimal delay, and handle large volumes&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Fault Tolerance and Data Consistency&lt;/b&gt;: Ensure fault tolerance with state saving for failure recovery and exactly-once processing.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Ease of Use and Community Support&lt;/b&gt;: Provide user-friendly APIs in multiple languages, comprehensive documentation, and active community support.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;img src=&quot;./assets/posts/telemetry/stateful-stream-processing.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 3: Stateful Stream Processing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Integration and Compatibility&lt;/b&gt;: Seamlessly integrate with various data sources and sinks, and be compatible with other tools in your tech stack.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Windowing and Event Time Processing&lt;/b&gt;: Support various &lt;a href=&quot;https://nightlies.apache.org/flink/flink-docs-release-1.19/docs/dev/datastream/operators/windows/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;windowing strategies&lt;/a&gt; (tumbling, sliding, session) and manage late-arriving data based on event timestamps.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Security and Monitoring&lt;/b&gt;: Include security features like data encryption and robust access controls, and provide tools for monitoring performance and logging.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although I have set the context to use Flink for this example;&lt;br /&gt;
☢️ Note: While &lt;a href=&quot;https://flink.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Apache Flink&lt;/a&gt; is a powerful choice for stream processing due to its rich feature set, scalability, and advanced capabilities, it can be overkill for a lot of use cases, particularly those with simpler requirements and/or lower data volumes.&lt;/p&gt;

&lt;p&gt;🚧 Open Source Alternatives: &lt;a href=&quot;https://kafka.apache.org/documentation/streams/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Apache Kafka Streams&lt;/a&gt;, &lt;a href=&quot;https://storm.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Apache Storm&lt;/a&gt;, &lt;a href=&quot;https://samza.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Apache Samza&lt;/a&gt;&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;3.2. Dependencies&lt;/summary&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Install PyFlink Using PIP: &lt;code&gt;pip3 install apache-flink==1.18.1&lt;/code&gt;&lt;br /&gt;Usage examples: &lt;a href=&quot;https://github.com/apache/flink/tree/release-1.19/flink-python/pyflink/examples&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;flink-python/pyflink/examples&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;b&gt;For Local Flink Set-up:&lt;/b&gt; (Or use Docker from next sub-section)
&lt;li&gt;&lt;p&gt;Download Flink and extract the archive: &lt;a href=&quot;https://www.apache.org/dyn/closer.lua/flink/flink-1.18.1/flink-1.18.1-bin-scala_2.12.tgz&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;www.apache.org/dyn/closer.lua/flink/flink-1.18.1/flink-1.18.1-bin-scala_2.12.tgz&lt;/a&gt;&lt;br /&gt;☢️ At the time of writing this post &lt;code&gt;Flink 1.18.1&lt;/code&gt; is the latest stable version that supports &lt;a href=&quot;https://www.apache.org/dyn/closer.lua/flink/flink-connector-kafka-3.1.0/flink-connector-kafka-3.1.0-src.tgz&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;kafka connector plugin&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Download Kafka Connector and extract the archive: &lt;a href=&quot;https://www.apache.org/dyn/closer.lua/flink/flink-connector-kafka-3.1.0/flink-connector-kafka-3.1.0-src.tgz&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;www.apache.org/dyn/closer.lua/flink/flink-connector-kafka-3.1.0/flink-connector-kafka-3.1.0-src.tgz&lt;/a&gt;&lt;br /&gt;Copy/Move the &lt;code&gt;flink-connector-kafka-3.1.0-1.18.jar&lt;/code&gt; to &lt;code&gt;flink-1.18.1/lib&lt;/code&gt; (&lt;code&gt;$FLINK_HOME/lib&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ensure Flink Path is set &lt;code&gt;export FLINK_HOME=/full-path/flink-1.18.1&lt;/code&gt; (add to &lt;code&gt;.bashrc&lt;/code&gt;/&lt;code&gt;.zshrc&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Start Flink Cluster: &lt;code&gt;cd flink-1.18.1 &amp;amp;&amp;amp; ./bin/start-cluster.sh&lt;/code&gt;
&lt;br /&gt;Flink dashboard at: &lt;a href=&quot;http://localhost:8081&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;localhost:8081&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;To Stop Flink Cluster: &lt;code&gt;./bin/stop-cluster.sh&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;h4&quot; id=&quot;telemetry-3-3&quot;&gt;3.3. Docker Compose&lt;/summary&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Create &lt;code&gt;flink_init/Dockerfile&lt;/code&gt; file for Flink and Kafka Connector:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM flink:1.18.1-scala_2.12

RUN wget -P /opt/flink/lib https://repo.maven.apache.org/maven2/org/apache/flink/flink-connector-kafka/3.1.0-1.18/flink-connector-kafka-3.1.0-1.18.jar

RUN chown -R flink:flink /opt/flink/lib
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Add Flink to &lt;code&gt;docker-compose.yml&lt;/code&gt; (in-addition to Kafka, from &lt;a href=&quot;#telemetry-2-3&quot;&gt;Section 2.3&lt;/a&gt;)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;version: &apos;3.8&apos;
services:
  jobmanager:
    build: flink_init/.
    ports:
      - &quot;8081:8081&quot;
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager

  taskmanager:
    build: flink_init/.
    depends_on:
      - jobmanager
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 2
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;p&gt;Run &lt;code&gt;docker-compose up&lt;/code&gt; to start the services (Kafka + Zookeeper, Flink).&lt;/p&gt;
&lt;/ul&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details class=&quot;code-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;3.4. Start Cluster&lt;/summary&gt;
&lt;p&gt;⚠️ PyFlink Job:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start all services 🚀:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Ensure all the services are running (Refer: Section &lt;a href=&quot;#telemetry-1-5&quot;&gt;1.5&lt;/a&gt;, &lt;a href=&quot;#telemetry-2-4&quot;&gt;2.4&lt;/a&gt;, &lt;a href=&quot;#telemetry-3-3&quot;&gt;3.3&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;

&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;4. Storage and Analysis &lt;/summary&gt;
&lt;p&gt;The code snippets - stops here! The rest of the post covers key conventions, strategies, and factors for selecting the right data store, performing real-time analytics, and alerts.&lt;/p&gt;
&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;4.1. Datastore &lt;/summary&gt;
&lt;p&gt;When choosing the right database for telemetry data, it&apos;s crucial to consider several factors:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Read and Write Patterns&lt;/b&gt;: Understanding the frequency and volume of read and write operations is key. High write and read throughput require different database optimizations and consistencies.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Data Amplification&lt;/b&gt;: Be mindful of how the data volume might grow over time (+&lt;a href=&quot;https://en.wikipedia.org/wiki/Write_amplification&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Write Amplification&lt;/a&gt;) and how the database handles this increase without significant performance degradation.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Cost&lt;/b&gt;: Evaluate the cost implications, including storage, processing, and any associated services.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Analytics Use Cases&lt;/b&gt;: Determine whether the primary need is for real-time analytics, historical data analysis, or both.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Transactions&lt;/b&gt;: Consider the nature and complexity of transactions that will be performed. For example: Batch write transactions&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Read and Write Consistency&lt;/b&gt;: Decide on the level of consistency required for the application. For example, OLTP (Online Transaction Processing) systems prioritize consistency and transaction integrity, while OLAP (Online Analytical Processing) systems are optimized for complex queries and read-heavy workloads.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;🌵 &lt;a href=&quot;https://tikv.github.io/deep-dive-tikv/key-value-engine/B-Tree-vs-Log-Structured-Merge-Tree.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;LSM-Tree&lt;/a&gt; favors write-intensive applications.&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;p&gt;For example, to decide between Row-based vs Columar Storage. Or OLTP (Online Transaction Processing), OLAP (Online Analytical Processing), or a Hybrid approach:&lt;/p&gt;

&lt;img class=&quot;center-image-90&quot; src=&quot;./assets/posts/telemetry/storage-scan-direction.png&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 4: Row vs Columnnar Storage&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Transactional and High Throughput Needs&lt;/b&gt;: For high write throughput and transactional batches (all or nothing), with queries needing wide-column family fetches and indexed queries within the partition, Cassandra/&lt;a href=&quot;https://www.scylladb.com/&quot; target=&quot;_blank&quot;&gt;ScyllaDB&lt;/a&gt; is better suited.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;b&gt;Complex Analytical Queries&lt;/b&gt;: For more complex analytical queries, aggregations on specific columns, and machine learning models, data store(s) such as &lt;a href=&quot;https://clickhouse.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;ClickHouse&lt;/a&gt; or &lt;a href=&quot;https://druid.apache.org/&quot; target=&quot;_blank&quot;&gt;Druid&lt;/a&gt; is more appropriate. Its optimized columnar storage and powerful query capabilities make it ideal for handling large-scale analytical tasks. Several others include: VictoriaMetrics and InfluxDB (emphasis on time-series); closed-source: &lt;a href=&quot;https://www.snowflake.com/&quot; target=&quot;_blank&quot;&gt;Snowflake&lt;/a&gt;, &lt;a href=&quot;https://cloud.google.com/bigquery&quot; target=&quot;_blank&quot;&gt;BigQuery&lt;/a&gt; and &lt;a href=&quot;https://aws.amazon.com/redshift/&quot; target=&quot;_blank&quot;&gt;Redshift&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;b&gt;Hybrid Approach&lt;/b&gt;: In scenarios requiring both fast write-heavy transactional processing and complex analytics, a common approach is to use Cassandra for real-time data ingestion and storage, and periodically perform ETL (Extract, Transform, Load) or CDC (Change Data Capture) processes to batch insert data into OLAP DB for analytical processing. This leverages the strengths of both databases, ensuring efficient data handling and comprehensive analytical capabilities. Proper indexing and data modeling goes unsaid 🧐&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;🌵 &lt;a href=&quot;https://debezium.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Debezium&lt;/a&gt;: Distributed platform for change data capture (more on &lt;a href=&quot;/debezium-postgres-cdc&quot;&gt;previous post&lt;/a&gt;).&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;p&gt;Using a HTAP (Hybrid Transactional/Analytical Processing) database that&apos;s suitable for both transactional and analytical workloads is worth considering. Example: &lt;a href=&quot;https://github.com/pingcap/tidb&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;TiDB&lt;/a&gt;, &lt;a href=&quot;https://www.timescale.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;TimescaleDB&lt;/a&gt; (Kind of).&lt;/p&gt;

&lt;p&gt;While you get some of the best from both worlds 🌎, you also inherit a few of the worst from each! &lt;br /&gt;Lucky for you, I have first hand experience with it 🤭:&lt;/p&gt;
&lt;img src=&quot;./assets/posts/telemetry/of-both-worlds-h.png&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 5: Detailed comparison of OLTP, OLAP and HTAP&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Analogy&lt;/b&gt;: Choosing the right database is like picking the perfect ride. Need pay-as-you-go flexibility? Grab a taxi. Tackling heavy-duty tasks? 🚜 Bring in the bulldozer. For everyday use, 🚗 a Toyota fits. Bringing a war tank to a community center is overkill. Sometimes, you need a fleet—a car for daily use, and a truck for heavy loads.&lt;/p&gt;

&lt;p&gt;☢️ &lt;a&gt;InfluxDB&lt;/a&gt;: Stagnant &lt;a href=&quot;https://github.com/influxdata/influxdb/graphs/contributors&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;contribution&lt;/a&gt; graph, &lt;a href=&quot;https://community.influxdata.com/t/is-flux-being-deprecated-with-influxdb-3-0/30992/4&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Flux&lt;/a&gt; deprecation, but new &lt;a href=&quot;https://www.influxdata.com/benchmarks/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;benchmarks&lt;/a&gt;!&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;4.2. Partition and Indexes&lt;/summary&gt;

&lt;p&gt;Without getting into too much detail, it&apos;s crucial to choose the right partitioning strategy (Ex: Range, List, Hash) to ensure partitions don&apos;t bloat and effectively support primary read patterns (in this context, example: client_id + region + 1st Day of Month).&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/telemetry/index-types.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 6: Types of Indexes and Materialized view&lt;/p&gt;

&lt;p&gt;Following this, clustering columns and indexes help organize data within partitions to optimize range queries and sorting. Secondary indexes (within the partition/local or across partitions/global) are valuable for query patterns where partition or primary keys don&apos;t apply. Materialized views for precomputing and storing complex query results, speeding up read operations for frequently accessed data.&lt;/p&gt;

&lt;img src=&quot;./assets/posts/telemetry/partition-view.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 7: Partition Key, Clustering Keys, Local/Global Secondary Indexes and Materialized views&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Multi-dimensional Index (Spatial/Spatio-temporal)&lt;/b&gt;: Indexes such as B+ trees and LSM trees are not designed to directly store higher-dimensional data. Spatial indexing uses structures like R-trees and &lt;a href=&quot;/hybrid-spatial-index-conclusion&quot; target=&quot;_blank&quot;&gt;Quad-trees&lt;/a&gt; and techniques like &lt;a href=&quot;/geohash&quot; target=&quot;_blank&quot;&gt;geohash&lt;/a&gt;. Space-filling curves like Z-order (Morton) and Hilbert curves interleave spatial and temporal dimensions, preserving locality and enabling efficient queries.&lt;/p&gt;

&lt;img class=&quot;center-image-0&quot; src=&quot;./assets/posts/spatial-index/spatial-index-types.svg&quot; /&gt; 
&lt;p class=&quot;figure-header&quot;&gt;Figure 8: Commonly Used: Types of Spatial Indexes&lt;/p&gt;

&lt;p&gt;🌵 &lt;a href=&quot;https://www.geomesa.org/documentation/stable/index.html&quot; target=&quot;_blank&quot;&gt;GeoMesa&lt;/a&gt;: spatio-temporal indexing on top of the Accumulo, HBase, Redis, Kafka, PostGIS and Cassandra. &lt;a href=&quot;https://www.geomesa.org/documentation/stable/user/datastores/index_overview.html&quot; target=&quot;_blank&quot;&gt;XZ-Ordering&lt;/a&gt;: Customizing Index Creation.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;twemoji&quot; src=&quot;../assets/img/emoji/rocket.svg&quot; alt=&quot;&quot; /&gt; &lt;a href=&quot;/spatial-index-space-filling-curve&quot;&gt;Next blog&lt;/a&gt; post is all about spatial indexes!&lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;sub-hr&quot; /&gt;

&lt;details open=&quot;&quot; class=&quot;text-container&quot;&gt;&lt;summary class=&quot;h4&quot;&gt;4.3. Analytics and Alerts&lt;/summary&gt;

&lt;p&gt;Typically, analytics are performed as batch queries on bounded datasets of recorded events, requiring reruns to incorporate new data.&lt;/p&gt;

&lt;img class=&quot;center-image-65&quot; src=&quot;./assets/posts/telemetry/telemetry-analytics.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 9: Analytics on Static, Relative and In-Motion Data&lt;/p&gt;

&lt;p&gt;In contrast, streaming queries ingest real-time event streams, continuously updating results as events are consumed, with outputs either written to an external database or maintained as internal state.&lt;/p&gt;

&lt;img src=&quot;./assets/posts/telemetry/usecases-analytics.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 10: Batch Analytics vs Stream Analytics&lt;/p&gt;
&lt;div class=&quot;table-container&quot;&gt;
&lt;table style=&quot;width: 800px;&quot;&gt;
    &lt;tr&gt;
        &lt;td&gt;Feature&lt;/td&gt;
        &lt;td&gt;Batch Analytics&lt;/td&gt;
        &lt;td&gt;Stream Analytics&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Data Processing&lt;/td&gt;
        &lt;td&gt;Processes large volumes of stored data&lt;/td&gt;
        &lt;td&gt;Processes data in real-time as it arrives&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Result Latency&lt;/td&gt;
        &lt;td&gt;Produces results with some delay; near real-time results with frequent query runs&lt;/td&gt;
        &lt;td&gt;Provides immediate insights and actions&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Resource Efficiency&lt;/td&gt;
        &lt;td&gt;Requires querying the database often for necessary data&lt;/td&gt;
        &lt;td&gt;Continuously updates results in transient data stores without re-querying the database&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Typical Use&lt;/td&gt;
        &lt;td&gt;Ideal for historical analysis and periodic reporting&lt;/td&gt;
        &lt;td&gt;Best for real-time monitoring, alerting, and dynamic applications&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Complexity Handling&lt;/td&gt;
        &lt;td&gt;Can handle complex queries and computations&lt;/td&gt;
        &lt;td&gt;Less effective for highly complex queries&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Backfill&lt;/td&gt;
        &lt;td&gt;Easy to backfill historical data and re-run queries&lt;/td&gt;
        &lt;td&gt;Backfill can potentially introduce complexity&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;🌵 &lt;a href=&quot;/anomaly-detection-and-remediation&quot; target=&quot;_blank&quot;&gt;Anomaly Detection and Remediation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;🌵 &lt;a href=&quot;https://docs.mindsdb.com/what-is-mindsdb&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;MindsDB&lt;/a&gt;: Connect Data Source, Configure AI Engine, Create AI Tables, Query for predictions and Automate workflows.&lt;/p&gt;
&lt;/details&gt;

&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot;&gt;5. References&lt;/summary&gt;

&lt;pre style=&quot;height: 300px&quot;&gt;&lt;code&gt;1. Wikipedia, &quot;Telemetry,&quot; available: https://en.wikipedia.org/wiki/Telemetry. [Accessed: June 5, 2024].
2. Apache Cassandra, &quot;Cassandra,&quot; available: https://cassandra.apache.org. [Accessed: June 5, 2024].
3. VictoriaMetrics, &quot;VictoriaMetrics,&quot; available: https://victoriametrics.com. [Accessed: June 6, 2024].
4. Fluentd, &quot;Fluentd,&quot; available: https://www.fluentd.org. [Accessed: June 5, 2024].
5. Elasticsearch, &quot;Elasticsearch,&quot; available: https://www.elastic.co. [Accessed: June 5, 2024].
6. InfluxData, &quot;Telegraf,&quot; available: https://www.influxdata.com. [Accessed: June 5, 2024].
7. InfluxData, &quot;Telegraf Plugins,&quot; available: https://docs.influxdata.com. [Accessed: June 5, 2024].
8. GitHub, &quot;osx-cpu-temp,&quot; available: https://github.com/lavoiesl/osx-cpu-temp. [Accessed: June 5, 2024].
9. GitHub, &quot;Inlets,&quot; available: https://github.com/inlets/inlets. [Accessed: June 5, 2024].
10. InfluxData, &quot;Telegraf Installation,&quot; available: https://docs.influxdata.com/telegraf/v1. [Accessed: June 5, 2024].
11. InfluxData, &quot;InfluxDB Line Protocol,&quot; available: https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol. [Accessed: June 5, 2024].
12. GitHub, &quot;Telegraf Exec Plugin,&quot; available: https://github.com/influxdata/telegraf/tree/master/plugins/inputs/exec. [Accessed: June 5, 2024].
13. GitHub, &quot;Telegraf Output Plugins,&quot; available: https://github.com/influxdata/telegraf/tree/master/plugins/outputs. [Accessed: June 5, 2024].
14. Pallets Projects, &quot;Flask,&quot; available: https://flask.palletsprojects.com. [Accessed: June 5, 2024].
15. Apache Kafka, &quot;Kafka,&quot; available: https://kafka.apache.org. [Accessed: June 5, 2024].
16. Confluent, &quot;Kafka Partitions,&quot; available: https://www.confluent.io. [Accessed: June 5, 2024].
17. AWS, &quot;Amazon Kinesis,&quot; available: https://aws.amazon.com/kinesis. [Accessed: June 5, 2024].
18. Redpanda, &quot;Redpanda,&quot; available: https://redpanda.com. [Accessed: June 5, 2024].
19. Apache, &quot;Apache Flink,&quot; available: https://flink.apache.org. [Accessed: June 6, 2024].
20. GitHub, &quot;flink-python/pyflink/examples,&quot; available: https://github.com/apache/flink/tree/master/flink-python/pyflink/examples. [Accessed: June 6, 2024].
21. Apache, &quot;Flink Download,&quot; available: https://www.apache.org/dyn/closer.lua/flink. [Accessed: June 6, 2024].
22. Apache, &quot;Flink Kafka Connector,&quot; available: https://www.apache.org/dyn/closer.lua/flink/flink-connector-kafka-3.1.0. [Accessed: June 6, 2024].
23. Docker, &quot;Docker Installation,&quot; available: https://docs.docker.com. [Accessed: June 6, 2024].
24. Apache Kafka, &quot;Kafka CLI,&quot; available: https://kafka.apache.org/quickstart. [Accessed: June 6, 2024].
25. Homebrew, &quot;Kafka Installation,&quot; available: https://formulae.brew.sh/formula/kafka. [Accessed: June 6, 2024].
26. Apache, &quot;Apache Storm,&quot; available: https://storm.apache.org. [Accessed: June 6, 2024].
27. Apache, &quot;Apache Samza,&quot; available: https://samza.apache.org. [Accessed: June 6, 2024].
28. ClickHouse, &quot;ClickHouse,&quot; available: https://clickhouse.com. [Accessed: June 6, 2024].
29. InfluxData, &quot;InfluxDB Benchmarks,&quot; available: https://www.influxdata.com/benchmarks. [Accessed: June 6, 2024].
30. TiDB, &quot;TiDB,&quot; available: https://github.com/pingcap/tidb. [Accessed: June 6, 2024].
31. Timescale, &quot;TimescaleDB,&quot; available: https://www.timescale.com. [Accessed: June 6, 2024].
32. MindsDB, &quot;MindsDB,&quot; available: https://docs.mindsdb.com. [Accessed: June 6, 2024].
33. Wikipedia, &quot;Write Amplification,&quot; available: https://en.wikipedia.org/wiki/Write_amplification. [Accessed: June 6, 2024].
34. GitHub, &quot;LSM-Tree,&quot; available: https://tikv.github.io/deep-dive/introduction/theory/lsm-tree.html. [Accessed: June 6, 2024].
&lt;/code&gt;&lt;/pre&gt;

&lt;/details&gt;
&lt;p&gt;&lt;/p&gt;</content><author><name>Adesh Nalpet Adimurthy</name></author><category term="System Wisdom" /><category term="Realtime" /><category term="Database" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pyblog.xyz/assets/featured/webp/telemetry-pipeline.webp" /><media:content medium="image" url="https://pyblog.xyz/assets/featured/webp/telemetry-pipeline.webp" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">B Trees and B+ Trees</title><link href="https://pyblog.xyz/b-tree" rel="alternate" type="text/html" title="B Trees and B+ Trees" /><published>2024-02-15T00:00:00+00:00</published><updated>2024-02-15T00:00:00+00:00</updated><id>https://pyblog.xyz/b-tree</id><content type="html" xml:base="https://pyblog.xyz/b-tree">&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/featured/webp/bee-tree.webp&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;blog-reference green-disclaimer&quot;&gt;
&lt;p&gt;This post aims to correlate the use of B+ Trees as indexes in DBMS, rather than delving deeply into the specifics of B+ Trees. And is primarily derived from &lt;a href=&quot;https://www.youtube.com/watch?v=aZjYr87r1b8&quot; target=&quot;_blank&quot;&gt;Abdul Bari&apos;s explanation on B Trees&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;0. Foundation&lt;/summary&gt;

&lt;h3&gt;Disk Structure&lt;/h3&gt;
&lt;p&gt;Let&apos;s start with disk structure. It&apos;s a &lt;a href=&quot;https://en.wikipedia.org/wiki/Hard_disk_drive_platter&quot; target=&quot;_blank&quot;&gt;platter&lt;/a&gt; with concentric circles, which are logical not physical. These circles of different radii are called tracks, and the vertical sections are called &lt;a href=&quot;https://en.wikipedia.org/wiki/Disk_sector&quot; target=&quot;_blank&quot;&gt;sectors&lt;/a&gt;. The intersection of a track and a sector is called a block. Hence, any location on the disk, i.e., block address, can be identified by the track number and sector number.&lt;/p&gt;
&lt;img class=&quot;center-image-0 center-image-90&quot; src=&quot;./assets/posts/b-tree/disk-structure.svg&quot; /&gt;

&lt;hr class=&quot;hr&quot; /&gt;
&lt;h3&gt;How is Data Stored on Disk&lt;/h3&gt;
&lt;p&gt;Let&apos;s consider a block size of 512 bytes (hypothetical), meaning each block is 512 bytes. All read and write operations are in terms of blocks. Considering one block of 512 bytes, we have a beginning address of 0 up to 511. Each byte can have its own address and is called an offset. Now, we can refer to any one byte on the disk in terms of block address and offset.&lt;/p&gt;

&lt;p&gt;The disk is mounted on a spindle and has a head post. By spinning, we can change the sectors, and with the arm movement of the head (for reading and writing), the tracks are changed. This allows us to access any block or byte of data.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-65&quot; src=&quot;./assets/posts/b-tree/disk-main-memory.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 1: Main Memory for Processing&lt;/p&gt;

&lt;p&gt;Another type of memory is main memory (&lt;a href=&quot;https://en.wikipedia.org/wiki/Random-access_memory&quot; target=&quot;_blank&quot;&gt;RAM&lt;/a&gt;). We run programs in main memory, and these programs access the data on the disk. To do so, the data has to be brought into the main memory to be accessed, and any updated results are written back to the disk. Thus, the data cannot be directly processed on the disk and must be brought into the main memory.&lt;/p&gt;

&lt;p&gt;Organizing the data inside the main memory as used by the program involves data structures, while organizing the data on the disk so that it can be accessed efficiently is managed by a DBMS (Database Management System).&lt;/p&gt;

&lt;p&gt;Moving on to understanding how the data is organized on the disk, let&apos;s consider an employee table with columns such as ID, name, department, and several others, containing 100 records/rows. Each record is 128 bytes, and each block on the disk is 512 bytes. Hence, the number of records that can be stored in each block is 4.&lt;/p&gt;
&lt;img class=&quot;center-image-0 center-image-80&quot; src=&quot;./assets/posts/b-tree/disk-organization-cropped.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 2: Disk Organization&lt;/p&gt;

&lt;p&gt;Number of blocks required = &lt;code&gt;Total Number of Records / Records per block&lt;/code&gt; = &lt;code&gt;100/4&lt;/code&gt; = &lt;code&gt;25&lt;/code&gt; blocks are required for storing 100 records.&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;
&lt;h3&gt;What is Indexing&lt;/h3&gt;
&lt;p&gt;Now, let&apos;s consider a query to search for a particular record. Because of the sequential access, this would require reading up to 25 blocks on the disk. To reduce this time and the number of blocks to scan, we prepare an &lt;a href=&quot;https://en.wikipedia.org/wiki/Database_index&quot; target=&quot;_blank&quot;&gt;index&lt;/a&gt; table. Each record in the index has a pointer to the table inside the disk/block, called the record pointer.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-80&quot; src=&quot;./assets/posts/b-tree/disk-index.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 3: Table Index&lt;/p&gt;

&lt;p&gt;Typically, for a &lt;a href=&quot;http://mlwiki.org/index.php/Secondary_Index&quot; target=&quot;_blank&quot;&gt;dense index&lt;/a&gt;, each record in the table has an entry in the index. The index is also stored on the disk. Given that the index is stored on the disk, the space it takes can be calculated as follows: We know that the ID takes 10 bytes, and assume the pointer takes 6 bytes. So, each entry in the index takes 16 bytes.&lt;/p&gt;

&lt;p&gt;For 100 records, the size of the index on the disk is: &lt;code&gt;100 × 16 bytes = 1600 bytes&lt;/code&gt;. And the number of blocks required is &lt;code&gt;1600 bytes/512 bytes per block&lt;/code&gt; = &lt;code&gt;3.125&lt;/code&gt;. Approximately, we need 4 blocks to store the index records on the disk.&lt;/p&gt;

&lt;p&gt;This significantly reduces the number of blocks to be read on the disk. By finding the ID in the index (accessing up to 4 blocks), followed by using the pointer address to find the record (accessing 1 block), the maximum number of blocks to access a record is reduced from 25 to 5 blocks.&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;
&lt;h3&gt;What is Multi-Level Indexing&lt;/h3&gt;

&lt;p&gt;But as the number of records grows, the size of the index also grows. For instance, if we have 1,000 records in the employee table, this would take up 250 blocks on the disk. The index would now need 32 blocks for the 1,000 entries, leading to the index itself becoming too large or requiring too many blocks to scan.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-80&quot; src=&quot;./assets/posts/b-tree/disk-multi-index.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 4: Multi Level Index&lt;/p&gt;

&lt;p&gt;This can be optimized by using multi-level indexing. The level-2 index points to the first record of each level-1 index block. Each level-1 index block contains 32 index records (ID + Pointer). Thus, each entry in the level-2 index holds the first ID and a pointer to a level-1 index block. This &lt;a href=&quot;http://mlwiki.org/index.php/Secondary_Index&quot; target=&quot;_blank&quot;&gt;sparse index&lt;/a&gt; reduces the number of blocks needed to search.&lt;/p&gt;

&lt;p&gt;By adding another level of indexing, the number of blocks to scan for a given &lt;code&gt;ID&lt;/code&gt; is reduced from 33 blocks (32 level-1 Index + 1 table block) to 3 blocks (1 level-2 index + 1 level-1 index + 1 table block).&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/b-tree/two-level-sparse-index.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 4: Two Level Sparse Index&lt;/p&gt;

&lt;p&gt;The multi-level index forms a tree structure. However, manually adding indexes every time the number of records increases significantly is not feasible. What we want is a system that can automatically add and delete higher-level indices, resulting in a self-managed multi-level indexing system.&lt;/p&gt;

&lt;p&gt;This concludes the foundation and introduces the basic concept behind B-trees, B+ trees, and more generally, M-way search trees.&lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;1. M-way Search Trees&lt;/summary&gt;
&lt;p&gt;Starting with a BST (&lt;a href=&quot;https://en.wikipedia.org/wiki/Binary_search_tree&quot; target=&quot;_blank&quot;&gt;Binary Search Tree&lt;/a&gt;), each node has one key/value and at most two children: the left child contains values less than the parent node, and the right child contains values greater than the parent node.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image&quot; src=&quot;./assets/posts/b-tree/m-way-intuition.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 5: BST vs M-Way Search Tree&lt;/p&gt;

&lt;p&gt;Extending this to a similar search tree structure with multiple keys per node, consider an example with 2 keys: &lt;code&gt;[20, 50]&lt;/code&gt;. Here, the keys are arranged in ascending order, and the node can have 3 children: one for values less than 20, one for values between 20 and 50, and one for values greater than 50.&lt;/p&gt;

&lt;p&gt;These are called M-Way Search Trees. The above example is a 3-way search tree, where the node has 2 keys and at most 3 children. In general, an M-Way Search Tree can have at most &lt;code&gt;M&lt;/code&gt; children and &lt;code&gt;(M - 1)&lt;/code&gt; keys. Thus, M is based on the number of children, representing the degree of a node.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/b-tree/m-way-node-structure.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 6: BST and 4-Way Search Tree Node&lt;/p&gt;

&lt;p&gt;Similar to a BST, where a node has a key/data and left and right child pointers, in an M-Way Search Tree, a node can have up to &lt;code&gt;M&lt;/code&gt; children pointers and &lt;code&gt;(M - 1)&lt;/code&gt; keys. For example, in a 4-way search tree, a node can have up to 4 children pointers and 3 keys.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-35&quot; src=&quot;./assets/posts/b-tree/m-way-multi-index-node.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 7: M-Way Search Tree (Multi Index) Node&lt;/p&gt;

&lt;p&gt;For multi-level indexes, we can use an M-Way Search Tree, where each node contains keys, child pointers, and record pointers (to the database record).&lt;/p&gt;

&lt;p&gt;However, let&apos;s take an example of using a 10-Way Search Tree for Multi-Level Indexing to see the issue with M-Way Trees. Where each node can have at most 10 children (M - 1) and 9 keys. Insert the keys: &lt;code&gt;10, 20, 30&lt;/code&gt;&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image-50&quot; src=&quot;./assets/posts/b-tree/m-way-issue.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 8: M-Way Search Tree - Out of Control&lt;/p&gt;

&lt;p&gt;While it may seem obvious to first fill up the node keys before branching to a new child, M-Way Search Trees have no strict rules enforced on branching (inserts and deletes). In the worst case, an M-Way Search Tree could have a length of &lt;code&gt;N&lt;/code&gt; for N number of keys, which is as bad as a linear search.

&lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;2. B Trees&lt;/summary&gt;
&lt;p&gt;In short, B-trees are M-Way trees with rules. The 4 rules:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A node should have at least &lt;code&gt;⌈M/2⌉&lt;/code&gt; children before creating a new child node to control the height of the M-Way Search Tree.&lt;/li&gt;
&lt;li&gt;The root node can have a minimum of 2 children without the restriction of Point 1.&lt;/li&gt;
&lt;li&gt;All leaf nodes should be at the same level.&lt;/li&gt;
&lt;li&gt;The creation process is bottom-up.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Taking an example, M = 4 (4 children, 3 keys), starting with keys: &lt;code&gt;[10, 20, 40, 50]&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;Initial Insertion:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Insert 10: The tree is empty, so 10 becomes the first key in the root node.&lt;/li&gt;
&lt;li&gt;Insert 20: 20 is greater than 10, so it is placed in the same node, resulting in &lt;code&gt;[10, 20]&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Insert 40: 40 is greater than both 10 and 20, so it is placed in the same node, resulting in &lt;code&gt;[10, 20, 40]&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;img class=&quot;center-image-0 center-image-70&quot; src=&quot;./assets/posts/b-tree/b-tree-2.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 9: B Tree, Insertion and Overflow (1)&lt;/p&gt;

&lt;p&gt;Handling Overflow:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Insert 50: The node now has 4 keys, exceeding the limit of 3 keys per node. This requires splitting the node.&lt;/li&gt;
&lt;li&gt;The middle key, 40, will be promoted to a new root node.&lt;/li&gt;
&lt;li&gt;The keys are split into two nodes: &lt;code&gt;[10, 20]&lt;/code&gt; and &lt;code&gt;[50]&lt;/code&gt;, with 40 as the root.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Adding more keys &lt;code&gt;[60, 70, 70]&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Insert 60: Goes to the right node &lt;code&gt;[50]&lt;/code&gt;, resulting in &lt;code&gt;[50, 60]&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Insert 70: Goes to the right node &lt;code&gt;[50, 60]&lt;/code&gt;, resulting in &lt;code&gt;[50, 60, 70]&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;img class=&quot;center-image-0 center-image&quot; src=&quot;./assets/posts/b-tree/b-tree-3.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 10: B Tree, Insertion and Overflow (2)&lt;/p&gt;

&lt;p&gt;Handling Overflow in Right Node:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Insert 80: The right node now has 4 keys, exceeding the limit. The middle key, 70, is promoted to the root.&lt;/li&gt;
&lt;li&gt;The keys are split into two nodes: &lt;code&gt;[50, 60]&lt;/code&gt; and &lt;code&gt;[80]&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Adding more keys &lt;code&gt;[30, 35]&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Insert 30: Goes to the left node &lt;code&gt;[10, 20]&lt;/code&gt;, resulting in &lt;code&gt;[10, 20, 30]&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Insert 35: The left node &lt;code&gt;[10, 20, 30]&lt;/code&gt; now has 4 keys, exceeding the limit. The middle key, 30, will be promoted to the root.&lt;/li&gt;
&lt;li&gt;The keys are split into two nodes: &lt;code&gt;[10, 20] and [35]&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;img class=&quot;center-image-0 center-image-100&quot; src=&quot;./assets/posts/b-tree/b-tree-4.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 11: B Tree, Insertion and Overflow (3)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The root now has &lt;code&gt;[30, 40, 70]&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Children: &lt;code&gt;[10, 20]&lt;/code&gt;, &lt;code&gt;[35]&lt;/code&gt;, &lt;code&gt;[50, 60]&lt;/code&gt;, &lt;code&gt;[80]&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Adding more keys &lt;code&gt;[5, 15]&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Insert 5: Goes to the leftmost node &lt;code&gt;[10, 20]&lt;/code&gt;, resulting in &lt;code&gt;[5, 10, 20]&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Insert 15: The leftmost node &lt;code&gt;[5, 10, 20]&lt;/code&gt; now has 4 keys, exceeding the limit. The middle key, 15, will be promoted to the parent node.&lt;/li&gt;
&lt;/ul&gt;

&lt;img class=&quot;center-image-0 center-image-100&quot; src=&quot;./assets/posts/b-tree/b-tree-5.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 12: B Tree, Insertion and Overflow (3)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The node &lt;code&gt;[30, 40, 70]&lt;/code&gt; will now have &lt;code&gt;[15, 30, 40, 70]&lt;/code&gt;, and needs to split because it has exceeded the limit.&lt;/li&gt;
&lt;li&gt;The middle key, 40, will be promoted to a new root.&lt;/li&gt;
&lt;li&gt;The keys are split into three nodes: &lt;code&gt;[15, 30]&lt;/code&gt; and &lt;code&gt;[70]&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Re-arrange the links/connections.&lt;/li&gt;
&lt;/ul&gt;

&lt;img class=&quot;center-image-0 center-image&quot; src=&quot;./assets/posts/b-tree/b-tree-6.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 13: B Tree, Final Form&lt;/p&gt;

&lt;p&gt;Note: Splitting the node in the above example is &lt;code&gt;⌈M/2⌉&lt;/code&gt; (Ciel), which makes it left-biased, whereas choosing &lt;code&gt;⌊M/2⌋&lt;/code&gt; (Floor) is still valid and would be right-biased.&lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;3. B+ Trees&lt;/summary&gt;

&lt;p&gt;B+ Tree is a variant of a B Tree. In a B Tree, every node has keys with record pointers, as shown in Figure 7. In contrast, a B+ Tree does not have record pointers in every node. Instead, only the leaf nodes have record pointers.&lt;/p&gt;

&lt;img class=&quot;center-image-0 center-image&quot; src=&quot;./assets/posts/b-tree/b-plus-tree.svg&quot; /&gt;
&lt;p class=&quot;figure-header&quot;&gt;Figure 13: B+ Tree&lt;/p&gt;

&lt;p&gt;Every key in the B+ Tree has its copy in the leaf node along with its record pointer. Additionally, the leaf nodes are connected, forming a linked list, making the leaf-node level a dense index, which matches the format of the multi-level index we wanted (Figure 4).&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;clear-hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot;&gt;4. References&lt;/summary&gt;
&lt;pre style=&quot;max-height: 300px&quot;&gt;&lt;code&gt;&quot;Platter,&quot; Wikipedia. [Online]. Available: https://en.wikipedia.org/wiki/Platter.
&quot;Sector,&quot; Wikipedia. [Online]. Available: https://en.wikipedia.org/wiki/Sector.
&quot;Random-access memory,&quot; Wikipedia. [Online]. Available: https://en.wikipedia.org/wiki/Random-access_memory.
&quot;Database index,&quot; Wikipedia. [Online]. Available: https://en.wikipedia.org/wiki/Database_index.
&quot;Dense Index,&quot; MLWiki. [Online]. Available: https://mlwiki.org/index.php/Dense_Index.
&quot;Sparse Index,&quot; MLWiki. [Online]. Available: https://mlwiki.org/index.php/Sparse_Index.
&quot;Binary search tree,&quot; Wikipedia. [Online]. Available: https://en.wikipedia.org/wiki/Binary_search_tree.
&quot;B-tree,&quot; Wikipedia. [Online]. Available: https://en.wikipedia.org/wiki/B-tree.
&quot;B+ tree,&quot; Wikipedia. [Online]. Available: https://en.wikipedia.org/wiki/B%2B_tree.
&quot;M-ary tree,&quot; Wikipedia. [Online]. Available: https://en.wikipedia.org/wiki/M-ary_tree.
&quot;B-Trees and B+ Trees,&quot; YouTube. [Online]. Available: https://www.youtube.com/watch?v=aZjYr87r1b8.
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;</content><author><name>Adesh Nalpet Adimurthy</name></author><category term="Code on the Road" /><category term="Database" /><category term="Data Structures" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pyblog.xyz/assets/featured/webp/bee-tree.webp" /><media:content medium="image" url="https://pyblog.xyz/assets/featured/webp/bee-tree.webp" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Debezium: PostgreSQL Change Data Capture (CDC)</title><link href="https://pyblog.xyz/debezium-postgres-cdc" rel="alternate" type="text/html" title="Debezium: PostgreSQL Change Data Capture (CDC)" /><published>2023-10-16T00:00:00+00:00</published><updated>2023-10-16T00:00:00+00:00</updated><id>https://pyblog.xyz/debezium-postgres-cdc</id><content type="html" xml:base="https://pyblog.xyz/debezium-postgres-cdc">&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/featured/webp/debezium-postgres-cdc.webp&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 1: Debezium Postgres Connector&lt;/p&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;1. Goal&lt;/summary&gt;
&lt;p&gt;Set up Debezium to capture row-level changes in the schemas of a PostgreSQL database and publish to Kafka topic(s).&lt;/p&gt;

&lt;p&gt;The high-level architecture is unquestionably explained in the above diagram 😎. Pikachu, aka Debezium PostgreSQL Connector, detects and carries/publishes row-level change events to Kafka topic(s) for configured Postgres tables.&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot;&gt;2. Definitions&lt;/summary&gt;

&lt;h3 id=&quot;cdc&quot;&gt;2.1. Change Data Capture (CDC)&lt;/h3&gt;
&lt;p&gt;In databases, change data capture (CDC) is a set of software design patterns used to determine and track the data that has changed (the &quot;deltas&quot;) so that action can be taken using the changed data [1].&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3 id=&quot;debezium&quot;&gt;2.2. Debezium&lt;/h3&gt;
&lt;p&gt;Debezium is a set of distributed services to capture changes in your databases so that your applications can see those changes and respond to them. Debezium records all row-level changes within each database table in a change event stream, and applications simply read these streams to see the change events in the same order in which they occurred [2].&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3 id=&quot;connectors&quot;&gt;2.3. Debezium Connectors&lt;/h3&gt;
&lt;p&gt;A library of connectors that capture changes from a variety of database management systems and produce events with very similar structures, making it far easier for your applications to consume and respond to the events regardless of where the changes originated [3].&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3 id=&quot;postgresql-connector&quot;&gt;2.4. Debezium connector for PostgreSQL&lt;/h3&gt;
&lt;p&gt;The Debezium PostgreSQL connector captures row-level changes in the schemas of a PostgreSQL database [4].&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3 id=&quot;kafka&quot;&gt;2.5. Kafka&lt;/h3&gt;
&lt;p&gt;Apache Kafka is a distributed data store optimized for ingesting and processing streaming data in real-time. Streaming data is data that is continuously generated by thousands of data sources, which typically send the data records in simultaneously [5].&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3 id=&quot;kafka-connect&quot;&gt;2.6. Kafka Connect&lt;/h3&gt;
&lt;p&gt;Kafka Connect is a tool for scalably and reliably streaming data between Apache Kafka and other systems. It makes it simple to quickly define connectors that move large collections of data into and out of Kafka [6].&lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot;&gt;3. Define Services (Docker-Compose)&lt;/summary&gt;
&lt;p&gt;As a generate note, If you use Mac M1/M2, ensure the docker image has &lt;code&gt;linux/arm64&lt;/code&gt; OS/ARCH.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/docker-debezium-arch.png&quot; /&gt; &lt;/p&gt;

&lt;p&gt;Section 3.x covers the breakdown of each service/docker image used in &lt;code&gt;docker-compose.yaml&lt;/code&gt; file, if you have worked with docker before, skip the section and pick up the entire file from section 4 instead.&lt;/p&gt;

&lt;p&gt;Break down of services in &lt;code&gt;docker-compose.yaml&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Postgres&lt;/b&gt;: The database containing the table(s) for which CDC is tracked.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;b&gt;Kafka&lt;/b&gt; and &lt;b&gt;Zookeeper&lt;/b&gt;: The event broker where CDC events are stored.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;b&gt;Schema Registry&lt;/b&gt;: To serialize/deserialize CDC message(s) using Avro schema.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;b&gt;Debezium&lt;/b&gt;: Responsible for capturing the row-level changes made to Postgres table(s) and streaming them to a Kafka topic.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot;&gt;3.1. PostgreSQL&lt;/summary&gt;
&lt;p&gt;&lt;a href=&quot;https://hub.docker.com/r/debezium/postgres&quot;&gt;debezium/postgres&lt;/a&gt;: PostgreSQL for use with Debezium change data capture. This image is based upon &lt;a href=&quot;https://hub.docker.com/_/postgres/&quot;&gt;postgres&lt;/a&gt; along with &lt;a href=&quot;https://www.postgresql.org/docs/11/logicaldecoding-explanation.html&quot;&gt;logical decoding&lt;/a&gt; plugin from &lt;a href=&quot;https://github.com/debezium/&quot;&gt;Debezium&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://hub.docker.com/r/dpage/pgadmin4/&quot;&gt;dpage/pgadmin4&lt;/a&gt; (Optional): Web browser version of &lt;a href=&quot;https://www.pgadmin.org/download/pgadmin-4-container/&quot;&gt;pgAdmin 4&lt;/a&gt; for the ease of running DML and DDL operations on PostgreSQL.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
postgres:
  image: debezium/postgres:13-alpine
  ports:
    - 5432:5432
  environment:
    - POSTGRES_USER=admin
    - POSTGRES_PASSWORD=root
    - POSTGRES_DB=pyblog

pgadmin:
  image: dpage/pgadmin4
  environment:
    - PGADMIN_DEFAULT_EMAIL=admin@admin.com
    - PGADMIN_DEFAULT_PASSWORD=root
  ports:
    - &apos;5050:80&apos;
  restart: always
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot;&gt;3.2. Kafka and Zookeeper&lt;/summary&gt;

&lt;p&gt;Confluent Platform Docker images for Kafka: &lt;a href=&quot;https://hub.docker.com/r/confluentinc/cp-enterprise-kafka/&quot;&gt;confluentinc/cp-enterprise-kafka/postgres&lt;/a&gt; and Zookeeper: &lt;a href=&quot;https://hub.docker.com/r/confluentinc/cp-zookeeper&quot;&gt;confluentinc/cp-zookeeper&lt;/a&gt;. The below example is for version &lt;code&gt;7.3&lt;/code&gt;, a more recent version, i.e., &lt;code&gt;7.5&lt;/code&gt; onwards, Confluent recommends &lt;a href=&quot;https://docs.confluent.io/platform/current/kafka-metadata/kraft.html&quot;&gt;KRaft&lt;/a&gt; mode for new deployments, and Zookeeper is deprecated.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
zookeeper:
  image: confluentinc/cp-zookeeper:7.3.5
  environment:
    ZOOKEEPER_CLIENT_PORT: 2181

kafka:
  image: confluentinc/cp-enterprise-kafka:7.3.5
  depends_on: [zookeeper]
  environment:
    KAFKA_BROKER_ID: 1
    KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
    KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    KAFKA_JMX_PORT: 9991
  ports:
    - 9092:9092
&lt;/code&gt;&lt;/pre&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot;&gt;3.3. Debezium and Schema Registry&lt;/summary&gt;

&lt;p&gt;&lt;a href=&quot;https://hub.docker.com/r/debezium/connect&quot;&gt;debezium/connect&lt;/a&gt; image defines a runnable &lt;a href=&quot;https://kafka.apache.org/documentation.html#connect&quot;&gt;Kafka Connect&lt;/a&gt; service preconfigured with all Debezium connectors; it monitors database management system(s) for changing data and then forwards those changes directly into Kafka topics organized by server, database, and table.
&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://hub.docker.com/r/confluentinc/cp-schema-registry&quot;&gt;confluentinc/cp-schema-registry&lt;/a&gt; enables client applications to read and write Avro data, in this case, to serialize and deserialize CDC messages.
&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
debezium:
  image: debezium/connect:2.4
  environment:
    BOOTSTRAP_SERVERS: kafka:9092
    GROUP_ID: 1
    CONFIG_STORAGE_TOPIC: connect_configs
    OFFSET_STORAGE_TOPIC: connect_offsets
    STATUS_STORAGE_TOPIC: my_status_topic
    CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
    CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
  depends_on: [kafka]
  ports:
    - 8083:8083

schema-registry:
  image: confluentinc/cp-schema-registry:7.3.5
  environment:
    - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
    - SCHEMA_REGISTRY_HOST_NAME=schema-registry
    - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8085,http://localhost:8085
  ports:
    - 8085:8085
  depends_on: [zookeeper, kafka]
&lt;/code&gt;&lt;/pre&gt;

&lt;/details&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;4. Start Services (Docker-Compose)&lt;/summary&gt;

&lt;p&gt;The complete &lt;code&gt;docker-compose.yaml&lt;/code&gt; to set up Postgres with debezium and publish data change events to Kafka:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Note&lt;/b&gt;: At the time of writing this post, the services use the current stable version(s); visit the docker hub page for the latest stable version(s).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;version: &quot;3.7&quot;
services:
  postgres:
    image: debezium/postgres:13-alpine
    ports:
      - 5432:5432
    environment:
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=root
      - POSTGRES_DB=pyblog

  pgadmin:
    image: dpage/pgadmin4
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@admin.com
      - PGADMIN_DEFAULT_PASSWORD=root
    ports:
      - &apos;5050:80&apos;
    restart: always

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.5
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-enterprise-kafka:7.3.5
    depends_on: [zookeeper]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9991
    ports:
      - 9092:9092

  debezium:
    image: debezium/connect:2.4
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: my_status_topic
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
    depends_on: [kafka]
    ports:
      - 8083:8083

  schema-registry:
    image: confluentinc/cp-schema-registry:7.3.5
    environment:
      - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
      - SCHEMA_REGISTRY_HOST_NAME=schema-registry
      - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8085,http://localhost:8085
    ports:
      - 8085:8085
    depends_on: [zookeeper, kafka]
&lt;/code&gt;&lt;/pre&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h3&gt;4.1. Run all containers&lt;/h3&gt;

&lt;p&gt;Clean-up (Optional) and Run (Create and Start) containers:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker rm -f $(docker ps -a -q)
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/debezium-docker-compose-up.png&quot; /&gt; &lt;/p&gt;
&lt;p&gt;Make a note of the assigned network name; from the above output, the network name is: &lt;code&gt;enricher_default&lt;/code&gt;. To create a custom network, refer &lt;a href=&quot;https://docs.docker.com/compose/networking/&quot;&gt;Networking in Compose&lt;/a&gt;&lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;5. Configure Services&lt;/summary&gt;

&lt;p&gt;End-to-end configuration for all the services to create the CDC pipeline:&lt;/p&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;5.1. Create Postgres Tables&lt;/summary&gt;

&lt;p&gt;a. Login to pgAdmin &lt;a href=&quot;http://localhost:5050&quot;&gt;localhost:5050&lt;/a&gt; with email/password (admin@admin.com/root) configured in &lt;code&gt;pgadmin&lt;/code&gt; container (refer: &lt;code&gt;docker-compose.yaml&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/debezium-pg-login.png&quot; /&gt; &lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;p&gt;b. Register database server with username/password (admin/root) and hostname (postgres) configured in &lt;code&gt;postgres&lt;/code&gt; container (refer: &lt;code&gt;docker-compose.yaml&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/debezium-pg-register.png&quot; /&gt; &lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;p&gt;c. Create and Alter table queries:&lt;/p&gt;
&lt;p&gt;Example: Create a table &lt;code&gt;user-profile&lt;/code&gt; from the query tool to track data change events in this table. &lt;b&gt;Skip this&lt;/b&gt;; if you already have your own schema for Postgres database tables for which CDC has to be configured.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 55%;&quot; src=&quot;./assets/posts/debezium-pg-query-tool.png&quot; /&gt; &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE TABLE user_profile (
  user_id INT NOT NULL,
  full_name VARCHAR(64) NOT NULL,
  email VARCHAR(255) NOT NULL,
  PRIMARY KEY (user_id),
  UNIQUE (email)
);

ALTER TABLE user_profile REPLICA IDENTITY FULL;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Setting the table&apos;s replication identity to &lt;code&gt;full&lt;/code&gt; infers that the entire row is used as the identifier for change-tracking.&lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;5.2. Set up Debezium Postgres Connector (Kafka Connect)&lt;/summary&gt;

&lt;p&gt;a. Check the status of the Kafka Connect service:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -H &quot;Accept:application/json&quot; localhost:8083/&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;./assets/posts/debezium-connector-status.png&quot; /&gt; &lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;p&gt;b. Register the Debezium Postgres connector:&lt;/p&gt;
&lt;p&gt;Create a file &lt;code&gt;debezium.json&lt;/code&gt;, the Debezium Postgres connector configuration, where &lt;code&gt;user_profile&lt;/code&gt; is the table being tracked&lt;/p&gt; 

&lt;pre&gt;&lt;code&gt;{
    &quot;name&quot;: &quot;postgresql-connector&quot;,
    &quot;config&quot;: {
        &quot;connector.class&quot;: &quot;io.debezium.connector.postgresql.PostgresConnector&quot;,
        &quot;plugin.name&quot;: &quot;pgoutput&quot;,
        &quot;database.hostname&quot;: &quot;postgres&quot;,
        &quot;database.port&quot;: &quot;5432&quot;,
        &quot;database.user&quot;: &quot;admin&quot;,
        &quot;database.password&quot;: &quot;root&quot;,
        &quot;database.dbname&quot;: &quot;pyblog&quot;,
        &quot;database.server.name&quot;: &quot;postgres&quot;,
        &quot;table.include.list&quot;: &quot;public.user_profile&quot;,
        &quot;table.whitelist&quot;: &quot;public.user_profile&quot;,
        &quot;database.tcpKeepAlive&quot;: true,
        &quot;topic.prefix&quot;: &quot;topic_user_profile&quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command uses the Kafka Connect service’s API to submit a POST request against the &lt;code&gt;/connectors&lt;/code&gt; resource with a JSON document that describes the new connector (called &lt;code&gt;postgresql-connector&lt;/code&gt;).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -i -X POST -H &quot;Accept:application/json&quot; -H &quot;Content-Type:application/json&quot; localhost:8083/connectors/ --data &quot;@debezium.json&quot;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;./assets/posts/debezium-connector-register.png&quot; /&gt; &lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;p&gt;c. Check the list of connectors registered with Kafka Connect:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -H &quot;Accept:application/json&quot; localhost:8083/connectors/&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;./assets/posts/debezium-connector-list.png&quot; /&gt; &lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;5.3. View Kafka Messages&lt;/summary&gt;

&lt;p&gt;a. Pull kafkacat docker image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker pull confluentinc/cp-kafkacat:7.1.9&lt;/code&gt;&lt;/pre&gt;

&lt;a href=&quot;https://hub.docker.com/r/confluentinc/cp-kafkacat/&quot;&gt;kafkacat&lt;/a&gt; is a commandline tool for interacting with Kafka brokers. It can be used to produce and consume messages, as well as query metadata.

&lt;hr class=&quot;hr&quot; /&gt;

&lt;p&gt;b. Listing topics on a broker:&lt;/p&gt;
&lt;p&gt;For the Kafka broker is accessible as &lt;code&gt;kafka:9092&lt;/code&gt; on the Docker network &lt;code&gt;enricher_default&lt;/code&gt;, list topics by running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --tty \
--network enricher_default \
confluentinc/cp-kafkacat:7.1.9 \
kafkacat -b kafka:9092 \
-L
&lt;/code&gt;&lt;/pre&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;p&gt;c. Consuming messages from a topic:&lt;/p&gt;

&lt;p&gt;For the Kafka broker is accessible as &lt;code&gt;kafka:9092&lt;/code&gt; on the Docker network &lt;code&gt;enricher_default&lt;/code&gt;, print messages and their associated metadata from topic &lt;code&gt;topic_user_profile.public.user_profile&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --tty \
--network enricher_default \
confluentinc/cp-kafkacat:7.1.9 \
kafkacat -b kafka:9092 -C \
-t topic_user_profile.public.user_profile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;./assets/posts/debezium-connector-error.png&quot; /&gt; &lt;/p&gt;

&lt;p&gt;If you get the error &lt;code&gt;% ERROR: Topic topic_user_profile.public.user_profile error: Broker: Leader not available&lt;/code&gt;, run the same command again!&lt;/p&gt;

&lt;/details&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;6. Moment of Truth 🚀&lt;/summary&gt;

&lt;p&gt;a. Insert/Update a row in Postgres table:&lt;/p&gt;
&lt;p&gt;For the table, Debezium CDC is configured; Following the example, creating a row in &lt;code&gt;user_profile&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;INSERT INTO user_profile
 (user_id, full_name, email) 
VALUES
 (1,&apos;John Ross&apos;, &apos;john.ross@pyblog.xyz&apos;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;b. Validate messages in Kafka topic:&lt;/p&gt;
&lt;p&gt;Consuming the Kafka messages, as mentioned in 3.2.4, section c, the output for inserting a new row:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/posts/debezium-connector-cdc.png&quot; /&gt; &lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;p&gt;c. Stop services and delete Docker Containers:&lt;/p&gt;

&lt;p&gt;To stop all the services and delete the docker containers, run:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-compose down
docker rm -f $(docker ps -a -q)&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/debezium-connector-kill.png&quot; /&gt; &lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot;&gt;7. Conclusion&lt;/summary&gt;
&lt;p&gt;The post demonstrated how to capture data change events with Debezium by streaming data from a PostgreSQL database to Kafka.&lt;/p&gt;

&lt;p&gt;Change Data Capture (CDC) has a lot of use cases, some of the top uses:
Updating/Invalidating Cache, Enriching Data/Logs from Entity Identifiers, Real-time data loading into Data Warehouse(s) and search engine(s), Synchronize data (on-premises to cloud), Microservices Data exchange with the Outbox Pattern and many more.
&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Whats&apos; next&lt;/b&gt;: In the next post, we see how to process the CDC events with stream processing engines such as &lt;a href=&quot;https://flink.apache.org/&quot;&gt;Apache Flink&lt;/a&gt;, cache the transformed data (&lt;a href=&quot;https://flink.apache.org/2021/01/18/using-rocksdb-state-backend-in-apache-flink-when-and-how/&quot;&gt;RockDB&lt;/a&gt;), and enrich/cleanse other events with more meaningful information than their raw versions without having to query the source database.&lt;/p&gt;
&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot;&gt;8. References&lt;/summary&gt;

&lt;pre&gt;&lt;code&gt;
[1] Wikipedia Contributors, “Change data capture,” Wikipedia, Feb. 04, 2019. https://en.wikipedia.org/wiki/Change_data_capture

[2] “Debezium Documentation :: Debezium Documentation,” debezium.io. https://debezium.io/documentation/reference/stable/index.html

[3] “Connectors :: Debezium Documentation,” debezium.io. https://debezium.io/documentation/reference/stable/connectors/index.html

[4] “Debezium connector for PostgreSQL :: Debezium Documentation,” debezium.io. https://debezium.io/documentation/reference/stable/connectors/postgresql.html (accessed Oct. 21, 2023).

[5] “What is Apache Kafka? | AWS,” Amazon Web Services, Inc. https://aws.amazon.com/msk/what-is-kafka/

[6] “Kafka Connect | Confluent Documentation,” docs.confluent.io. https://docs.confluent.io/platform/current/connect/index.html
‌
‌[7] J. P. Alvim, “Streaming data from PostgreSQL to s3 using Debezium, Kafka and Python,” Medium, Feb. 11, 2023. https://medium.com/@joaopaulonobregaalvim/streaming-data-from-postgresql-to-s3-using-debezium-kafka-and-python-16c6cdd6dc1e (accessed Oct. 21, 2023).

[8] D. Danushka, “Configuring Debezium to Capture PostgreSQL Changes with Docker Compose,” Tributary Data, Aug. 16, 2021. https://medium.com/event-driven-utopia/configuring-debezium-to-capture-postgresql-changes-with-docker-compose-224742ca5372 (accessed Oct. 21, 2023).

&lt;/code&gt;&lt;/pre&gt;

&lt;/details&gt;</content><author><name>Adesh Nalpet Adimurthy</name></author><category term="System Wisdom" /><category term="System Design" /><category term="Database" /><summary type="html">Figure 1: Debezium Postgres Connector</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://pyblog.xyz/assets/featured/webp/debezium-postgres-cdc.webp" /><media:content medium="image" url="https://pyblog.xyz/assets/featured/webp/debezium-postgres-cdc.webp" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Postgres as a Graph Database</title><link href="https://pyblog.xyz/postgres-as-graph" rel="alternate" type="text/html" title="Postgres as a Graph Database" /><published>2023-09-27T00:00:00+00:00</published><updated>2023-09-27T00:00:00+00:00</updated><id>https://pyblog.xyz/postgres-as-graph</id><content type="html" xml:base="https://pyblog.xyz/postgres-as-graph">&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/featured/neo4j-vs-pgsql.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Neo4j vs PostgreSQL&lt;/p&gt;

&lt;p&gt;Have you ever come across the need to store a graph in a relational database because using/onboarding a graph database for a small use-case is overkill?&lt;/p&gt;

&lt;p&gt;Before jumping into using a relational database like MySQL or PostgreSQL as a graph database, let’s lay down the fundamentals:&lt;/p&gt;

&lt;h2 id=&quot;what-is-a-graph&quot;&gt;What is a Graph?&lt;/h2&gt;
&lt;p&gt;A graph is a set of vertices/nodes interconnected by edges/links. The edges can be directed (unidirectional or bidirectional) or undirected (no orientation, only infers a connection between nodes).&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 75%;&quot; src=&quot;./assets/posts/graph-types.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 1: (Left to Right) Undirected, Unidirectional and Bidirectional&lt;/p&gt;

&lt;h2 id=&quot;graph-data-structure-in-java&quot;&gt;Graph Data Structure in Java&lt;/h2&gt;
&lt;p&gt;A vertex represents the entity, and an edge represents the relationship between entities:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Vertex {
    Integer label;
    // standard constructor, getters, setters
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The graph would be a collection of vertices and edges:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Graph {
    private Map&amp;lt;Vertex, List&amp;lt;Vertex&amp;gt;&amp;gt; adjVertices;
    // standard constructor, getters, setters

    void addVertex(Integer label) {
        adjVertices.putIfAbsent(new Vertex(label), new ArrayList&amp;lt;&amp;gt;());
    }

    void addEdge(Integer label1, Integer label2) {
        Vertex v1 = new Vertex(label1);
        Vertex v2 = new Vertex(label2);
        adjVertices.get(v1).add(v2);
        adjVertices.get(v2).add(v1);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Graph createGraph() {
    Graph graph = new Graph();
    graph.addVertex(1);
    graph.addVertex(2);
    graph.addVertex(3);
    graph.addVertex(4);
    graph.addVertex(5);
    graph.addVertex(6);
    
    graph.addEdge(1, 2);
    graph.addEdge(1, 3);
    graph.addEdge(2, 1);
    graph.addEdge(2, 4);
    graph.addEdge(3, 5);
    graph.addEdge(3, 6);
    
    return graph;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 75%;&quot; src=&quot;./assets/posts/graph-example-1.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 2: Graph visual and map data-structure representation&lt;/p&gt;

&lt;h2 id=&quot;graph-data-structures-in-postgres&quot;&gt;Graph Data Structures in Postgres&lt;/h2&gt;

&lt;p&gt;Storing the graph &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Map&amp;lt;Vertex, List&amp;lt;Vertex&amp;gt;&amp;gt;&lt;/code&gt; in a relational database such as Postgres as-is would mean creating two tables: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Vertex&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Graph&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CREATE TABLE vertex (
    vertex_id INT,
    PRIMARY KEY(vertex_id)
    // Other columns
);

CREATE TABLE graph (
    graph_id INT,
    vertex_id INT,
    vertices INTEGER[]

    PRIMARY KEY(graph_id),
    CONSTRAINT fk_vertex_id
    FOREIGN KEY(vertex_id)
    REFERENCES vertex(vertex_id)
    ON DELETE NO ACTION
);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Ideally, each element in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;graph&lt;/code&gt; -&amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vertices&lt;/code&gt; array should represent foreign keys to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vertex&lt;/code&gt; table.&lt;/p&gt;

&lt;p&gt;Relational databases operate most efficiently on properly normalized data models. Arrays are not relational data structures, by definition they are sets; while the SQL standard supports defining foreign keys on array elements, PostgreSQL currently does not support it. However, there is an ongoing effort to implement this.&lt;/p&gt;

&lt;p&gt;A better way to store a graph in Postgres is by creating two tables: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vertex&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;edge&lt;/code&gt;
&lt;img class=&quot;center-image&quot; style=&quot;width: 90%;&quot; src=&quot;./assets/posts/graph-example-2.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 3: Graph representation - List of Edges&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CREATE TABLE vertex (
    vertex_id INT,
    PRIMARY KEY(vertex_id)
    // Other columns
);

CREATE TABLE edge (
    source_vertex INT REFERENCES vertex(vertex_id),
    target_vertex INT REFERENCES vertex(vertex_id),
    PRIMARY KEY (source_vertex, target_vertex)
);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The table &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;edge&lt;/code&gt; represents the relationship between two vertices; the composite primary key &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(source_vertex, target_vertex)&lt;/code&gt; ensures that each edge is unique.&lt;/p&gt;

&lt;h2 id=&quot;real-world-use-case&quot;&gt;Real World Use-case&lt;/h2&gt;
&lt;p&gt;Zigbee protocol [2] and its mesh topology is a perfect example of a tree data structure. Zigbee has been around for a long time, initially conceived in the early 1990s, and is a widely wireless technology designed to facilitate low-cost, low-power wireless Internet of Things (IoT) networks.&lt;/p&gt;

&lt;p&gt;Moving on to the technical details, Zigbee Devices Types:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Zigbee Coordinator (ZC)&lt;/li&gt;
  &lt;li&gt;Zigbee Router (ZR)&lt;/li&gt;
  &lt;li&gt;Zigbee Endpoint Device (ZED)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 60%;&quot; src=&quot;./assets/posts/zigbee-example-1.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 4: Zigbee Mesh Topology&lt;/p&gt;

&lt;p&gt;The Zigbee network has exactly one &lt;strong&gt;Zigbee Coordinator (ZC)&lt;/strong&gt; responsible for forming and coordinating the network. The &lt;strong&gt;Zigbee Router (ZR)&lt;/strong&gt; represents intermediate nodes to assist in relaying data between nodes in the network and is instrumental in building the Zigbee network. The &lt;strong&gt;Zigbee Endpoint Device (ZED)&lt;/strong&gt; are nodes that are logically attached to a Zigbee Router (ZR) and are typically devices such as lights, sensors, switches, etc., and communicates only with the Zigbee Router (parent).&lt;/p&gt;

&lt;h3 id=&quot;create-queries&quot;&gt;Create Queries&lt;/h3&gt;
&lt;p&gt;Tables to store ZC/ZR and their relationships in Postgres:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; CREATE TABLE router (
    id SERIAL PRIMARY KEY,
    serial_number VARCHAR(64),
    role VARCHAR(32)
);

CREATE TABLE neighbor (
    PRIMARY KEY (source_router, target_router),
    source_router INTEGER REFERENCES router(id),
    target_router INTEGER REFERENCES router(id)
);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;router&lt;/code&gt; table has ZC and ZR, distinguished by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;role&lt;/code&gt; column; in a Zigbee network, ZC and ZR are essentially routers, where ZC is often called Leader Router/Co-ordinator. The relationship between &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ZC and ZR(s)&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ZR and ZR(s)&lt;/code&gt; is stored in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;neighbor&lt;/code&gt; table.&lt;/p&gt;

&lt;h3 id=&quot;insert-queries&quot;&gt;Insert Queries&lt;/h3&gt;
&lt;p&gt;The data inserts for the mesh topology as shown in Figure 4 (without leaf nodes/end devices):&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;INSERT INTO router (serial_number, role) VALUES (&apos;ACX7100-67600&apos;, &apos;ZC&apos;);
INSERT INTO router (serial_number, role) VALUES (&apos;ACX7100-67601&apos;, &apos;ZR&apos;);
INSERT INTO router (serial_number, role) VALUES (&apos;ACX7100-67602&apos;, &apos;ZR&apos;);
INSERT INTO router (serial_number, role) VALUES (&apos;ACX7100-67603&apos;, &apos;ZR&apos;);
INSERT INTO router (serial_number, role) VALUES (&apos;ACX7100-67604&apos;, &apos;ZR&apos;);
INSERT INTO router (serial_number, role) VALUES (&apos;ACX7100-67605&apos;, &apos;ZR&apos;);
INSERT INTO router (serial_number, role) VALUES (&apos;ACX7100-67606&apos;, &apos;ZR&apos;);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img class=&quot;center-image img-border&quot; style=&quot;width: 60%;&quot; src=&quot;./assets/posts/postgres-router.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 5: Entries in Router&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;INSERT INTO neighbor (source_router, target_router) VALUES (1, 2);
INSERT INTO neighbor (source_router, target_router) VALUES (1, 3);
INSERT INTO neighbor (source_router, target_router) VALUES (1, 6);
INSERT INTO neighbor (source_router, target_router) VALUES (3, 4);
INSERT INTO neighbor (source_router, target_router) VALUES (3, 5);
INSERT INTO neighbor (source_router, target_router) VALUES (6, 7);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img class=&quot;center-image img-border&quot; style=&quot;width: 35%;&quot; src=&quot;./assets/posts/postgres-neighbor.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 6: Entries in Neighbor&lt;/p&gt;

&lt;h3 id=&quot;select-queries&quot;&gt;Select Queries&lt;/h3&gt;
&lt;p&gt;A router (ZC or ZR) has neighbors, and a neighbor router (ZR) also has neighbors (ZR), and this goes on until we have a leaf node (ZED). Querying for all the neighbors of a router = traversing the graph.&lt;/p&gt;

&lt;p&gt;Postgres offers built-in recursive queries, typically used for hierarchical or tree-structured data, i.e., to find all the direct and indirect relations to an entity.&lt;/p&gt;

&lt;p&gt;Get all neighbors (neighbors of neighbors) for a given router id:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WITH RECURSIVE all_neighbors AS (
	SELECT neighbor.target_router
	FROM neighbor
	WHERE neighbor.source_router = 1
	
	UNION
	
	SELECT neighbor.target_router
	FROM neighbor
	JOIN all_neighbors ON neighbor.source_router = all_neighbors.target_router
)
SELECT router.id, router.serial_number
FROM router
JOIN all_neighbors ON router.id = all_neighbors.target_router;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img class=&quot;center-image img-border&quot; style=&quot;width: 40%;&quot; src=&quot;./assets/posts/postgres-all-neighbors.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 7: All interconnected neighbors&lt;/p&gt;

&lt;p&gt;Get all neighbors (neighbors of neighbors - relationships) for a given router id&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WITH RECURSIVE all_neighbors AS (
	SELECT neighbor.source_router, neighbor.target_router
	FROM neighbor
	WHERE neighbor.source_router = 1
	
	UNION
	
	SELECT neighbor.source_router, neighbor.target_router
	FROM neighbor
	JOIN all_neighbors ON neighbor.source_router = all_neighbors.target_router
)
SELECT all_neighbors.source_router, all_neighbors.target_router FROM all_neighbors;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img class=&quot;center-image img-border&quot; style=&quot;width: 35%;&quot; src=&quot;./assets/posts/postgres-neighbors-of-neighbors.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 8: Neighbors of neighbors&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Postgres recursive queries work with circular graphs and will not lead to an infinite loop.&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[1] “7.8. WITH Queries (Common Table Expressions),” PostgreSQL Documentation, May 11, 2023. https://www.postgresql.org/docs/current/queries-with.html#QUERIES-WITH-RECURSIVE

[2] BHIS, “Understanding Zigbee and Wireless Mesh Networking,” Black Hills Information Security, Aug. 27, 2021. https://www.blackhillsinfosec.com/understanding-zigbee-and-wireless-mesh-networking/‌

[3]“Apache AGE,” age.apache.org. https://age.apache.org/

[4] D. Paulus, “Postgres: The Graph Database You Didn’t Know You Had,” dylanpaulus.com. https://www.dylanpaulus.com/posts/postgres-is-a-graph-database
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Adesh Nalpet Adimurthy</name></author><category term="System Wisdom" /><category term="System Design" /><category term="Database" /><summary type="html">Neo4j vs PostgreSQL</summary></entry><entry><title type="html">Documentation: Conceptualization of a Cartogram</title><link href="https://pyblog.xyz/cartograms-documentation" rel="alternate" type="text/html" title="Documentation: Conceptualization of a Cartogram" /><published>2022-07-02T00:00:00+00:00</published><updated>2022-07-02T00:00:00+00:00</updated><id>https://pyblog.xyz/cartograms-documentation</id><content type="html" xml:base="https://pyblog.xyz/cartograms-documentation">&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/featured/solar-system-cartogram.png&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;explanation&quot;&gt;Explanation&lt;/h1&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot; id=&quot;whatisacartogram&quot;&gt; 1. What is a cartogram?&lt;/summary&gt;

&lt;p&gt;Simply put, a cartogram is a map. But a cartogram is a unique type of map that combines statistical information such as population with geographic location. Typically, physical or topographical maps show relative area and distance, but they do not provide any data about the inhabitants or the population of a place. For example, a quick and intuitive view of the world map in relation to population makes it easy for viewers to co-relate the effect and the relative measure&apos;s gravity. &lt;/p&gt;

&lt;p&gt;The basic idea is distorting the map by resizing the regions by population (or any other metric) since the population is among the most important aspects to consider; for example, if malnutrition is high in a vast country, then the severity is much worse than if malnutrition is high in a tiny country.&lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot; id=&quot;howaregridsrelatedtocartograms&quot;&gt; 2. How are grids related to cartograms?&lt;/summary&gt;

&lt;p&gt;With an objective to plot a visually conclusive map by illustrating territories using a method for trading off shape and area.&lt;/p&gt;

&lt;p&gt;It’s vital to ensure the shape or the outline of a region (Example: Country and Province) is preserved, i.e., visualization steps have to be in place so that the resulting cartograms appear similar to the original world cartograms, such that the area is easily recognizable only by its appearance without the explicit need for labels and quickly understand the displayed data.&lt;/p&gt;

&lt;p&gt;While generating a cartogram algorithmically yields good results, the best cartograms out there are the ones that as designed artistically/manually. This boils down to finding a balance between using algorithms to generate cartograms and manually nitpicking fine details - that&apos;s where the grids come into the picture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;./assets/posts/cartograms/hex-grid-cartogram.png&quot; /&gt; &lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 1: Hex grid cartogram. &lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot; id=&quot;choosingtherightgrid&quot;&gt; 3. Choosing the right grid&lt;/summary&gt;

&lt;p&gt;Grids are built from a repetition of simple shapes such as squares and hexagons. Grids have three types of parts: faces (tiles), edges, and vertices.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each face is a two-dimensional surface enclosed by edges. &lt;/li&gt;

&lt;li&gt;Each edge is a one-dimensional line segment ending at two vertices. &lt;/li&gt;

&lt;li&gt;Each vertex is a zero-dimensional point&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;square&quot;&gt;Square&lt;/h3&gt;

&lt;p&gt;One of the most commonly used grids is a square grid. It&apos;s simple, easy to work with, and maps nicely onto a computer screen. The location uses cartesian coordinates (x, y), and the axes are orthogonal. Not to mention, the coordinate system is the same even if the squares are angled in an isometric or axonometric projection.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Squares are 4-sided polygons. &lt;/li&gt;

&lt;li&gt;Squares have all the sides the same length. &lt;/li&gt;

&lt;li&gt;They have 4 sides and 4 corners.&lt;/li&gt;

&lt;li&gt;Each side is shared by 2 squares. &lt;/li&gt;

&lt;li&gt;Each corner is shared by 4 squares.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hexagon&quot;&gt;Hexagon&lt;/h3&gt;

&lt;p&gt;Hexagonal grids are the next commonly used grids, as they offer less distortion of distances than square grids because each hexagon has more non-diagonal neighbors than a square (diagonals distort grid distances). Moreover, hexagons have a pleasing appearance (the honeycomb is a good example). As for the grids, the position is either pointy tops and flat sides or flat tops and pointy sides.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/cartograms/hexagon-grid-details.png&quot; /&gt; &lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 2: Modified from original Image source: &lt;a href=&quot;https://www.redblobgames.com/grids/hexagons&quot; target=&quot;_blank&quot;&gt;@redblobgames&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Hexagons are 6-sided polygons. &lt;/li&gt;

&lt;li&gt;Regular hexagons have all the sides the same length. &lt;/li&gt;

&lt;li&gt;They have 6 sides and 6 corners.&lt;/li&gt;

&lt;li&gt;Each side is shared by 2 hexagons. &lt;/li&gt;

&lt;li&gt;Each corner is shared by 3 hexagons.&lt;/li&gt;

&lt;li&gt;Typically, the orientations for hex grids are vertical columns (flat-topped) and horizontal rows (pointy-topped).&lt;/li&gt;
&lt;/ul&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot; id=&quot;hexagonsvssquares&quot;&gt; 4. Hexagons vs Squares&lt;/summary&gt;

&lt;h3 id=&quot;squaregrids&quot;&gt;Square grids&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Square grids are universally used in Raster datasets in GIS. &lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ease of definition and storage: the only explicit geographical information necessary to define a raster grid are the coordinates of the origin, cell size, and grid dimensions, i.e., the number of cells in each direction. The attribute data can be stored as an aspatial matrix, and the geographical location of any cell can be derived from the cell’s position relative to the origin - this makes data storage and retrieval easier since the coordinates of the vertices of each grid cell are not explicitly stored.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ease of resampling to different spatial scales: increasing the spatial resolution of a square grid is just a matter of dividing each grid cell into four. Similarly, decreasing the spatial resolution only requires combining groups of four cells into one.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hexagonalgrids&quot;&gt;Hexagonal grids&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Reduced edge effects: a hexagonal grid gives the lowest perimeter to area ratio of any regular tessellation of the plane - this means that edge effects are minimized when working with hexagonal grids.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;All neighbours are identical: square grids have two classes of neighbours, those in the cardinal directions that share an edge and those in diagonal directions that share a vertex. In contrast, a hexagonal grid cell has six identical neighboring cells, each sharing one of the six equal-length sides. Furthermore, the distance between centroids is the same for all neighbors.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Better fit to curved surfaces: when dealing with large areas, where the curvature of the earth becomes important, hexagons are better able to fit this curvature than squares (this is why soccer balls are constructed of hexagonal panels).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/cartograms/hex-square-tessellation.png&quot; /&gt; &lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 3: Tessellation of the plane (Square and Hexagon). &lt;/p&gt;

&lt;h3 id=&quot;hexagonalgridforcartograms&quot;&gt;Hexagonal grid for Cartograms&lt;/h3&gt;

&lt;p&gt;For a cartogram, the reasons to choose hexagons over squares are as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;It&apos;s a better fit for curved surfaces, thereby supporting most geographic projections.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Representing a complex-shaped polygon by hexagons offers a lower error factor (tessellation of the plane), i.e., (the actual area of the polygon - Area formed by tiny tiles/hexagons) is lower as compared to that formed by squares.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;They look badass! Without a doubt, hexagonal grids look way more impressive than square grids.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot; id=&quot;buildingashapepreservedhexagonalgridcartogram&quot;&gt; 5. Building a shape preserved hexagonal grid cartogram&lt;/summary&gt;

&lt;p&gt;Since the primary dependency is D3 - a Javascript library extensively used for drawing geographic visualizations and uses &lt;a href=&quot;https://geojson.org&quot;&gt;GeoJSON&lt;/a&gt;/&lt;a href=&quot;https://en.wikipedia.org/wiki/GeoJSON&quot;&gt;TopoJSON&lt;/a&gt; for representing shapes on maps by converting them to rendered SVG element(s); explanations are supported by implementation details in D3.&lt;/p&gt;

&lt;details&gt;&lt;summary class=&quot;h4&quot; id=&quot;projection&quot;&gt; 5.1. Projection&lt;/summary&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/cartograms/earth-projection.png&quot; /&gt; &lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 4: Mercator projection. &lt;/p&gt;

&lt;p&gt;Earth is round or more accurately, an ellipsoid. To show its features on a flat surface, it&apos;s not possible to accurately translate a sphere onto a plane, hence the need for projections. For instance, the Mercator projection is famously known to over-exaggerate the size of landmasses near the poles (No wonder Greenland looks massive). &lt;/p&gt;

&lt;p&gt;D3 offers a range of built-in &lt;a href=&quot;https://github.com/d3/d3-geo-projection&quot;&gt;projections&lt;/a&gt;; however, no projection accurately depicts all points in the globe, so it&apos;s important to choose the appropriate projection for the use case. The purpose is simple: translate the latitude and longitude pair to a pair of X and Y coordinates on SVG. Lastly, to fit the coordinates to the SVG element, the &lt;code&gt;fitExtent&lt;/code&gt; and &lt;code&gt;rotate&lt;/code&gt; are handly, as the projection has no knowledge of the size or extent of the SVG element.&lt;/p&gt;

&lt;p&gt;&lt;img style=&quot;text-align: center&quot; src=&quot;./assets/posts/cartograms/projection-function.png&quot; /&gt; &lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 5: Projection function to map coordinate. &lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h4&quot; id=&quot;geopath&quot;&gt; 5.2. Geopath&lt;/summary&gt;

&lt;p&gt;The projection function works well for converting points into X and Y coordinates but not lines. A typical map has regions represented by lines and not individual points. Hence to render the map, irregular lines are represented using the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/SVG/Tutorial/Paths&quot;&gt;path&lt;/a&gt; element.
The &lt;code&gt;d&lt;/code&gt; attribute in &lt;code&gt;&amp;lt;path&amp;gt;&amp;lt;/path&amp;gt;&lt;/code&gt; defines the shape of the line.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;path
    d=&quot;M732.4944016581658,608.9022205707863L727.1354648887938,
    610.9411167803873L706.8155159265721,604.6447353677604L703.587646715891,
    610.7806528270128L688.0319490712842,611.8868016539795L688.8280117925813, 
    ......
    ......
    ......
    600.4706783128443L788.2046582778905,605.2215195516151L781.7980088643487,
    600.5439608373076L772.9856281618564,600.8681045994042L760.5726799028025,
    607.2632255686299L744.3618779892297,607.9935254189165L742.5384536592165,
    615.3237961667451Z&quot;
    stroke=&quot;white&quot;
    fill=&quot;rgb(211, 211, 211)&quot;
  &amp;lt;/path&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ussage in D3: &lt;code&gt;const path = d3.geoPath().projection(projection)&lt;/code&gt;, the &lt;code&gt;path&lt;/code&gt; functions takes &lt;code&gt;GeoJSON&lt;/code&gt; polygons, and returns a string which can directly be used as the &lt;code&gt;d&lt;/code&gt; attribute of an SVG path.&lt;/p&gt;

&lt;p&gt;To render the map, the plan is to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Loop through each country’s &lt;code&gt;GeoJSON&lt;/code&gt; polygon&lt;/li&gt;

&lt;li&gt;Create the &lt;code&gt;d&lt;/code&gt; attribute string using the &lt;code&gt;d3.geopath&lt;/code&gt; function&lt;/li&gt;

&lt;li&gt;Create and append an SVG path element with the above &lt;code&gt;d&lt;/code&gt; attribute&lt;/li&gt;
&lt;/ul&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h4&quot; id=&quot;tessellation&quot;&gt; 5.3. Tessellation&lt;/summary&gt;

&lt;p&gt;A tessellation or tiling is a process of covering a surface or a plane, using one or more geometric shapes, called tiles, with no overlaps or gaps. Furthermore, a variant of symmetric tessellation has a fixed tile size and geometric shape.&lt;/p&gt;

&lt;p&gt;Figure 3 shows the tessellation of Sri Lanka using a Hexagon and Square as the tile/cell. However, with the tessellation of a polygon, only the tiles within the polygon are arranged in the same order. Whereas, when dealing with multiple polygons in the same grid, the arrangement of tiles has to be based on the nearest tile that fits in the grid - implying the need for a point grid.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/cartograms/hex-grid-tessellation.png&quot; /&gt; &lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 6: Consistent Tessellation in a Grid. &lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h4&quot; id=&quot;tessellationofnpolygons&quot;&gt; 5.4. Tessellation of n polygons&lt;/summary&gt;

&lt;p&gt;Putting it all together, &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;the first step is forming a grid of points, where each point represents the center of the tile (hexagon/square). Figure 7 shows the point grid for hexagon tiles.&lt;/li&gt;

&lt;li&gt;The next step is to draw the tile relative to each point in the grid (tessellate points), forming the base playground - Then, superimpose the set of polygons (Features in TopoJSON) on the grid playground. &lt;/li&gt;

&lt;li&gt;Finally, tessellate each of the polygons by ensuring the tiles chosen are from the previously formed grid of tiles.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 100%&quot; src=&quot;./assets/posts/cartograms/point-grid.png&quot; /&gt; &lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 7: Point grid of (Width x Height). &lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 5%&quot; src=&quot;./assets/posts/down-arrow.png&quot; /&gt; &lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 100%&quot; src=&quot;./assets/posts/cartograms/point-grid-cell.png&quot; /&gt; &lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 8: Tessellate points with hexagons &lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 5%&quot; src=&quot;./assets/posts/down-arrow.png&quot; /&gt; &lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 100%&quot; src=&quot;./assets/posts/cartograms/point-grid-polygon.png&quot; /&gt; &lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 9: Draw the TopoJSON on Canvas (the above TopoJSON is the world map scaled by population of 2018). &lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 5%&quot; src=&quot;./assets/posts/down-arrow.png&quot; /&gt; &lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 100%&quot; src=&quot;./assets/posts/cartograms/point-grid-hex-cartogram.png&quot; /&gt; &lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 10: Regularly tessellate each country/polygon in the world-map with hexagons. &lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h4&quot; id=&quot;tessellationofnpolygons&quot;&gt; 5.5. Plotting a cartogram&lt;/summary&gt;

This section is a word in progress, stay tuned! 🤓

&lt;p&gt;The algorithm for generating a cartogram is a variant of continuous area cartograms by James A. Dougenik, Nicholas R. Chrisman, and Duane R. Niemeyer. &lt;/p&gt;

&lt;p&gt;The research paper: &lt;a href=&quot;http://lambert.nico.free.fr/tp/biblio/Dougeniketal1985.pdf&quot;&gt;An Algorithm to Construct Continous Area Cartograms&lt;/a&gt;. Without getting into the exact details, line-by-line, the procedure to produce cartograms is as follows: &lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 100%; border: 1px solid #000;&quot; src=&quot;./assets/posts/cartograms/world-map-centroids.png&quot; /&gt; &lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 11: Centroid of all polygons/countries. &lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h4&quot; id=&quot;tessellationofnpolygons&quot;&gt; 5.6. Fixed vs Fluid mode&lt;/summary&gt;

&lt;p&gt;&lt;strong&gt;Fixed:&lt;/strong&gt; The cell size is &lt;code&gt;fixed&lt;/code&gt; across years. The cell size is the population count of each cell (a country with a population of 10 million has 20 cells when the cell size is 0.5 million). Irrespective of the year/total population, the cell size remains the same in the &lt;code&gt;Fixed&lt;/code&gt; mode.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 100%; border: 1px solid #000;&quot; src=&quot;./assets/posts/cartograms/cartogram-fixed.gif&quot; /&gt; &lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 13: Cartogram scaled from 1950 to 1990 in Fixed mode &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fluid:&lt;/strong&gt; On the other hand, in the fluid mode, as the year/total population changes, the cell size is adjusted accordingly to best utilize the entire screen/container to display the cartogram. For example: A region with a total population of 20 million and a cell size of 0.5 million would have the same view when the total population is 40 million, and the cell size is 1 million.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 100%; border: 1px solid #000;&quot; src=&quot;./assets/posts/cartograms/cartogram-fluid.gif&quot; /&gt; &lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;Figure 14: Cartogram scaled from 1950 to 1990 in Fluid mode &lt;/p&gt;

&lt;/details&gt;

&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;implementation&quot;&gt;Implementation&lt;/h1&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot; id=&quot;dependencies&quot;&gt; 6. Dependencies&lt;/summary&gt;

&lt;pre&gt;&lt;code&gt;&quot;d3&quot;: &quot;^7.4.3&quot;,
&quot;d3-array&quot;: &quot;^3.1.6&quot;,
&quot;d3-geo&quot;: &quot;^3.0.1&quot;,
&quot;d3-hexbin&quot;: &quot;^0.2.2&quot;,
&quot;topojson-client&quot;: &quot;^3.1.0&quot;,
&quot;topojson-server&quot;: &quot;^3.0.1&quot;,
&quot;topojson-simplify&quot;: &quot;^3.0.3&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot; id=&quot;project-structure&quot;&gt; 7. Project Structure&lt;/summary&gt;

&lt;p&gt;The &lt;code&gt;core&lt;/code&gt; module:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;index.html&lt;/code&gt;: HTML page of the main screen containing the root container and input form fields such as year, radius, scale mode, cell size, export format, and cell color selector.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;cartogram.js&lt;/code&gt;: Implementation of the algorithm to construct continuous area cartograms.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;plot.js&lt;/code&gt;: The logic for rendering the tessellated point-grid and plotting the cartogram based on the selected input fields.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;shaper.js&lt;/code&gt;: Functions dependent on the cell shape; the common pattern followed is to take decisions based on the cell shape using a switch case.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;events.js&lt;/code&gt;: All the mouse events in the application, such as single/double click, hover, and drag/drop.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot; id=&quot;project-files&quot;&gt;8. Project Files&lt;/summary&gt;

&lt;br /&gt;

&lt;details&gt;&lt;summary class=&quot;h4&quot; id=&quot;project-files&quot;&gt;8.1. &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/owid/cartograms/blob/main/index.html&quot;&gt;index.html&lt;/a&gt;&lt;/summary&gt;

&lt;h3&gt;Create a HTML &lt;code&gt;div&lt;/code&gt; with a unique &lt;code&gt;id&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;To append SVG, i.e., the hexagonal grid and polygons/regions of the cartogram (derived from the topojson).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;html language-html&quot;&gt;&amp;lt;div class=&quot;container-fluid&quot;&amp;gt;
    &amp;lt;div id=&quot;container&quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h4&quot; id=&quot;project-files&quot;&gt;8.2. &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/owid/cartograms/blob/main/core/catogram.js&quot;&gt;cartogram.js&lt;/a&gt;&lt;/summary&gt;

&lt;p&gt; Without getting into the exact details, line-by-line, the procedure to produce cartograms is as follows: &lt;/p&gt;

&lt;h3 id=&quot;calculateforcereductionfactor&quot;&gt;Calculate Force Reduction Factor&lt;/h3&gt;

&lt;p&gt;The &quot;force reduction factor&quot; is a number less than 1, used to reduce the impact of cartogram forces in the early iterations of the procedure. The force reduction factor is the reciprocal of one plus the mean of the size error. The size error is calculated by the ratio of area over the desired area (if area is larger) or desired area over area in the other case.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;For each polygon
  Read and store PolygonValue (negative value illegal)
  Sum PolygonValue into TotalValue
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;For each iteration (user controls when done)
  For each polygon
      Calculate area and centroid (using current boundaries)
  Sum areas into TotalArea
  For each polygon
      Desired = (TotalArea * (PolygonValuelTotaIValue))
      Radius = SquareRoot (Area / π)
      Mass = SquareRoot (Desired / π) - SquareRoot (Area / π)
      SizeError = Max(Area, Desired) / Min(Area, Desired)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;moveboundarycoordinates&quot;&gt;Move boundary co-ordinates&lt;/h3&gt;

&lt;p&gt;The brute force method (fixed small number of polygons): the forces of all polygons/countries act upon every boundary coordinate. As long as the number of polygons is relatively small (under 500), distortions can be computed for a rather complex line work (thousands of points). Furthermore, the computation of force effects could be restricted by implementing a search limitation to exclude infinitesimal forces from far-away polygons.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  ForceReductionFactor = 1 / (1 + Mean (SizeError))
  For each boundary line; Read coordinate chain
      For each coordinate pair
          For each polygon centroid
              Find angle, Distance from centroid to coordinate
                If (Distance &amp;gt; Radius of polygon): Fij = Mass * (Radius / Distance)
                Else: Fij = Mass * (Distance^2 / Radius^2) * (4 - 3 * (Distance / Radius))
          Using Fij and angles, calculate vector sum
          Multiply by ForceReductionFactor
          Move coordinate accordingly
      Write distorted line to output and plot result
&lt;/code&gt;&lt;/pre&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h4&quot; id=&quot;project-files&quot;&gt;8.3. &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/owid/cartograms/blob/main/core/plot.js&quot;&gt;plot.js&lt;/a&gt;&lt;/summary&gt;

&lt;h3 id=&quot;createapointgrid&quot;&gt;Create a point grid&lt;/h3&gt;

&lt;p&gt;A point grid is a matrix containing the centers of all the cells in the grid.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  let cellRadius = cellDetails.radius;
  let cellShape = cellDetails.shape;

  let shapeDistance = getRadius(cellRadius, cellShape);
  let cols = width / shapeDistance;
  let rows = height / shapeDistance;
  let pointGrid = d3.range(rows * cols).map(function (el, i) {
    return {
      x: Math.floor(i % cols) * shapeDistance,
      y: Math.floor(i / cols) * shapeDistance,
      datapoint: 0,
    };
  });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;shapeDistance&lt;/code&gt; is different for different cell-shapes. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  switch (cellShape) {
      case cellPolygon.Hexagon:
        shapeDistance = radius * 1.5;
      case cellPolygon.Square:
        shapeDistance = radius * 2;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 5%&quot; src=&quot;./assets/posts/down-arrow.png&quot; /&gt; &lt;/p&gt;

&lt;h3 id=&quot;plotthehexagonalgridplayground&quot;&gt;Plot the hexagonal grid playground&lt;/h3&gt;

&lt;p&gt;The playground of cells is as shown in Figure 8, where each point in the grid is tesselated with the respective cell shape. The playground also serves as the never-ending sea/ocean on the world map.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  d3.select(&quot;#container&quot;).selectAll(&quot;*&quot;).remove();
    const svg = d3
      .select(&quot;#container&quot;)
      .append(&quot;svg&quot;)
      .attr(&quot;width&quot;, width + margin.left + margin.top)
      .attr(&quot;height&quot;, height + margin.top + margin.bottom)
      .append(&quot;g&quot;)
      .attr(&quot;transform&quot;, `translate(${margin.left} ${margin.top})`);

  svg
    .append(&quot;g&quot;)
    .attr(&quot;id&quot;, &quot;hexes&quot;)
    .selectAll(&quot;.hex&quot;)
    .data(getGridData(cellShape, newHexbin, pointGrid))
    .enter()
    .append(&quot;path&quot;)
    .attr(&quot;class&quot;, &quot;hex&quot;)
    .attr(&quot;transform&quot;, getTransformation(cellShape))
    .attr(&quot;d&quot;, getPath(cellShape, newHexbin, shapeDistance))
    .style(&quot;fill&quot;, &quot;#fff&quot;)
    .style(&quot;stroke&quot;, &quot;#e0e0e0&quot;)
    .style(&quot;stroke-width&quot;, strokeWidth)
    .on(&quot;click&quot;, mclickBase);
&lt;/code&gt;&lt;/pre&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h4&quot; id=&quot;project-files&quot;&gt;8.4. &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/owid/cartograms/blob/main/core/shaper.js&quot;&gt;shaper.js&lt;/a&gt;&lt;/summary&gt;

&lt;p&gt;The &lt;code&gt;shaper.js&lt;/code&gt; has all the code snippets that depend on the cells shape. &lt;/p&gt;

&lt;p&gt;Once again, the transformation, SVG path, and binned data points (grid) are dependent on the cell-shape.
For hexagons, the library used: &lt;a href=&quot;https://github.com/d3/d3-hexbin&quot;&gt;d3-hexbin&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  function getGridData(cellShape, bin, grid) {
    switch (cellShape) {
      case cellPolygon.Hexagon:
        return bin(grid);
      case cellPolygon.Square:
        return grid;
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Translate is one of the support transformations (Translate, Rotate, Scale, and Skew). It moves the SVG elements inside the webpage and takes two values, &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. The &lt;code&gt;x&lt;/code&gt; value translates the SVG element along the x-axis, while &lt;code&gt;y&lt;/code&gt; translates the SVG element along the y-axis. 
For example: A single point in a point-grid represents the top-right corner of a square, which is moved by &lt;code&gt;length of the side/2&lt;/code&gt; on the x and y-axis using &lt;code&gt;transform.translate(x, y)&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  function getTransformation(cellShape) {
    switch (cellShape) {
      case cellPolygon.Hexagon:
        return function (d) {
          return &quot;translate(&quot; + d.x + &quot;, &quot; + d.y + &quot;)&quot;;
        };
      case cellPolygon.Square:
        return function (d) {
          return &quot;translate(&quot; + d.x / 2 + &quot;, &quot; + d.y / 2 + &quot;)&quot;;
        };
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To emphasize the ease of extending the solution for other cell shapes, notice the &lt;code&gt;rightRoundedRect&lt;/code&gt; that takes &lt;code&gt;borderRadius&lt;/code&gt; (zero for a square/rectangle); however, setting it to 50% would result in circular cells.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  function getPath(cellShape, bin, distance) {
    switch (cellShape) {
      case cellPolygon.Hexagon:
        return bin.hexagon();
      case cellPolygon.Square:
        return function (d) {
          return rightRoundedRect(d.x / 2, d.y / 2, distance, distance, 0);
        };
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 5%&quot; src=&quot;./assets/posts/down-arrow.png&quot; /&gt; &lt;/p&gt;

&lt;h3 id=&quot;createthebasecartogram&quot;&gt;Create the base cartogram&lt;/h3&gt;

&lt;p&gt;The expectation of &lt;code&gt;Cartogram()&lt;/code&gt; is to take the current topo-features of the map projection along with the source population count and target population count to return new topo-features (arcs for every polygon/country).&lt;/p&gt;

&lt;p&gt;In this example, the base cartogram is a population-scaled world map for the year 2018.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  var topoCartogram = cartogram()
    .projection(null)
    .properties(function (d) {
      return d.properties;
    })
    .value(function (d) {
      var currentValue = d.properties.count;
      return +currentValue;
    });
  topoCartogram.features(topo, topo.objects.tiles.geometries);
  topoCartogram.value(function (d) {
    var currentValue = populationJson[d.properties.id][year];
    return +currentValue;
  });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As for the presentation, there are two types: &lt;code&gt;Fixed&lt;/code&gt; and &lt;code&gt;Fluid&lt;/code&gt;, as shown in Figures 13 and 14.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Population Factor:&lt;/strong&gt; The &lt;code&gt;populationFactor&lt;/code&gt; is &quot;1&quot; in &lt;code&gt;FLUID&lt;/code&gt; mode and depends on the source and target population ratio in &lt;code&gt;FIXED&lt;/code&gt; mode, calculated using back-propagation, where the default &lt;code&gt;populationFactor&lt;/code&gt; is 1.6 (mean of expected values across years) and increased/decreased in steps of 0.1 to reach the desired cell-size.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  var topoFeatures = topoCartogram(
    topo,
    topo.objects.tiles.geometries,
    cellDetails,
    populationData, year,
    populationFactor
  ).features;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  populationFactor(selectedScale, populationData, year) {
    switch (selectedScale) {
      case cellScale.Fixed:
        var factor =
          getTotalPopulation(populationData, 2018) /
          getTotalPopulation(populationData, year) /
          1.6;
        return factor;
      case cellScale.Fluid:
        return 1;
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 5%&quot; src=&quot;./assets/posts/down-arrow.png&quot; /&gt; &lt;/p&gt;

&lt;h3&gt;Flatten the features of the cartogram/topojson.&lt;/h3&gt;

&lt;p&gt;A quick transformation to form a list of polygons irrespective of whether the feature is a &lt;code&gt;MultiPolygon&lt;/code&gt; or a &lt;code&gt;MultiPolygon&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;function flattenFeatures(topoFeatures) {
  let features = [];
  for (let i = 0; i &amp;lt; topoFeatures.length; i++) {
    var tempFeatures = [];
    if (topoFeatures[i].geometry.type == &quot;MultiPolygon&quot;) {
      for (let j = 0; j &amp;lt; topoFeatures[i].geometry.coordinates.length; j++) {
        tempFeatures[j] = topoFeatures[i].geometry.coordinates[j][0];
      }
    } else if (topoFeatures[i].geometry.type == &quot;Polygon&quot;) {
      tempFeatures[0] = topoFeatures[i].geometry.coordinates[0];
    }
    features[i] = {
      coordinates: tempFeatures,
      properties: topoFeatures[i].properties,
    };
  }
  return features;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 5%&quot; src=&quot;./assets/posts/down-arrow.png&quot; /&gt; &lt;/p&gt;

&lt;h3&gt;Fill the polygons/regions of the base cartogram with hexagons (tessellation)&lt;/h3&gt;

&lt;p&gt;This is the step where the polygons are tesselated, and the &lt;code&gt;d3.polygonContains&lt;/code&gt; function checks for points in the point-grid within the polygon as shown in figures 9 and 10. &lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  let features = flattenFeatures(topoFeatures);
  let cellCount = 0;
  for (let i = 0; i &amp;lt; features.length; i++) {
    for (let j = 0; j &amp;lt; features[i].coordinates.length; j++) {
      var polygonPoints = features[i].coordinates[j];

      let tessellatedPoints = pointGrid.reduce(function (arr, el) {
        if (d3.polygonContains(polygonPoints, [el.x, el.y])) arr.push(el);
        return arr;
      }, []);
      cellCount = cellCount + tessellatedPoints.length;

      svg
        .append(&quot;g&quot;)
        .attr(&quot;id&quot;, &quot;hexes&quot;)
        .selectAll(&quot;.hex&quot;)
        .data(getGridData(cellShape, newHexbin, tessellatedPoints))
        .append(&quot;path&quot;)
        .attr(&quot;class&quot;, &quot;hex&quot; + features[i].properties.id)
        .attr(&quot;transform&quot;, getTransformation(cellShape))
        .attr(&quot;x&quot;, function (d) {
          return d.x;
        })
        .attr(&quot;y&quot;, function (d) {
          return d.y;
        })
        .attr(&quot;d&quot;, getPath(cellShape, newHexbin, shapeDistance))
        ... // same as above
        .style(&quot;stroke-width&quot;, strokeWidth);
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h4&quot; id=&quot;project-files&quot;&gt;8.5. &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/owid/cartograms/blob/main/core/events.js&quot;&gt;events.js&lt;/a&gt;&lt;/summary&gt;

&lt;h3 id=&quot;draganddrophexagonsinthehexgrid&quot;&gt;Drag and drop hexagons in the hex-grid&lt;/h3&gt;

&lt;p&gt;Implementation of &lt;code&gt;start&lt;/code&gt;, &lt;code&gt;drag&lt;/code&gt;, and &lt;code&gt;end&lt;/code&gt; - representing the states when the drag has started, in-flight, and dropped to a cell-slot.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  function dragstarted(event, d) {
    d.fixed = false;
    d3.select(this).raise().style(&quot;stroke-width&quot;, 1).style(&quot;stroke&quot;, &quot;#000&quot;);
  }

  function dragged(event, d) {
    let cellShape = document.querySelector(&quot;#cell-shape-option&quot;).value;
    let hexRadius = document.querySelector(&quot;input#radius&quot;).value;
    var x = event.x;
    var y = event.y;
    var grids = getNearestSlot(x, y, hexRadius, cellShape);
    d3.select(this)
      .attr(&quot;x&quot;, (d.x = grids[0]))
      .attr(&quot;y&quot;, (d.y = grids[1]))
      .attr(&quot;transform&quot;, getTransformation(cellShape));
  }

  function dragended(event, d) {
    d.fixed = true;
    d3.select(this).style(&quot;stroke-width&quot;, strokeWidth).style(&quot;stroke&quot;, &quot;#000&quot;);
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Finding the nearest cell-slot:&lt;/strong&gt; It&apos;s vital to ensure that a cell can only be dragged to another cell-slot. From the x and y co-ordinate, calculate the nearest available slot. For example, a square of length 5 units at x co-ordinate of 102, &lt;code&gt;102 - (102 % 5) = 100&lt;/code&gt; would be the position of the nearest slot on the x-axis, similarly on the y-axis. On the other hand, hexagons are a bit tricky, where the lengths of the hexagon are &lt;code&gt;radius * 2&lt;/code&gt; and &lt;code&gt;apothem * 2&lt;/code&gt;. Recommended read on hexagons and hex-grid: &lt;a href=&quot;https://www.redblobgames.com/grids/hexagons/&quot;&gt;https://www.redblobgames.com/grids/hexagons&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  function getNearestSlot(x, y, n, cellShape) {
    switch (cellShape) {
      case cellPolygon.Hexagon:
        var gridx;
        var gridy;
        var factor = Math.sqrt(3) / 2;
        var d = n * 2;
        var sx = d * factor;
        var sy = n * 3;
        if (y % sy &amp;lt; n) {
          gridy = y - (y % sy);
          gridx = x - (x % sx);
        } else {
          gridy = y + (d - (n * factor) / 2) - (y % sy);
          gridx = x + n * factor - (x % sx);
        }
        return [gridx, gridy];
      case cellPolygon.Square:
        var gridx;
        var gridy;
        var sx = n * 2;
        var sy = n * 2;
        gridy = y - (y % sy);
        gridx = x - (x % sx);
        return [gridx, gridy];
    }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;mouseoverandoutinthehexgrid&quot;&gt;Mouse over and out in the hex-grid&lt;/h3&gt;

&lt;p&gt;Similarly, a few other events include mouse over, mouse out, and mouse click.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  svg.append(&apos;g&apos;)
  ... // same as above
  .on(&quot;mouseover&quot;, mover)
  .on(&quot;mouseout&quot;, mout)
  .call(d3.drag()
      .on(&quot;start&quot;, dragstarted)
      .on(&quot;drag&quot;, dragged)
      .on(&quot;end&quot;, dragended));
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;javascript language-javascript&quot;&gt;  function mover(d) {
    d3.selectAll(&quot;.&quot; + this.getAttribute(&quot;class&quot;))
      .transition()
      .duration(10)
      .style(&quot;fill-opacity&quot;, 0.9);
  }

  function mout(d) {
    d3.selectAll(&quot;.&quot; + this.getAttribute(&quot;class&quot;))
      .transition()
      .duration(10)
      .style(&quot;fill-opacity&quot;, 1);
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;/details&gt;

&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;details open=&quot;&quot;&gt;&lt;summary class=&quot;h3&quot; id=&quot;conclusion&quot;&gt; 9. Pending items&lt;/summary&gt;

&lt;p&gt;A complete implementation of the above (with additional features):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Prototype: &lt;a href=&quot;https://owid.github.io/cartograms/&quot;&gt;https://owid.github.io/cartograms&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;Github Repository: &lt;a href=&quot;https://github.com/owid/cartograms&quot;&gt;https://github.com/owid/cartograms&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, this does not conclude meeting the expected requirement(s). The last pending piece is to generate a new cartogram/topojson after moving the cells. That&apos;s a work in progress; stay tuned! &lt;a href=&quot;https://pyblog.medium.com/subscribe&quot;&gt;Subscribe&lt;/a&gt; maybe?&lt;/p&gt;

&lt;/details&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;details&gt;&lt;summary class=&quot;h3&quot; id=&quot;references&quot;&gt; 10. References&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;[1] “Amit’s Thoughts on Grids,” www-cs-students.stanford.edu. http://www-cs-students.stanford.edu/~amitp/game-programming/grids

[2] M. Strimas-Mackey, “Fishnets and Honeycomb: Square vs. Hexagonal Spatial Grids,” Matt Strimas-Mackey, Jan. 14, 2016. https://strimas.com/post/hexagonal-grids

[3] S. Kamani, “D3 Geo Projections Explained” www.sohamkamani.com. https://www.sohamkamani.com/blog/javascript/2019-02-18-d3-geo-projections-explained (accessed Jun. 14, 2022).

[4] “Markdown to HTML Converter - Markdown Editor - Online - Browserling Web Developer Tools,” www.browserling.com. https://www.browserling.com/tools/markdown-to-html (accessed Jul. 10, 2022).
&lt;/code&gt;&lt;/pre&gt;

&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Adesh Nalpet Adimurthy</name></author><category term="Comics" /><category term="Project" /><category term="GSoC" /><category term="Cartogram" /><category term="Algorithms" /><category term="Open Source" /><summary type="html"></summary></entry><entry><title type="html">Distributed Model Training</title><link href="https://pyblog.xyz/distributed-model-training" rel="alternate" type="text/html" title="Distributed Model Training" /><published>2022-06-26T00:00:00+00:00</published><updated>2022-06-26T00:00:00+00:00</updated><id>https://pyblog.xyz/distributed-model-training</id><content type="html" xml:base="https://pyblog.xyz/distributed-model-training">&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/featured/porco-rosso.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Porco Rosso. &lt;/p&gt;

&lt;h2 id=&quot;distributed-training&quot;&gt;Distributed Training&lt;/h2&gt;
&lt;p&gt;Deep learning is a subset of machine learning, a branch of artificial intelligence to perform tasks through experience. Deep learning algorithms are well suited and perform the best with large datasets, not to mention the need for high computation power. With the pay-per-use serverless service model, such as the google collab, training large neural networks on the cloud is easier than ever.
While it’s possible to train huge models in a single multi-core GPU machine, it could take days and even weeks. Hence, this leads to the fundamental problem of reducing the training time.&lt;/p&gt;

&lt;p&gt;Typically, any scaling problem is broadly addressed by scaling-up or scaling-out, i.e., horizontal and vertical scaling. Depending on the use case, vertical scaling has the limitation of maxing out at a point and often tends to be a lot more expensive in the long run, both in price and technical backlog.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;One-liner:&lt;/strong&gt; Distributed training distributes training workloads across multiple computation processors. Where a cluster of worker nodes works in parallel to accelerate the training process, parallelism is achieved by data parallelism or model parallelism.&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h2 id=&quot;types-of-distributed-training&quot;&gt;Types of Distributed Training&lt;/h2&gt;
&lt;h3 id=&quot;data-parallelism&quot;&gt;Data Parallelism&lt;/h3&gt;
&lt;p&gt;As the name suggests, the dataset is horizontally/vertically sharded and processed parallelly. Each worker node in the cluster trains a copy of the model on a different batch of training data, communicating the computation results to keep the model parameters and gradients in sync across all nodes. The computation results can be shared synchronously, i.e., at the end of each batch computation or asynchronously.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/machine-learning/data-parallel-training.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 1: Data-Parallel training. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;One-liner:&lt;/strong&gt; The entire model is deployed to multiple nodes of the cluster, and each node represents the horizontal/vertical split of the sharded dataset and the model.&lt;/p&gt;

&lt;h3 id=&quot;model-parallelism&quot;&gt;Model Parallelism&lt;/h3&gt;
&lt;p&gt;On the contrary, in model parallelism, the model itself is divided into parts/layers in situations where the model size is too large for a single worker; hence a set of layers are trained simultaneously across different worker nodes. The entire dataset is copied/available to all worker nodes, and they only share the global model parameters with other workers—typically just before forward or backward propagation. Furthermore, the layers can be partitioned vertically or horizontally.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/machine-learning/model-parallel-training.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 2: Model-Parallel training. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;One-liner:&lt;/strong&gt; A layer or a group of layers of the model is deployed to multiple nodes of the cluster, and the entire dataset is copied to every node.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/machine-learning/model-partitioning.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 3: Model-Partitioning horizontally or
vertically. &lt;/p&gt;

&lt;p&gt;Among the two, data parallelism is commonly used and easier to implement. The ability to train a model in batches of data (non-sequential) and contribute to the overall performance of the model is the crux of the solution. In other words, the model parameters and gradients are calculated for every small batch of data in the worker node, and at the end of it → updated weights are sent back to the initiating node → the weighted average/mean of the weights from each worker node is applied to the model parameters → updated model parameters are sent back all worker nodes for the next iteration; this leads to questions about how and when model parameters are stored and updated.&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h2 id=&quot;distributed-training-loops&quot;&gt;Distributed Training Loops&lt;/h2&gt;
&lt;p&gt;The two ways of carrying out distributed training loops are as follows:&lt;/p&gt;

&lt;h3 id=&quot;synchronous-training&quot;&gt;Synchronous training&lt;/h3&gt;
&lt;p&gt;Once again, taking the example of data parallelism, where we divide the data into partitions/batches for each worker node to process. Every worker node has a full replica of the model and the batch of data.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The forward pass starts at the same time for all workers, and each worker node computes the gradients (Output).&lt;/li&gt;
  &lt;li&gt;Workers wait until all the other workers have completed the training loop. Then, once all the workers have computed the gradients, they start communicating with each other to aggregate the gradients.&lt;/li&gt;
  &lt;li&gt;After all the gradients are combined, a copy of the updated gradients is sent to all the workers.&lt;/li&gt;
  &lt;li&gt;Then, each worker continues with the backward pass and updates the local copy of the weights.&lt;/li&gt;
  &lt;li&gt;Until all the workers have updated their weights, the next forward pass does not start; hence the name “synchronous”.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note: All the workers produce different gradients as they are trained on different subsets of data, and eventually, all workers have the same weight.&lt;/p&gt;

&lt;h3 id=&quot;reduce-algorithm&quot;&gt;Reduce Algorithm&lt;/h3&gt;
&lt;p&gt;Typically, a single node is used to complete aggregation. For instance, in the case shown in Figure 3, the bandwidth for Machine A increases as the number of machines/parameters increases.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 65%&quot; src=&quot;./assets/posts/machine-learning/single-reduce.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 4: Single node aggregator.&lt;/p&gt;

&lt;p&gt;Following up on the reduce-algorithm mentioned in synchronous training, the idea behind the all-reduce algorithm is to share the load of storing and maintaining the global parameters to overcome the limitation of using the parameter server method. There are serval all-reduce algorithms that dictate how parameters are calculated and shared:&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 45%&quot; src=&quot;./assets/posts/machine-learning/all-reduce.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 5: All Reduce: Aggregation task distributed to all nodes instead of a single node.&lt;/p&gt;

&lt;p&gt;Like AllReduce, each node performs the aggregation task on a subset of parameters: machine A – parameter 1, machine B – parameter 2, etc. Instead of sending its version of parameters to all other nodes, each worker node sends its version to the next one.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 45%&quot; src=&quot;./assets/posts/machine-learning/ring-all-reduce.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 6: Ring All Reduce.&lt;/p&gt;

&lt;p&gt;Similarly, in tree-all-reduce, parameters are shared via a tree structure. Irrespective of the topology, all-reduce algorithms reduce synchronization overhead and make it easier to scale horizontally.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; style=&quot;width: 65%&quot; src=&quot;./assets/posts/machine-learning/tree-all-reduce.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 7: Tree All Reduce.&lt;/p&gt;

&lt;p&gt;Each worker node holds a subset of data and computes the gradient(s); those values are passed up the tree and aggregated until a global aggregate value is calculated in the root node. Then, the global value is passed down to all other nodes.&lt;/p&gt;

&lt;h3 id=&quot;asynchronous-training&quot;&gt;Asynchronous training&lt;/h3&gt;
&lt;p&gt;The evident problem with the synchronous approach is the lack of efficient resource usage since a worker must wait for all the other workers in the cluster to move forward in the pipeline. Furthermore, the problem amplifies when the computation time for workers is significantly different, which could be because of dataset or computation power variations - because of which the whole process is only as fast as the slowest worker in the cluster. Hence in asynchronous training, the workers work independently in such a way that a worker need not wait for any other worker in the cluster. One way to achieve this is by using a parameter server.&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h2 id=&quot;communication-approaches&quot;&gt;Communication Approaches&lt;/h2&gt;
&lt;p&gt;The two communication approaches, centralized and de-centralized patterns, apply to both data-parallel and model-parallel training. The key here is the communication between the worker nodes, how the parameters are initiated, and how the weights/biases are updated.&lt;/p&gt;

&lt;h3 id=&quot;centralized-training&quot;&gt;Centralized Training&lt;/h3&gt;
&lt;p&gt;In distributed training, the cluster of workers performs just one task: training. However, in the centralized communication pattern, we assign a different role to each worker, where some workers act as parameter servers and the rest as training workers.&lt;/p&gt;

&lt;p&gt;The parameter servers are responsible for holding the parameters of the model and are responsible for updating the global state of our model. At the same time, the training workers run the actual training loop and produce the gradients from the batch of data assigned to them.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/machine-learning/centralized-data-parallel-training.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 8: Centralized training. &lt;/p&gt;

&lt;p&gt;Hence the entire process for Centralized data-parallel training is as follows:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Replicate the model across the training worker nodes; each worker node uses a subset of the data.&lt;/li&gt;
  &lt;li&gt;Each training worker fetches the parameters from the parameter server(s).&lt;/li&gt;
  &lt;li&gt;Each training worker node performs a training loop and sends back the gradients to all parameter servers.&lt;/li&gt;
  &lt;li&gt;Parameter servers update the model parameters and ensures all the worker models are in sync.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some known disadvantages are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;At a given point in time, only one of the workers may be using the updated version of the model, while the rest use a stale version.&lt;/li&gt;
  &lt;li&gt;Using only one worker as a parameter server can become a bottleneck and lead to a single point of failure.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;de-centralized-training&quot;&gt;De-centralized Training&lt;/h3&gt;
&lt;p&gt;On the flip side, In a de-centralized communication pattern, each worker node communicates with every other node to update the model parameters. The advantage of this approach is that peer-peer updates are faster, and there is no single point of failure.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;center-image&quot; src=&quot;./assets/posts/machine-learning/decentralized-data-parallel-training.png&quot; /&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Figure 9: De-centralized training. &lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Deep learning models become more ambitious by the day, and their supporting infrastructures struggle to keep up. Employing distributed model training techniques is only a matter of time to solve the problem of training a complex machine learning model on huge datasets. Moreover, the advantages supersede the development time/bandwidth with better Fault tolerance and reliability, higher Efficiency,  horizontally scalable to handle massive scale, and cost-effective in the long run.&lt;/p&gt;

&lt;hr class=&quot;hr&quot; /&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[1] “Distributed Training: Guide for Data Scientists,” neptune.ai, Jan. 19, 2022. https://neptune.ai/blog/distributed-training (accessed Jun. 23, 2022).

[2] “Distributed Training,” www.run.ai. https://www.run.ai/guides/gpu-deep-learning/distributed-training (accessed Jun. 24, 2022).

[3] “Distributed Training for Machine Learning – Amazon Web Services,” Amazon Web Services, Inc. https://aws.amazon.com/sagemaker/distributed-training/ (accessed Jun. 26, 2022).

[4] “Distributed model training II: Parameter Server and AllReduce – Ju Yang.” http://www.juyang.co/distributed-model-training-ii-parameter-server-and-allreduce/ (accessed Jun. 26, 2022).
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Adesh Nalpet Adimurthy</name></author><category term="System Wisdom" /><category term="System Design" /><category term="Machine Learning" /><summary type="html">Porco Rosso.</summary></entry></feed>