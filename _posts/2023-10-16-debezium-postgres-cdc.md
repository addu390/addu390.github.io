---
layout: post
title: "Debezium: PostgreSQL Change Data Capture (CDC)"
date: 2023-10-16
tags:
  - System Design
author: Adesh Nalpet Adimurthy
feature: assets/featured/debezium-postgres-cdc.png
category: System Wisdom
---

<img class="center-image" src="./assets/featured/debezium-postgres-cdc.png" /> 
<p style="text-align: center;">Figure 1: Debezium Postgres Connector</p>



<details open><summary class="h3">1. Goal</summary>
<p>Set up Debezium to capture row-level changes in the schemas of a PostgreSQL database and publish to Kafka topic(s).</p>

<p>The high-level architecture is unquestionably explained in Figure 1. Pikachu, aka Debezium PostgreSQL Connector, detects and carries/publishes row-level change events to Kafka topic(s) for configured Postgres tables.</p>
</details>

<hr class="hr">

<details><summary class="h3">2. Definitions</summary>

<h3 id="cdc">2.1. Change Data Capture (CDC)</h3>
<p>In databases, change data capture (CDC) is a set of software design patterns used to determine and track the data that has changed (the "deltas") so that action can be taken using the changed data [1].</p>

<hr class="hr">

<h3 id="debezium">2.2. Debezium</h3>
<p>Debezium is a set of distributed services to capture changes in your databases so that your applications can see those changes and respond to them. Debezium records all row-level changes within each database table in a change event stream, and applications simply read these streams to see the change events in the same order in which they occurred [2].</p>

<hr class="hr">

<h3 id="connectors">2.3. Debezium Connectors</h3>
<p>A library of connectors that capture changes from a variety of database management systems and produce events with very similar structures, making it far easier for your applications to consume and respond to the events regardless of where the changes originated [3].</p>

<hr class="hr">

<h3 id="postgresql-connector">2.4. Debezium connector for PostgreSQL</h3>
<p>The Debezium PostgreSQL connector captures row-level changes in the schemas of a PostgreSQL database [4].</p>

<hr class="hr">

<h3 id="kafka">2.5. Kafka</h3>
<p>Apache Kafka is a distributed data store optimized for ingesting and processing streaming data in real-time. Streaming data is data that is continuously generated by thousands of data sources, which typically send the data records in simultaneously [5].</p>

<hr class="hr">

<h3 id="kafka-connect">2.6. Kafka Connect</h3>
<p>Kafka Connect is a tool for scalably and reliably streaming data between Apache Kafka and other systems. It makes it simple to quickly define connectors that move large collections of data into and out of Kafka [6].</p>

</details>

<hr class="hr">

<details open><summary class="h3">3. Set up using Docker-Compose</summary>
<p>As a generate note, If you use Mac M1/M2, ensure the docker image has <code>linux/arm64</code> OS/ARCH.</p>
<p><img class="center-image" src="./assets/posts/docker-debezium-arch.png" /> </p>

<p>Section 3.1 covers the breakdown of each service/docker image used in <code>docker-compose.yaml</code> file, if you have worked with docker before, skip the section and pick up the entire file from 3.2 instead.</p>

<details><summary class="h3">3.1. Services Details (Optional)</summary>
<p>Break down of services in <code>docker-compose.yaml</code></p>

<ul>
<li><p><b>Postgres</b>: The database containing the table(s) for which CDC is tracked.</p></li>

<li><p><b>Kafka</b> and <b>Zookeeper</b>: The event broker where CDC events are stored.</p></li>

<li><p><b>Schema Registry</b>: To serialize/deserialize CDC message(s) using Avro schema.</p></li>

<li><p><b>Debezium</b>: Responsible for capturing the row-level changes made to Postgres table(s) and streaming them to a Kafka topic.</p></li>
</ul>

<details open><summary class="h3">3.1.1. PostgreSQL</summary>
<p><a href="https://hub.docker.com/r/debezium/postgres">debezium/postgres</a>: PostgreSQL for use with Debezium change data capture. This image is based upon <a href="https://hub.docker.com/_/postgres/">postgres</a> along with <a href="https://www.postgresql.org/docs/11/logicaldecoding-explanation.html">logical decoding</a> plugin from <a href="https://github.com/debezium/">Debezium</a></p>

<p><a href="https://hub.docker.com/r/dpage/pgadmin4/">dpage/pgadmin4</a> (Optional): Web browser version of <a href="https://www.pgadmin.org/download/pgadmin-4-container/">pgAdmin 4</a> for the ease of running DML and DDL operations on PostgreSQL.</p>

<pre><code>
postgres:
  image: debezium/postgres:13-alpine
  ports:
    - 5432:5432
  environment:
    - POSTGRES_USER=admin
    - POSTGRES_PASSWORD=root
    - POSTGRES_DB=pyblog

pgadmin:
  image: dpage/pgadmin4
  environment:
    - PGADMIN_DEFAULT_EMAIL=admin@admin.com
    - PGADMIN_DEFAULT_PASSWORD=root
  ports:
    - '5050:80'
  restart: always
</code></pre>
</details>

<hr class="hr">

<details><summary class="h3">3.1.2. Kafka and Zookeeper</summary>

<p>Confluent Platform Docker images for Kafka: <a href="https://hub.docker.com/r/confluentinc/cp-enterprise-kafka/">confluentinc/cp-enterprise-kafka/postgres</a> and Zookeeper: <a href="https://hub.docker.com/r/confluentinc/cp-zookeeper">confluentinc/cp-zookeeper</a>. The below example is for version <code>7.3</code>, a more recent version, i.e., <code>7.5</code> onwards, Confluent recommends <a href="https://docs.confluent.io/platform/current/kafka-metadata/kraft.html">KRaft</a> mode for new deployments, and Zookeeper is deprecated.</p>

<pre><code>
zookeeper:
  image: confluentinc/cp-zookeeper:7.3.5
  environment:
    ZOOKEEPER_CLIENT_PORT: 2181

kafka:
  image: confluentinc/cp-enterprise-kafka:7.3.5
  depends_on: [zookeeper]
  environment:
    KAFKA_BROKER_ID: 1
    KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
    KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    KAFKA_JMX_PORT: 9991
  ports:
    - 9092:9092
</code></pre>

</details>

<hr class="hr">

<details><summary class="h3">3.1.3. Debezium and Schema Registry</summary>

<p><a href="https://hub.docker.com/r/debezium/connect">debezium/connect</a> image defines a runnable <a herf="https://kafka.apache.org/documentation.html#connect">Kafka Connect</a> service preconfigured with all Debezium connectors; it monitors database management system(s) for changing data and then forwards those changes directly into Kafka topics organized by server, database, and table.
</p>

<p><a href="https://hub.docker.com/r/confluentinc/cp-schema-registry">confluentinc/cp-schema-registry</a> enables client applications to read and write Avro data, in this case, to serialize and deserialize CDC messages.
</p>

<pre><code>
debezium:
  image: debezium/connect:2.4
  environment:
    BOOTSTRAP_SERVERS: kafka:9092
    GROUP_ID: 1
    CONFIG_STORAGE_TOPIC: connect_configs
    OFFSET_STORAGE_TOPIC: connect_offsets
    STATUS_STORAGE_TOPIC: my_status_topic
    CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
    CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
  depends_on: [kafka]
  ports:
    - 8083:8083

schema-registry:
  image: confluentinc/cp-schema-registry:7.3.5
  environment:
    - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
    - SCHEMA_REGISTRY_HOST_NAME=schema-registry
    - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8085,http://localhost:8085
  ports:
    - 8085:8085
  depends_on: [zookeeper, kafka]
</code></pre>

</details>

</details>

<hr class="hr">

<details open><summary class="h3">3.2. Start Services</summary>

<p>The complete <code>docker-compose.yaml</code> to set up Postgres with debezium and publish data change events to Kafka:</p>

<p><b>Note</b>: At the time of writing this post, the services use the current stable version(s); visit the docker hub page for the latest stable version(s).</p>

<pre><code>
version: "3.7"
services:
  postgres:
    image: debezium/postgres:13-alpine
    ports:
      - 5432:5432
    environment:
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=root
      - POSTGRES_DB=pyblog

  pgadmin:
    image: dpage/pgadmin4
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@admin.com
      - PGADMIN_DEFAULT_PASSWORD=root
    ports:
      - '5050:80'
    restart: always

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.5
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-enterprise-kafka:7.3.5
    depends_on: [zookeeper]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9991
    ports:
      - 9092:9092

  debezium:
    image: debezium/connect:2.4
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: my_status_topic
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
    depends_on: [kafka]
    ports:
      - 8083:8083

  schema-registry:
    image: confluentinc/cp-schema-registry:7.3.5
    environment:
      - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
      - SCHEMA_REGISTRY_HOST_NAME=schema-registry
      - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8085,http://localhost:8085
    ports:
      - 8085:8085
    depends_on: [zookeeper, kafka]
</code></pre>

<ul>
<li><p>Clean-up and Remove containers: <code>docker rm -f $(docker ps -a -q)</code></p></li>
<li><p>Create and Start containers: <code>docker-compose up -d</code></p></li>
<li><p>Stop containers: <code>docker-compose down</code></p></li>
<li><p>List containers: <code>docker ps</code></p></li>
</ul>

</details>

<p>Work in Progress!</p>

</details>